#Import the packagesimport numpy as npimport pylabimport sysfrom skimage import iofrom skimage import colorfrom scipy import ndimagefrom matplotlib import pyplotimport project_helpers as ph# Flag that indicates whether to show images.VIEW = False# Set the path to the data files.data_path = "crchistophenotypes_2016_04_28/CRCHistoPhenotypes_2016_04_28/"   #Start with the imageProcessing tutorial, then work on the nuclei_detection_tutorial, and fill in the required TODO functions in project_helpers.####################TODO 4.0 (BELOW)###################    #Train your model on 20 images. #Validate (iterate) over 20 testing images (not in the training set) and compute the average precision, recall, and F1Measure#Write each output image to disk for later review using savefig('foo.png') where foo is a distinct name for each image  #Setup the same experiment but train on the first N images with K templates per image#I suggest the following values:max_template_count = 50img_count = 30N = 3500 * img_counttemplate_img_count = 15#TODO 4.1 First get all of the templates from template_img_count images, with max_template_count maximum templates per image##template_set_many_images = ph.get_template_set(data_path,template_img_count,max_template_count)#TODO 4.2 Get all of the features for the training images, N samples per image##features_train,labels_train = ph.get_features_for_image_set(data_path,img_count,N,template_set_many_images)#Visualize our new templatesph.display_templates(template_set_many_images,VIEW)#TODO 4.3 This will take a while, time for a coffeeclassif_final,scaler_final = ph.train_model(features_train,labels_train)#New code to loop over some images and gather the resultsnum_test_images = 20#TODO 4.4 - Fill in the validate_model function, iterate over the testing images (e.g. 80-100), calculate the features, predict the detections, score the result# Keep track from the precision, recall, and F1Measure in a num_test_images by 1 array.def validate_model(num_test_images, data_path, template_set, scaler, classif):    ##    precision = np.zeros((num_test_images,1))####    recall = np.zeros((num_test_images,1))####    F1Measure = np.zeros((num_test_images,1))####    count = 0####    for idx in range(100-num_test_images,100):####        img_name = "img%.0f"%(idx)####        imgB, detectionsB, labelsB = ph.load_data_set(data_path,img_name)####        featuresImgB = ph.calculateFeatures(imgB,template_set)####        probabilityPredictionNew,predictionsBNew = ph.predict_centres(imgB,featuresImgB,scaler,classif)####        precision_local,recall_local,F1Measure_local,tmp = ph.score_detector(detectionsB,predictionsBNew)####        precision[count] = precision_local####        recall[count] = recall_local####        F1Measure[count] = F1Measure_local####        count = count +1##    print("Precision %f +/- %f; Recall %f +/- %f; F1Measure %f +/- %f"%(np.mean(precision),np.std(precision),np.mean(recall),np.std(recall),np.mean(F1Measure),np.std(F1Measure)))    #End of Function#TODO Ru4.5: Run the function for the three classifiers and evaluate the resultprint("Basic model, one template")##validate_model(num_test_images,data_path,T,scaler_oneTemplate,classif_oneTemplate)print("Basic model, many templates")##validate_model(num_test_images,data_path,templates,scaler_multipleTemplates,classif_multipleTemplates)print("Final model")##validate_model(num_test_images,data_path,template_set_many_images,scaler_final,classif_final)###################        #TODO DONE (ABOVE)###################