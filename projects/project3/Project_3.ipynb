{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "swWt6ngbZbAQ",
        "hPBRCFMUS3-W",
        "Wm2-b5b4ZkbK",
        "X7kZTFKuddYV",
        "NT6kGuNEZ9Eo",
        "-yYdGwfNhw1F",
        "_JqQs1EObfOb",
        "ZH3cviZ9qVVT",
        "yKk471KciFR6",
        "JMKPmPgPlDj_",
        "GwiAxX0Zd5p2",
        "MMAw7GVRd_Dn",
        "pnB6p0gdeDXe",
        "VZ_HiddyiJ3R",
        "ucjYEWYkhVkM",
        "_SMdu4DqhY0P",
        "be95MxaQhcOw",
        "7-UJSAEgwdZp"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swWt6ngbZbAQ"
      },
      "source": [
        "# Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PhysioNet is a widely-used repository of biomedical data and software. It enables researchers around the world to share and reuse resources that underpin clinical studies, promoting reproducible research and lowering barriers to data access. Each year, PhysioNet hosts a challenge in which researchers and hobbyists can compete to see who can create the most accurate models for a given problem, with previous challenges including sleep apnea detection and heart sound classification (https://physionetchallenges.org/).\n",
        "\n",
        "For this project, you will train a basic machine learning model that is capable of solving the task from the 2019 PhysioNet Challenge on sepsis prediction. Early detection and treatment of sepsis are critical for improving sepsis outcomes, where each hour of delayed treatment has been associated with roughly an 4–8% increase in mortality [1, 2]. The challenge gave people access to a dataset containing demographic information, vital signs, and lab reports. Your model will load this data, split it into separate groups for different purposes, and then train and evaluate your model."
      ],
      "metadata": {
        "id": "7RX3dqMGTYJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1] Kumar, A., Roberts, D., Wood, K.E., Light, B., Parrillo, J.E., Sharma, S., Suppes, R., Feinstein, D., Zanotti, S., Taiberg, L. and Gurka, D., 2006. Duration of hypotension before initiation of effective antimicrobial therapy is the critical determinant of survival in human septic shock. Critical care medicine, 34(6), pp.1589-1596.\n",
        "\n",
        "[2] Seymour, C.W., Gesten, F., Prescott, H.C., Friedrich, M.E., Iwashyna, T.J., Phillips, G.S., Lemeshow, S., Osborn, T., Terry, K.M. and Levy, M.M., 2017. Time to treatment and mortality during mandated emergency care for sepsis. New England Journal of Medicine, 376(23), pp.2235-2244.\n"
      ],
      "metadata": {
        "id": "lJqsUtjMT9gy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What to Submit"
      ],
      "metadata": {
        "id": "hPBRCFMUS3-W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please go through the notebook and complete any of the code blocks marked `# TODO`. To get full credit for this assignment, we should be able to run your entire notebook without any errors. To check this, go to \"Runtime\" > \"Run all\" in the Google Colab menu. We realize this will take a while, but we want to make sure everything can be run."
      ],
      "metadata": {
        "id": "wOX30k9UFOlU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wm2-b5b4ZkbK"
      },
      "source": [
        "# Part 1: Preparing for the Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Required Reading Materials"
      ],
      "metadata": {
        "id": "LinUS0NhUTWg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should also read the details of the challenge at https://physionet.org/challenge/2019/.\n",
        "Pay particular attention to what kind of data you will be working with and what the objective of the challenge is.\n"
      ],
      "metadata": {
        "id": "0qOBvSLsdXvR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional Reading Materials"
      ],
      "metadata": {
        "id": "X7kZTFKuddYV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine learning is a vast and deep topic, and this assignment will only scratch the surface.\n",
        "Although you should be able to complete this assignment strictly by following our instructions, it may help to read through some materials to familiarize yourself with important concepts.\n",
        "There are hundreds of blogs, videos, and online courses that people use to learn about machine learning.\n",
        "Here are a couple of our favorites:\n",
        "* [Jason Mayes' Machine Learning 101](https://docs.google.com/presentation/d/1kSuQyW5DTnkVaZEjGYCkfOxvzCqGEFzWBy4e9Uedd9k)\n",
        "* [Machine Learning Mastery](https://machinelearningmastery.com/start-here/)\n",
        "\n",
        "If you would prefer to look at academic materials, we recommend going through Roger Grosse's course notes for CSC321: http://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/.\n",
        "These particular materials may be of interest:\n",
        "* [CSC411 Intro](http://www.cs.toronto.edu/~rgrosse/courses/csc411_f18/slides/lec01-slides.pdf): What is machine learning, history of machine learning\n",
        "* [CSC321 Lecture 2 Slides](http://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/readings/L02\\%20Linear\\%20Regression.pdf): Fitting polynomials (useful visualization), generalization\n",
        "* [CSC321 Lecture 2 Notes](http://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/readings/L02\\%20Linear\\%20Regression.pdf): Generalization\n",
        "* [CSC321 Lecture 3 Notes](http://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/readings/L03\\%20Linear\\%20Classifiers.pdf): Section 1, intro paragraph of 2."
      ],
      "metadata": {
        "id": "LBPekSqrUQ6w"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT6kGuNEZ9Eo"
      },
      "source": [
        "## Package Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will need to take advantage of numerous software packages that will give us access to functions that will make our lives easier. You have already seen one of these packages (`numpy`) in a previous assignment, but the full list is below:\n",
        "* [`numpy`](https://numpy.org/) provides efficient implementations of many math operations, particularly ones that involve arrays and matrices.\n",
        "* [`pandas`](https://pandas.pydata.org) is an extremely useful library for working with data, especially when your data can be organized into tables (e.g., a `.csv` or `.xlsx` file).\n",
        "* [`scikit-learn`](https://scikit-learn.org/stable/index.html) is a tool for data mining, data analysis and machine learning.\n",
        "* [`imbalanced-learn`](https://github.com/scikit-learn-contrib/imbalanced-learn) contains functions to help you work with imbalanced data.\n",
        "* [`cache-em-all`](https://pypi.org/project/cache-em-all/) will allow us to save the result of a function so that it will only take a long time the first time you call it. In other words, `cache-em-all` allows you to save the result of the function so that it only takes 5 minutes the first time the function is called; whenever you call it again, it will only take a couple of seconds to load the saved result. This package was created by a TA from a previous iteration of the course.\n",
        "\n",
        "`numpy`, `pandas`, and `scikit-learn` are some of the most popular ones for doing data science with Python, so getting familiar with these packages would be a good idea for both this assignment and any future projects you might do on your own.\n",
        "\n",
        "If you are running your program on a local computer, you will need to install these packages yourself.\n",
        "Google Colab will already have some of these packages pre-installed, but we will confirm this and install the missing packages by running the following command:"
      ],
      "metadata": {
        "id": "NAWXB-ypUipp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SluQMiBvaNlf"
      },
      "source": [
        "!pip install scikit-learn numpy pandas cache-em-all imbalanced-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is not Python code, but rather a `bash` command that you would normally run in a local terminal."
      ],
      "metadata": {
        "id": "0A0TPdFmjgic"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcknqoGYaEkV"
      },
      "source": [
        "# Part 2: Loading the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the Data"
      ],
      "metadata": {
        "id": "-yYdGwfNhw1F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One way you could get the into your program would be to download the `.zip` file(s) provided by the challenge website, extract their contents, and then putting those files in the working directory of your code. However, this is time-consuming and would require you to repeat the process if the data were to change. What we can do instead is run `bash` commands to directly download the data programmatically:"
      ],
      "metadata": {
        "id": "IEo9TDd1hz4R"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AH3gIwV-aJpR"
      },
      "source": [
        "!wget -nc https://archive.physionet.org/users/shared/challenge-2019/training_setA.zip\n",
        "!unzip -n training_setA.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the code block below to import all of the software packages we will want to use throughout our program:"
      ],
      "metadata": {
        "id": "UbIUCxvJkPn-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTDD1_yCGerU"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GroupKFold, StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from cache_em_all import Cachable\n",
        "\n",
        "DATA_DIR = \"training\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `DataFrames` in `Pandas`"
      ],
      "metadata": {
        "id": "Vv4sbZvCodVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `pandas` library has a special data structure called a `DataFrame` It is very similar to a table in that it has rows and columns, and each column can have a name assigned to it. We can create a `DataFrame` in many different ways, but for the sake of this example, we will manually create one with random values:"
      ],
      "metadata": {
        "id": "PVv_QmO8h5Mm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an example\n",
        "np.random.seed(0)\n",
        "df = pd.DataFrame(np.random.rand(6,3), columns=['hemoglobin', 'bilirubin', 'uric acid'])"
      ],
      "metadata": {
        "id": "BlEU9Ue2omL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to a dictionary, you can access specific columns within the `DataFrame` by putting a column name or a list of column names within square brackets:"
      ],
      "metadata": {
        "id": "htyYBePpooWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an example\n",
        "df[\"bilirubin\"] # Retrieves one column\n",
        "df[[\"hemoglobin\", \"bilirubin\"]] # Retrieves multiple columns"
      ],
      "metadata": {
        "id": "5xeRqFr0opAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can take this a step further to assign values to all the rows of a given column. For example, the following code converts the hemoglobin values from g/dL to g/L by multiplying them by a factor of 10:"
      ],
      "metadata": {
        "id": "GVV4A28Sopd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an example\n",
        "df[\"hemoglobin\"] = df[\"hemoglobin\"] * 10"
      ],
      "metadata": {
        "id": "aS1S_nJLoqIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also create new columns with a default value for all of the rows.\n",
        "In this example, we have created a new column for people's mood with the default value `\"happy\"`:"
      ],
      "metadata": {
        "id": "QdAw0ylgoq8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an example\n",
        "df[\"mood\"] = \"happy\""
      ],
      "metadata": {
        "id": "uKEkr71uorfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each row is assigned an numerical **index** value. By default, each row's index is the same as its row number (i.e., the first row has an index of 0, the second row has an index of 1, etc). However, this may not always be true since there may be situations when you need to either index your rows differently or shuffle your rows while keeping track of their original position. You can access specific rows of a `DataFrame` using either its assigned label in the `DataFrame` (with the method `.loc[]`) or its positional index (with the method `.iloc[]`):"
      ],
      "metadata": {
        "id": "SgT1taeyo9JG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an example\n",
        "df.loc[0] # The first row in df\n",
        "df.iloc[0] # The row in df with the index 0"
      ],
      "metadata": {
        "id": "EXGRa7z6o971"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the purposes of this assignment, you should just be aware that each row is associated with a numerical index."
      ],
      "metadata": {
        "id": "DSvVsD-SpOJr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JqQs1EObfOb"
      },
      "source": [
        "## Loading a Single File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksFs6JObcZd7"
      },
      "source": [
        "We will first create a helper function called `load_single_file()` that will load a single file from the dataset folder that you just created.  These files are in the `.psv` format. Just like how a `.csv` file contains values separated by commas (`,`), a `.psv` file contains values separated by pipes (`|`). Your function should return a `DataFrame` after doing the following:\n",
        "\n",
        "* Read in a file using the `pandas` function `read_csv()`. As its name suggests, this function typically expects values to be separated by commas; however, the optional `sep` argument enables us to specify the character that the file uses to separate values. Here is an example of this function being used for a `.psv` file: `df = pd.read_csv(\"training/p00001.psv\", sep=\"|\")`\n",
        "\n",
        "* Create a new column called `patient` that contains the name of the file from which we retrieved this data. We will use the file name as a sort of patient ID to keep track of which rows belong to which patient.\n",
        "\n",
        "* Create a column called `hour` that represents when each row was collected. You may recall from the challenge description that each row in the file represents an hour. This means that we can use the row number (or index) to as the hour value for each row: `df[\"hour\"] = df.index`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnRsq2xnGer9"
      },
      "source": [
        "def load_single_file(file_path):\n",
        "    # TODO: Write your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your function here"
      ],
      "metadata": {
        "id": "LqD3hY2a-IeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading All of the Data"
      ],
      "metadata": {
        "id": "ZH3cviZ9qVVT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwYUi4EIjTic"
      },
      "source": [
        "Now that we can read one file, we will write a helper function called `load_data()` that will read all of the data files and put them into a single `DataFrame`. One way we could do this is by continuously appending rows to a single `DataFrame`, but that is very slow. Instead, what we will do is read each file in our dataset, append the resulting `DataFrame` to a list, and then use the `pandas` function `concat()` to concatenate the list of `DataFrames` into a single one. Here are the steps your function should follow:\n",
        "\n",
        "* Get a list of all the filenames in the dataset using the `get_data_files()` function we have provided.\n",
        "* Call the `load_single_file()` helper function you wrote earlier on each filename in that list and append the result to a list.\n",
        "* Use the function `pd.concat()` to combine the `DataFrames`. Note that this is only possible because each `DataFrame` in the list has the same columns.\n",
        "* Pre-process the data using the `clean_data()` function we have provided.\n",
        "\n",
        "Once you are sure this function is working correctly, you can uncomment the `@Cachable(\"data.csv\")` line above the function. The next time you run the function, its result will be saved and subsequent calls to the function will load the saved data. If you realize there was a mistake in your implementation and you have to fix it, you will need to delete the `cache` folder; otherwise, your fixed code will not be called and the old saved data will still be returned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB0COxqnGesE"
      },
      "source": [
        "# Names of all columns in the data that contain physiological data\n",
        "physiological_cols = ['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2',\n",
        "       'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN',\n",
        "       'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct',\n",
        "       'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium',\n",
        "       'Bilirubin_total', 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC',\n",
        "       'Fibrinogen', 'Platelets']\n",
        "\n",
        "# Names of all columns in the data that contain demographic data\n",
        "demographic_cols = ['Age', 'Gender', 'Unit1', 'Unit2', 'HospAdmTime', 'ICULOS']\n",
        "\n",
        "# The combination of physiological and demographic data is what we will use as features in our model\n",
        "feature_cols = physiological_cols + demographic_cols\n",
        "\n",
        "# The name of the column that contains the value we are trying to predict\n",
        "label_col = \"SepsisLabel\"\n",
        "\n",
        "# Pre-calculated means and standard deviation of all physiological and demographic columns. We will use this to normalize\n",
        "# data using their z-score. This isn't as important for simpler models such as random forests and decision trees,\n",
        "# but can result in significant improvements when using neural networks\n",
        "physiological_mean = np.array([\n",
        "        83.8996, 97.0520,  36.8055,  126.2240, 86.2907,\n",
        "        66.2070, 18.7280,  33.7373,  -3.1923,  22.5352,\n",
        "        0.4597,  7.3889,   39.5049,  96.8883,  103.4265,\n",
        "        22.4952, 87.5214,  7.7210,   106.1982, 1.5961,\n",
        "        0.6943,  131.5327, 2.0262,   2.0509,   3.5130,\n",
        "        4.0541,  1.3423,   5.2734,   32.1134,  10.5383,\n",
        "        38.9974, 10.5585,  286.5404, 198.6777])\n",
        "physiological_std = np.array([\n",
        "        17.6494, 3.0163,  0.6895,   24.2988, 16.6459,\n",
        "        14.0771, 4.7035,  11.0158,  3.7845,  3.1567,\n",
        "        6.2684,  0.0710,  9.1087,   3.3971,  430.3638,\n",
        "        19.0690, 81.7152, 2.3992,   4.9761,  2.0648,\n",
        "        1.9926,  45.4816, 1.6008,   0.3793,  1.3092,\n",
        "        0.5844,  2.5511,  20.4142,  6.4362,  2.2302,\n",
        "        29.8928, 7.0606,  137.3886, 96.8997])\n",
        "demographic_mean = np.array([60.8711, 0.5435, 0.0615, 0.0727, -59.6769, 28.4551])\n",
        "demographic_std = np.array([16.1887, 0.4981, 0.7968, 0.8029, 160.8846, 29.5367])\n",
        "\n",
        "def get_data_files():\n",
        "    return [os.path.join(DATA_DIR, x) for x in sorted(os.listdir(DATA_DIR)) if int(x[1:-4]) % 5 > 0]\n",
        "\n",
        "def clean_data(data):\n",
        "    data.reset_index(inplace=True, drop=True)\n",
        "\n",
        "    # Normalizes physiological and demographic data using z-score.\n",
        "    data[physiological_cols] = (data[physiological_cols] - physiological_mean) / physiological_std\n",
        "    data[demographic_cols] = (data[demographic_cols] - demographic_mean) / demographic_std\n",
        "\n",
        "    # Maps invalid numbers (NaN, inf, -inf) to numbers (0, really large number, really small number)\n",
        "    data[feature_cols] = np.nan_to_num(data[feature_cols])\n",
        "\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @Cachable(\"data.csv\")\n",
        "def load_data():\n",
        "    # TODO: Write your code here"
      ],
      "metadata": {
        "id": "KwE4Ri0pQXHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your function here"
      ],
      "metadata": {
        "id": "3UaAj2O9QeB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Exploration"
      ],
      "metadata": {
        "id": "yKk471KciFR6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsuBjukFkgsH"
      },
      "source": [
        "Once you have loaded the data, run the following commands to understand some high-level characteristics of your dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GbE8cmwkoum"
      },
      "source": [
        "# This is an example\n",
        "df = load_data()\n",
        "print(\"Column names:\", df.columns)\n",
        "print(\"Number of samples:\", len(df))\n",
        "print(\"Distribution of sepsis vs. non-sepsis samples:\", df[\"SepsisLabel\"].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moving forward, we will consider all of the columns other than the patient ID to be our **features** (the inputs to our model) and our **label** (the desired output of our model) to be `SepsisLabel`. Because we are working with data that has labels, we will be using a type of learning called **supervised learning**. More specifically, we are trying to predict an output $y$ given an input $X$ and we have examples of $(X, y)$ pairs that we can use to train our system. This is in contrast to **unsupervised learning** where we would only have $X$ at our disposal.\n",
        "\n",
        "There are two types of tasks within supervised learning: **regression** and **classification**. Regression involves continuous labels like white blood cell count or the price of a house. Classification involves discrete labels like healthy/sick or cat/dog/bird; the different possible values that a discrete label can take for a given problem are known as **classes**. We will be doing binary (2-class) classification in this assignment."
      ],
      "metadata": {
        "id": "RcJQdt2Hv3vH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMKPmPgPlDj_"
      },
      "source": [
        "# Part 3: Machine Learning Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting the Data"
      ],
      "metadata": {
        "id": "GwiAxX0Zd5p2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want the model we train to be able to produce accurate predictions on data it has not seen before. One way we can do this is by splitting our data into two sets: (1) a **training dataset** that we use to train the model, and (2) a **test set** that will only be used to evaluate the model. The `scikit-learn` library provides a function called `train_test_split()` that splits data into train and test splits for us:"
      ],
      "metadata": {
        "id": "xrkDOhTcd7j6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an example\n",
        "train_df, test_df = train_test_split(df, test_size=0.2)"
      ],
      "metadata": {
        "id": "ZZhvfiTKePZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The parameter `test_size` is the proportion of data that should be used for the test set. In this example, 20% of the data goes to the test set `test_df`, which means the remaining 80% goes to the training set `train_df`."
      ],
      "metadata": {
        "id": "HLF4I5j3eQSR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a Classifier"
      ],
      "metadata": {
        "id": "MMAw7GVRd_Dn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have $X$ and $y$ for both the train and test sets, we are finally ready to create a classifier. There are many different types of classifiers available in `scikit-learn`, but we will start with a decision tree classifier. Look through the [online documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) for `DecisionTreeClassifier` and complete the following steps for `train_simple()`:\n",
        "\n",
        "* Separate the features and the labels for both `train_df` and `test_df`. For your convenience, some of the code your ran earlier has variables called `feature_cols` and `label_col`.\n",
        "\n",
        "* Create a new instance of the `DecisionTreeClassifier` with `class_weight=\"balanced\"`.\n",
        "\n",
        "* Pass the training data through the classifier so it can identify the best structure and model weights that will maximize its accuracy; this process is often known as **fitting**.\n",
        "\n",
        "* Use your trained model to **predict** labels for the training features.\n",
        "\n",
        "* Use the `evaluate()` function we have provided to print out accuracy metrics that explain how often the predicted labels matched the expected labels.\n",
        "\n",
        "* Repeat the previous two steps using the test dataset."
      ],
      "metadata": {
        "id": "_Xutu8SSe8re"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(actual, predicted, prefix=\"\"):\n",
        "  \"\"\"\n",
        "  Compares the predicted labels to the actual lables and prints out multiple metrics\n",
        "  of classification performance: precision, recall, and overall accuracy\n",
        "\n",
        "  actual corresponds to the ground truth labels that were in the collected dataset\n",
        "  predicted corresponds to the labels that were predicted by the model\n",
        "  prefix is a string you can use to specify which data or model corresponds to the given analysis\n",
        "\n",
        "  \"\"\"\n",
        "  precision = precision_score(actual, predicted)\n",
        "  recall = recall_score(actual, predicted)\n",
        "  accuracy = accuracy_score(actual, predicted)\n",
        "\n",
        "  print(\"%s Precision: %.3f%%, Recall: %.3f%%, Accuracy: %.3f%%\" % (prefix, precision * 100, recall * 100, accuracy * 100))"
      ],
      "metadata": {
        "id": "laGk011P8zHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wq5emY6kpgc"
      },
      "source": [
        "def train_simple(data, feature_cols, label_col):\n",
        "    # TODO: Write your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your function here"
      ],
      "metadata": {
        "id": "k2heHZHLL6hO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making Your Results Repeatable"
      ],
      "metadata": {
        "id": "pnB6p0gdeDXe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What happens if you run `train_simple()` multiple times? The results are not consistent because there are multiple parts of our code that rely on randomness: how we split the data into training and test sets, how the model fits itself to training data, etc. Inconsistent results make it hard to replicate our work, so we should have a way to be able to produce the same result every time.\n",
        "\n",
        "Many random number generators are not truly random; they are actually pseudorandom in that they generate numbers based on a **seed**. Therefore, if we set the value of the seed, we can control the sequence of random numbers the generator produces. We can do this by using the following lines of code:"
      ],
      "metadata": {
        "id": "MIGn4sXug2-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an example\n",
        "seed = 9001\n",
        "np.random.seed(seed)"
      ],
      "metadata": {
        "id": "oLn9XymNg9-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can set the value of your random seed to be whatever you want; as long as you keep the seed the same, your program should produce the same results. These lines of code should be ran before any part of your program that involves randomness. We recommend putting it next to the `import` statements from the first part of the assignment. We also need to pass this seed to the `train_test_split()` function:"
      ],
      "metadata": {
        "id": "7BBv_5bLg9Pn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an example\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=seed)"
      ],
      "metadata": {
        "id": "Bh5fjYgrhJji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Re-run your `train_simple()` function multiple times to make sure it produces the same results each time."
      ],
      "metadata": {
        "id": "rX48T4OxhL0j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 4: Improving Your Pipeline"
      ],
      "metadata": {
        "id": "VZ_HiddyiJ3R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dealing with Overfitting"
      ],
      "metadata": {
        "id": "ucjYEWYkhVkM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How well does the model work on the training dataset? How about on the test dataset? The model likely worked better on the training data for a variety of reasons. The test dataset may have some rows that are completely different from what was used to train the model, which would lead to a higher chance of misclassification. The model might also be memorizing the training data so well that it lacks the flexibility to generalize to unseen data that is roughly similar; we call this phenomenon **overfitting**.\n",
        "\n",
        "One way of addressing overfitting is by tuning the complexity of the model. A model that is too simple may not have enough flexibility to capture the complex nature of the dataset, while a model that is too complicated may be so flexible that it can memorize the dataset; the best model will often lie between these two extremes. For the decision tree classifier, the model complexity is dictated by the width and depth of the decision tree, which we can control as follows:"
      ],
      "metadata": {
        "id": "Mh3qCFkzhkEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an example\n",
        "clf = DecisionTreeClassifier(class_weight=\"balanced\", max_depth=20, max_leaf_nodes=20)"
      ],
      "metadata": {
        "id": "ou7r2ZfBhq7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try different values for the model complexity parameters in your `train_simple()` implementation. We suggest varying those parameters in increments of 10 and looking for general trends; otherwise, you may overoptimize the complexity of your model for your particular data split."
      ],
      "metadata": {
        "id": "ya9thExhhqiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dealing with Class Imbalance"
      ],
      "metadata": {
        "id": "_SMdu4DqhY0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that there is a significant difference between the number of positive (`SepsisLabel = 1`) and negative examples (`SepsisLabel = 0`) in our dataset. When a dataset is significantly imbalanced, classifiers may become biased because there are too few examples of a particular class.\n",
        "\n",
        "Within the `DecisionTreeClassifier`, we can set `class_weight=\"balance\"` to tell the classifier to weigh classes according to how many examples there are in the training data. For example, if there are twice as many negative examples than positive examples, the classifier will consider incorrect predictions on positive examples twice as bad as a incorrect predictions on negative examples while training.\n",
        "\n",
        "Another way to deal with class imbalance is by adjusting how the data is sampled. In this case, we are going to **undersample** the data, which means that were are going to keep all of the data in the minority class and decreasing the size of the majority class. The alternative would be **oversampling**, which means that we would be keeping the size of the majority class and repeating examples in the minority class. In your `train_simple()` implementation, use the `RandomUnderSampler` from `imbalanced-learn` to undersample the training data before you fit your model:"
      ],
      "metadata": {
        "id": "BZIQVJzEj6iE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an example\n",
        "rus = RandomUnderSampler(random_state=seed)\n",
        "X_train, y_train = rus.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "St68F5bBkXUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Better Cross Validation"
      ],
      "metadata": {
        "id": "be95MxaQhcOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous section, we split the data into training and test sets to see how well our model would generalize to unseen data. However, those splits were not as independent as they should be. The `train_test_split()` function randomly splits the rows in the dataset, but multiple rows belong to same patient. This means that data from patient $P_1$ can appear in both the training and test datasets.\n",
        "If that happens, the model is essentially \"peeking at the answers\" ahead of time, so even if a model has high accuracy on the test dataset, we cannot argue that it will work for other unseen patients.\n",
        "\n",
        "To fix this issue, we will split our data using a variant of **$k$-fold cross-validation**. A typical $k$-fold cross-validation procedure goes as follows:\n",
        "\n",
        "* Rather than splitting the data into a single pair of training and testing sets, we split the data into $k$ number of sets (called **folds**) of equal size.\n",
        "* For each fold, we do the following:\n",
        "\n",
        "  * We select one fold to hold out as the test set and use the remaining $k-1$ folds collectively as the training set.\n",
        "  * We fit a model on the training set and evaluate on the test set as we would normally do.\n",
        "  * We save the prediction results for the training and test datasets, but we discard the model.\n",
        "\n",
        "* At this point, all of the folds will have been the test set at least once, which means we will have a prediction for each sample. We can therefore calculate the performance of our modeling approach the same way as we did before.\n",
        "\n",
        "This still does not solve our problem of maintaining independence, which is why we need to use a variant of $k$-fold cross-validation. We will stratify our data according to the `patient` column before we split it into folds so that rows from the same patient can only appear in one fold. `scikit-learn` has an object called `GroupKFold` that will do this for us:"
      ],
      "metadata": {
        "id": "wx6m0xuuk03Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an example\n",
        "X = data[feature_cols]\n",
        "y = data[label_col]\n",
        "group = data[stratify_col]\n",
        "kf = GroupKFold(n_splits=5)\n",
        "kf.split(X, y, group)"
      ],
      "metadata": {
        "id": "NLGSfWzAwLEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have implemented the skeleton for a stratified 5-fold cross-validation procedure in `train_stratified()`. Your job is to complete this function by writing code that trains a classifier within the loop. You may re-use your `train_simple()` function as you see fit.\n",
        "\n",
        "When this function is complete and you run it, you should expect to see a drop in accuracy since you are no longer \"cheating\" during model training; nevertheless, this is a more accurate representation of how well your approach will be able to generalize for unseen patients."
      ],
      "metadata": {
        "id": "9GKoGt85wMGZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfKfUvyzGesW"
      },
      "source": [
        "def train_stratified(data, feature_cols, label_col, stratify_col):\n",
        "    X = data[feature_cols]\n",
        "    y = data[label_col]\n",
        "    group = data[stratify_col]\n",
        "\n",
        "    train_pred = []\n",
        "    train_actual = []\n",
        "\n",
        "    test_pred = []\n",
        "    test_actual = []\n",
        "\n",
        "    kf = GroupKFold(n_splits=5)\n",
        "    for train_idx, test_idx in kf.split(X, y, group):\n",
        "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
        "        X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
        "\n",
        "        # TODO: Implement your classifier here\n",
        "\n",
        "        train_pred.extend(clf.predict(X_train))\n",
        "        train_actual.extend(y_train)\n",
        "\n",
        "        test_pred.extend(clf.predict(X_test))\n",
        "        test_actual.extend(y_test)\n",
        "\n",
        "    evaluate(train_actual, train_pred, \"Train\")\n",
        "    evaluate(test_actual, test_pred, \"Test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your function here"
      ],
      "metadata": {
        "id": "Stb6kQiLJN6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 5: Putting It All Together"
      ],
      "metadata": {
        "id": "7-UJSAEgwdZp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you have written and iterated upon a pipeline for model training, it is time for you to find a configuration that maximizes cross-validated test accuracy. There are numerous aspects of the pipeline that you can tweak, but here are the easiest ones to start with:\n",
        "\n",
        "* **Model architecture:** We have been using the `DecisionTreeClassifier` in `scikit-learn`, but there are many others at your disposal. We have imported a few others that you can try — `KNeighborsClassifier`, `RandomForestClassifier`, and `MLPClassifier` — but you can also explore other ones on `scikit-learn`'s website.\n",
        "\n",
        "* **Model parameters:** We examined how adjusting the model complexity can help us avoid overfitting. As you try different models, be sure to also explore different parameters.\n",
        "\n",
        "* **Number of folds:** The skeleton we wrote for `train_stratified()` performs 5-fold cross-validation because of the parameter we passed to `GroupKFold`. What happens when you increase the number of folds to 10? What happens when you decrease the number of folds to 2 or 3?\n",
        "\n",
        "You could also improve your pipeline by looking into feature pre-processing, feature selection, and automated hyperparameter tuning. However, these topics are outside of the scope of this course. If you are interested in learning more, feel free to reach out to the instructors!\n",
        "\n",
        "The final deliverable for this assignment is a report that explains the different configurations you tried, the accuracy those configurations achieved, and written explanations of why you believe those results happened. Since there are so many configurations to choose from and each person may be splitting the data differently, we are not expecting everyone to achieve a definitive correct answer. What we are looking for is careful experimentation and viable explanations for the results of those experiments. You may find it helpful to use tables or graphs to systematically present your accuracy numbers. The report should be single-column, single-spaced, and no longer than 3 pages including tables and graphs. Save the report as either `report.pdf` or `report.docx`."
      ],
      "metadata": {
        "id": "9MqnSmW9wgbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feel free to run your experiments here"
      ],
      "metadata": {
        "id": "7VTqlsbzxPvt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}