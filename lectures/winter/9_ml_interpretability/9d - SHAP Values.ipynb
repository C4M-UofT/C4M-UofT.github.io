{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["DekAnzq1b82b","10lMoc0ds8cm","wAdiNJlTs_-P","Tp4eMkFcgpQ6","HY7Fy9_IQrXG","WOCp8z96Qp4b","RhogJfvkdyQg"],"authorship_tag":"ABX9TyMSd4nPRB5EuPIGsy3t4SCG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["In this notebook, we're going to talk about ***SHapley Additive exPlanations (SHAP)*** values. SHAP values are a model-agnostic way of calculating feature importance scores. Rather than looking at the internals of a model, they are inspired by the concept of Shapley values from cooperative game theory."],"metadata":{"id":"BDaO9cuMWe83"}},{"cell_type":"markdown","source":["# Important: Run this code cell each time you start a new session!"],"metadata":{"id":"DekAnzq1b82b"}},{"cell_type":"code","source":["!pip install numpy\n","!pip install pandas\n","!pip install matplotlib\n","!pip install os\n","!pip install scikit-learn\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","import sklearn"],"metadata":{"id":"jrO0X1ZMxMN5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn import datasets\n","from sklearn.linear_model import LinearRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squred_error, mean_absolute_error, r2_score\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","# Load the dataset\n","diabetes_dataset = datasets.load_diabetes(as_frame=True)\n","df = diabetes_dataset.frame\n","\n","# Rename the features for clarity\n","df = df.rename(columns={'s1': 'total serum cholesterol',\n","                        's2': 'low-density lipoproteins',\n","                        's3': 'high-density lipoproteins',\n","                        's4': 'total cholesterol',\n","                        's5': 'log of serum triglycerides',\n","                        's6': 'blood sugar'})"],"metadata":{"id":"bkHkGrOMm2KL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_regressor(orig_df):\n","    \"\"\"\n","    Train and test a regression model on the input DataFrame, returning the\n","    regressor, the feature names, and a dictionary of all the relevant data\n","    orig_df: the input DataFrame\n","    \"\"\"\n","    # Set random number generator so the results are always the same\n","    np.random.seed(42)\n","\n","    # Get the names of the features\n","    feature_names = df.columns.tolist()\n","    feature_names.remove('target')\n","\n","    # Split the data into train and test sets\n","    train_df, test_df = train_test_split(orig_df, test_size=0.2)\n","\n","    # Separate features from labels\n","    x_train = train_df.drop('target', axis=1).values\n","    y_train = train_df['target'].values\n","    x_test = test_df.drop('target', axis=1).values\n","    y_test = test_df['target'].values\n","\n","    # Create and train the model\n","    regr = LinearRegression()\n","    regr.fit(x_train, y_train)\n","\n","    # Use the model to predict on the test set\n","    y_pred = regr.predict(x_test)\n","\n","    # Create a nested dictionary of all the data for easier retrieval\n","    data = {'train': {'x': x_train, 'y': y_train},\n","            'test': {'x': x_test, 'y': y_test},\n","            'pred': {'x': x_test, 'y': y_pred}}\n","    return regr, feature_names, data"],"metadata":{"id":"dckQxUtmXekZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_classifier(orig_df):\n","    \"\"\"\n","    Train and test a classification model on the input DataFrame, returning the\n","    classifier, the feature names, and a dictionary of all the relevant data\n","    orig_df: the input DataFrame for regression\n","    \"\"\"\n","    # Set random number generator so the results are always the same\n","    np.random.seed(42)\n","\n","    # Copy the DataFrame since we will be modifying it\n","    df = orig_df.copy()\n","\n","    # Get the names of the features\n","    feature_names = df.columns.tolist()\n","    feature_names.remove('target')\n","\n","    # Turn the label into a binary variable\n","    df['target'] = df['target'] > 150\n","\n","    # Split the data into train and test sets\n","    train_df, test_df = train_test_split(df, test_size=0.2)\n","\n","    # Separate features from labels\n","    x_train = train_df.drop('target', axis=1).values\n","    y_train = train_df['target'].values\n","    x_test = test_df.drop('target', axis=1).values\n","    y_test = test_df['target'].values\n","\n","    # Create and train the model\n","    clf = DecisionTreeClassifier()\n","    clf.fit(x_train, y_train)\n","\n","    # Use the model to predict on the test set\n","    y_pred = clf.predict(x_test)\n","\n","    # Create a nested dictionary of all the data for easier retrieval\n","    data = {'train': {'x': x_train, 'y': y_train},\n","            'test': {'x': x_test, 'y': y_test},\n","            'pred': {'x': x_test, 'y': y_pred}}\n","    return clf, feature_names, data"],"metadata":{"id":"NdmtZ4niHtVi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# An Illustrative Example"],"metadata":{"id":"10lMoc0ds8cm"}},{"cell_type":"markdown","source":["To illustrate the intuition behind SHAP values, we will walk through a hypothetical scenario that has nothing to do with machine learning."],"metadata":{"id":"fpcIi7B41VBg"}},{"cell_type":"markdown","source":["Three friends – Alice, Bob, and Carlos – go out for a meal. They ordered and shared all of their dishes together and the bill came out to \\$900. However, they they did not eat an equal amount of food, so doing an even split of \\$300 each does not seem fair to them. How should they determine how much each person should pay?"],"metadata":{"id":"AH_kKsb2tFiv"}},{"cell_type":"markdown","source":["If each person kept track of how much they ate, then they could simply pay according to the percentage of food that they ate. However, let's assume that nobody was counting french fries or pizza slices."],"metadata":{"id":"TsIfFLaPynHS"}},{"cell_type":"markdown","source":["Instead, let's imagine that the friends talk through how much they would have collectively spent had they gone to dinner in different combinations. For example, if Alice went to dinner on her own, she would have spent \\$800, but if Alice and Carlos went together, they would have spent \\$850. Here are the outcomes of all possible combinations:\n","\n","| People | Total Cost |\n","|--------|------------|\n","| Alice | \\$800 |\n","| Bob | \\$560 |\n","| Carlos | \\$700 |\n","| Alice and Bob | \\$800 |\n","| Alice and Carlos | \\$850 |\n","| Bob and Carlos | \\$720 |\n","| Alice, Bob, and Carlos | \\$900 |\n"],"metadata":{"id":"1pDFZ_wmuM_O"}},{"cell_type":"markdown","source":["To determine the fairest split possible, we could determine how much each friend would pay if they were to be added to the group one at a time. For example, let's imagine that Alice, Bob, and Carlos were to pay in sequence. Alice would pay \\$800. Since Alice and Bob would have spent the same amount together, Bob would not need to pay anything. Once Carlos gets added, he would need to pay \\$100 to get the total to \\$900. If we were to repeat this calculation for all possible combinations of friends, we would get the following payouts:\n","\n","| Order | Payouts |\n","|-------|---------|\n","| Alice, Bob, Carlos | \\$800 + \\$0 + \\$100 |\n","| Bob, Alice, Carlos | \\$560 + \\$240 + \\$100 |\n","| Bob, Carlos, Alice | \\$560 + \\$160 + \\$180 |\n","| Carlos, Alice, Bob | \\$700 + \\$150 + \\$50 |\n","| Carlos, Bob, Alice | \\$700 + \\$20 + \\$180 |\n","| Alice, Carlos, Bob | \\$800 + \\$50 + \\$50 |"],"metadata":{"id":"1hiusLngwScP"}},{"cell_type":"markdown","source":["To determine how much each friend should pay, we would take the average of how much they would have spent across all possible scenarios:\n","\n","| Friend | Fair Payment |\n","|--------|-----------|\n","| Alice | (\\$800 + \\$240 + \\$180 + \\$150 + \\$180 + \\$800) / 6 = \\$392 |\n","| Bob | (\\$0 + \\$560 + \\$560 + \\$50 + \\$20 + \\$50) / 6 = \\$207 |\n","| Carlos | (\\$100 + \\$100 + \\$160 + \\$700 + \\$700 + \\$50) / 6 = \\$302 |\n","\n","Conveniently enough, the total of these payments ends up being \\$900 with a bit of rounding error."],"metadata":{"id":"16Szh_63yiG_"}},{"cell_type":"markdown","source":["# Translating the Illustrative Example to Machine Learning"],"metadata":{"id":"wAdiNJlTs_-P"}},{"cell_type":"markdown","source":["In our toy example, the friends represent features and the total bill represents the prediction to which they are contributing. If we knew how much each feature contributed to the prediction (i.e., how much each person ate), we would have been able to figure out their contributions directly. This would be the equivalent of inspecting the internals of the model."],"metadata":{"id":"Dx3hIrqD0ROE"}},{"cell_type":"markdown","source":["Instead, SHAP values allow us to treat the model as a black box. We simulate generating predictions using different combinations of features, and we use those results to calculate the contribution of each feature in the final prediction."],"metadata":{"id":"oDh44EGq_Ygw"}},{"cell_type":"markdown","source":["Here are the steps for calculating the SHAP value for a single feature $F$:\n","\n","1. Create the set of all possible feature combinations called coalitions.\n","2. Calculate the model's average prediction across the entire training dataset. For a classification problem, the prediction is a continuous probability between 0 and 1. For a regression problem, the prediction is a continuous output variable.\n","3. For each coalition, calculate the difference between the model's prediction without $F$ and the average prediction.\n","4. For each coalition, calculate the difference between the model's prediction with $F$ and the average prediction.\n","5. For each coalition, calculate how much $F$ changed the model's prediction from the average (i.e., step 4 - step 3). This is the marginal contribution of F.\n","5. The SHAP value for $F$ is the average of all the values calculated in step 5 (i.e., the average of $F$'s marginal contributions)"],"metadata":{"id":"rmxWipdCjT3Y"}},{"cell_type":"markdown","source":["Fortunately, we don't have to do this math ourselves. The `shap` library provides everything you need to calculate SHAP values for most models that are built with `scikit-learn`."],"metadata":{"id":"DsB3_R6y_b-N"}},{"cell_type":"code","source":["!pip install shap\n","import shap"],"metadata":{"id":"PwKtexgG_ipT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["SHAP values can either be generated to explain predictions on any subset of data: the training set, the test set, etc. However, we would be answering different questions about our model depending on which one we choose.\n","\n","Looking at the training set would allow us to learn more about what the model learned, while looking at the test set would allow us to learn more about how the model will make decisions on unseen data. In the examples below, we will focus on the latter because it will better illustrate how SHAP values can provide interpretable explanations for model decisions."],"metadata":{"id":"4Vren37ZwwCL"}},{"cell_type":"markdown","source":["# Visualizing SHAP Values for Individual Predictions (Regression)"],"metadata":{"id":"Tp4eMkFcgpQ6"}},{"cell_type":"markdown","source":["One of the great things about SHAP values is that we can use them to explain how each feature contributes to a single prediction. This would allow us to answer questions like \"Why did the model make this prediction for this specific input?\"."],"metadata":{"id":"ttatBg77eZ9n"}},{"cell_type":"markdown","source":["Let's pretend that we want to see how each feature contributed to the prediction made on the first sample in the test set. To start, we will calculate the SHAP values associated with all of the samples in our test set:"],"metadata":{"id":"MmXGAL67nf4F"}},{"cell_type":"code","source":["# Get the regression model and its relevant information\n","regr, feature_names, data = generate_regressor(df)\n","x_test = data['test']['x']\n","\n","# Generate the SHAP explainer\n","explainer = shap.Explainer(regr, x_test, feature_names=feature_names)\n","\n","# Apply the SHAP explainer on our test set\n","shap_values = explainer(x_test)\n","\n","print(f'Shape of the test set: {x_test.shape}')\n","print(f'Shape of the SHAP values: {shap_values.shape}')"],"metadata":{"id":"dNurzXzWellJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["There are a couple of different ways we can visualize these SHAP values. We'll first look at a waterfall plot:"],"metadata":{"id":"ySQF0SYAPOeC"}},{"cell_type":"code","source":["shap.plots.waterfall(shap_values[0])"],"metadata":{"id":"amJPdYt1PIKA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here is how we should interpret this graph:\n","* The average prediction of the model across the entire dataset is denoted at the bottom at $E[f(X)]$, also known as the expected value of the model.\n","* The prediction for this particular example is listed at the top as $f(X)$.\n","* The feature values associated with the sample we are investigating are shown along the left side of the screen. Remember that our features are normalized between -0.2 and 0.2, which is why some of the values seem a bit weird.\n","* The red and blue arrows within the graph indicate how each feature moves the prediction from the average prediction to the final result. Red arrows indicate positive contributions that increase the final result, and blue arrows indicate negative contributions that decrease the final result.\n","* The features are ordered from top-to-bottom in terms of the magnitude of their contribution."],"metadata":{"id":"wDRxElrGPct5"}},{"cell_type":"markdown","source":["The second graph will be a force graph, which shows similar information but on a single line. Unfortunately, this graph will not be very readable because we used long feature names, but hopefully you can see how it presents mostly the same information."],"metadata":{"id":"5FRmLsGOPGgj"}},{"cell_type":"code","source":["shap.force_plot(explainer.expected_value, shap_values.values[0],\n","                features=x_test[0], feature_names=feature_names, matplotlib=True)"],"metadata":{"id":"mN4atAUwPKQW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["So what can we learn from these graphs?\n","* It seems that total serum cholesterol has the biggest influence on the prediction for this sample, and it drives the prediction to be much lower than it would have been otherwise.\n","* Low-density lipoproteins and the log of serum triglycerides also have moderately strong, negative contributions on teh prediction.\n","* Features like age, BMI, and blood sugar seem to be negligible in this case."],"metadata":{"id":"aJmjqUxzqYTC"}},{"cell_type":"markdown","source":["# Visualizing SHAP Values for an Entire Dataset (Regression)"],"metadata":{"id":"HY7Fy9_IQrXG"}},{"cell_type":"markdown","source":["Looking at the SHAP values associated with an individual prediction is great, but different features might have different contributions on different predictions depending on the values of the features themselves. For example, total cholesterol may be extremely important for male patients but less important for female patients."],"metadata":{"id":"5JvT8HpVooY_"}},{"cell_type":"markdown","source":["It can therefore be helpful to visualize the distribution of SHAP values for each feature across the entire test set. This would allow us to answer questions like \"Which features are generally more important to the model?\" and \"Does this feature generally have a positive or negative impact on the prediction output?\"."],"metadata":{"id":"oQ3Q8zBrpHJZ"}},{"cell_type":"code","source":["shap.summary_plot(shap_values, features=x_test, feature_names=feature_names)"],"metadata":{"id":"5B1dmsZHpqv7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here is how we should interpret this graph:\n","* As with the waterfall plot, each row corresponds to a feature.\n","* Each dot within a row represents a single sample in our dataset. Therefore, each row should have the same number of dots.\n","* The color of each dot indicates the value of each feature relative to the rest of the dataset. Red dots indicate high feature values, while blue dots indicate low feature values.\n","* The horizontal position of each dot represents the contribution that feature had on the given prediction. Dots on the left had lower predictions because of the feature value associated with that sample, while dots on the right had higher predictions for the same reason.\n","* The vertical position of each dot within a given row has no meaning; this is strictly done so that the dots are more clearly visibile.\n"],"metadata":{"id":"nHC3p_L2qJlY"}},{"cell_type":"markdown","source":["To clarify these rules further, let's iterate through some possible scenarios for feature $F$ in a sample $S$:\n","\n","| Color of the Dot | Horizontal Position of the Dot | Interpretation |\n","|------------------|--------------------------------|----------------|\n","| Blue | Left | The value of $F$ in $S$ is low, leading to a lower prediction for $S$ |\n","| Blue | Middle | The value of $F$ in $S$ is low, but it has little influence on the prediction for $S$ |\n","| Blue | Right | The value of $F$ in $S$ is low, leading to a higher prediction for $S$ |\n","| Red | Left | The value of $F$ in $S$ is high, leading to a lower prediction for $S$ |\n","| Red | Middle | The value of $F$ in $S$ is high, but it has little influence on the prediction for $S$ |\n","| Red | Right | The value of $F$ in $S$ is high, leading to a higher prediction for $S$ |\n","\n","When all of the colors are grouped together within a row, then we can be fairly confident that these trends uphold across the entire dataset."],"metadata":{"id":"HxCafLCBr3-H"}},{"cell_type":"markdown","source":["So what can we learn from this graph?\n","* Total serum cholesterol has the biggest overall influence on predictions since it has the most dots at either horizontal extreme. However, it should be observed that there are many dots near the center of the graph, indicating that the feature may not have been the most influential for all predictions.\n","* Higher total serum cholesterol values generally led to lower predictions, while lower values generally led to higher predictions.\n","* Age and blood sugar seem to be the least important features for all of our dataset since the dots are generally at the center of the graph."],"metadata":{"id":"1am6g9sOs4I6"}},{"cell_type":"markdown","source":["# Visualizing SHAP Values for Individual Predictions (Classification)"],"metadata":{"id":"WOCp8z96Qp4b"}},{"cell_type":"markdown","source":["Up until this point, we've been looking at SHAP values for our regression model. Let's generate the same graphs as before, only this time for our classification model. We'll start with the visualization of an individual prediction."],"metadata":{"id":"J8yYvjL5weZC"}},{"cell_type":"code","source":["# Get the classification model and its relevant information\n","clf, feature_names, data = generate_classifier(df)\n","x_test = data['test']['x']\n","\n","# Generate the SHAP explainer\n","explainer = shap.Explainer(clf, x_test, feature_names=feature_names)\n","\n","# Apply the SHAP explainer on our test set\n","shap_values = explainer(x_test)\n","\n","print(f'Shape of the test set: {x_test.shape}')\n","print(f'Shape of the SHAP values: {shap_values.shape}')"],"metadata":{"id":"YiUXEavGqDtE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Notice that the shape of the SHAP values array is different. This is because if a classification problem has more than two possible classes, it is important the we are able to attribute feature contributions towards each class.\n","\n","In the case of a binary classifer like the one we have, `shap_values[:, :, 0] == -shap_values[:, :, 0]` since positive contributions toward a positive prediction are the same negative contributions toward a negative prediction. We will look at the SHAP values from the perspective of the positive class since that will be more intuitive."],"metadata":{"id":"l_JNAWnj82Eo"}},{"cell_type":"code","source":["target_class = 1\n","shap.plots.waterfall(shap_values[0, :, target_class])"],"metadata":{"id":"MpVLI3ZhCn3-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target_class = 1\n","shap.force_plot(explainer.expected_value[target_class], shap_values.values[0, :, target_class],\n","                features=x_test[0], feature_names=feature_names, matplotlib=True)"],"metadata":{"id":"DgEfPhu_CqwD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Recall that the labels of our classifier simply threshold the disease progression scores at 150, so lower regression scores are correlated with \"lower\" classification outcomes. Therefore, it makes sense that we would hopefully see similar trends as we did for our regression model. For example, total serum cholesterol has the biggest influence on the prediction for this sample, and it drives the prediction to be much lower than it would have been otherwise.\n","\n","However, we also see that some of the contributions are flipped. For our regression model, low-density lipoproteins had a fairly positive contribution to our regression label, while it has a slightly negative contribtion to our classification model. This can be for a number of reasons: the structure of the models, the relative magnitude of the contributions, etc."],"metadata":{"id":"ys7jHGwiDZp7"}},{"cell_type":"markdown","source":["# Visualizing SHAP Values for an Entire Dataset (Classification)"],"metadata":{"id":"RhogJfvkdyQg"}},{"cell_type":"markdown","source":["Now let's look at the SHAP values for all of our dataset:"],"metadata":{"id":"XELEBAZ8DcyS"}},{"cell_type":"code","source":["target_class = 1\n","shap.summary_plot(shap_values[:, :, target_class], features=x_test,\n","                  feature_names=feature_names)"],"metadata":{"id":"VbQvhS_eDrLI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now things have gotten interesting. Notice that the colors of the dots are intermixed a bit more than they were with our regression model. This is primarily due to the structure of the models are using.\n","\n","With a linear regression, feature values are multiplied by fixed coefficients, so increasing the value of feature $F$ will always have a monotonic (i.e., always increasing or decreasing) impact on its contribution to the prediction. This is not the case with a decision tree classifier. Imagine the first branch in the tree splits between high and low values of $F$. Both sides of the tree are likely to have scenarios where both positive and negative outcomes are possible, so the magnitude and direction of $F$'s contribution is not as clear cut."],"metadata":{"id":"YjfRj3_HCIT-"}},{"cell_type":"markdown","source":["Still, we can see some trends that generalize across most of the dataset:\n","* Higher BMIs are more likely to lead to positive predictions\n","* Lower low-density lipoproteins tend to lead to positive predictions as well"],"metadata":{"id":"Bbg38_M4F_Zo"}}]}