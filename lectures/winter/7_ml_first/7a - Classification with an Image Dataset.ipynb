{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DekAnzq1b82b",
        "xP4sP_ekZxqW",
        "dF7vGVljaKp7",
        "ryaahUysaOHD",
        "gmMs1P1tabse",
        "90Fwfakplyu8",
        "TUuv3wRJaVer",
        "A-AcODJ3aYx6",
        "-fpM5JCVcS_c",
        "hT0cnOFdafEF",
        "WwE9unOpIbm2",
        "e87qpxdPIsga",
        "iikCuJ_eeHUj",
        "uvtSJXQxeJE9"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we're going to build a classification model that discriminates between benign and malignant skin lesions using images from the [International Skin Imaging Collaboration (ISIC) 2016](https://challenge.isic-archive.com/data/) dataset we examined in a previous session."
      ],
      "metadata": {
        "id": "BDaO9cuMWe83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will also be our first encounter with [`scikit-learn`](https://scikit-learn.org/stable/index.html) â€” the most popular Python library for building and evaluating machine learning models."
      ],
      "metadata": {
        "id": "ya0DHpuKh1He"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "import sklearn"
      ],
      "metadata": {
        "id": "AUlGQ9EpiGkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important: Run this code cell each time you start a new session!"
      ],
      "metadata": {
        "id": "DekAnzq1b82b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install os\n",
        "!pip install opencv-python\n",
        "!pip install scikit-learn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import sklearn"
      ],
      "metadata": {
        "id": "jrO0X1ZMxMN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -Ncnp https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part3_Training_Data.zip"
      ],
      "metadata": {
        "id": "bASFcdZNZuGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -n ISBI2016_ISIC_Part3_Training_Data.zip"
      ],
      "metadata": {
        "id": "2hP2UnPrcEdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -Ncnp https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part3_Training_GroundTruth.csv"
      ],
      "metadata": {
        "id": "hIBYeAPogvAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -Ncnp https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part1_Training_GroundTruth.zip"
      ],
      "metadata": {
        "id": "b3tho-Kt9q_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -n ISBI2016_ISIC_Part1_Training_GroundTruth.zip"
      ],
      "metadata": {
        "id": "Ebi3lsSm-poa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Define the Problem You Are Trying to Solve"
      ],
      "metadata": {
        "id": "xP4sP_ekZxqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a reminder, the overarching goal of the ISIC 2016 Challenge was to develop image analysis tools that automatically diagnose of melanoma from dermoscopic images. The organizers of the challenge provided collections of 1022 (w) $\\times$ 767 (h) px images gathered from distinct patients. Each image was determined to be benign or malignant based on the judgment of a clinician."
      ],
      "metadata": {
        "id": "BBrNiJenan-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The relevant folders and files associated with this dataset\n",
        "# (we will talk about some of them later)\n",
        "image_folder = 'ISBI2016_ISIC_Part3_Training_Data'\n",
        "segmentation_folder = 'ISBI2016_ISIC_Part1_Training_GroundTruth'\n",
        "label_filename = 'ISBI2016_ISIC_Part3_Training_GroundTruth.csv'"
      ],
      "metadata": {
        "id": "tjO9wyZHMg9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load two pre-selected image files to show what they look like\n",
        "benign_filename = 'ISIC_0000000.jpg'\n",
        "malignant_filename = 'ISIC_0000002.jpg'\n",
        "benign_img = cv2.imread(os.path.join(image_folder, benign_filename))\n",
        "benign_img = cv2.cvtColor(benign_img, cv2.COLOR_BGR2RGB)\n",
        "malignant_img = cv2.imread(os.path.join(image_folder, malignant_filename))\n",
        "malignant_img = cv2.cvtColor(malignant_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Show the images and their labels\n",
        "plt.figure(figsize=(6, 3))\n",
        "plt.subplot(1, 2, 1), plt.imshow(benign_img), plt.title('Benign')\n",
        "plt.subplot(1, 2, 2), plt.imshow(malignant_img), plt.title('Malignant')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nlbjx-aIDbFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because we are deciding between distinct outcome categories, we will want to create a ***classification model***. More specifically, we will be creating a binary classifier since we have 2 possible outcomes: 'negative' (benign) and 'positive' (malignant)."
      ],
      "metadata": {
        "id": "e8tQO6exj_sr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Create Your Features and Labels"
      ],
      "metadata": {
        "id": "dF7vGVljaKp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The labels for our dataset will be the diagnoses associated with each image."
      ],
      "metadata": {
        "id": "QYNa_YEfe7vi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traditional machine learning models are not able to handle raw image data. Rather, they are best suited for handling tabular data. When we first saw this image dataset, we wrote a series of functions that allowed us to summarize the visual characteristics of each skin lesion according to its asymmetry, border, color, and diameter. These numbers will serve as our features.\n",
        "\n",
        "This goes to show that knowing about machine learning is often not enough to work with real-world data. Having some domain expertise relevant to the target task can ensure that you are able to extract meaningful features from your data."
      ],
      "metadata": {
        "id": "1O2DKWI7lpOk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All of the code from our initial exploration of this dataset is copied below, so refer to that notebook if you need a reminder of how we came up with these functions."
      ],
      "metadata": {
        "id": "QvYU2W0HXJvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_contour(seg_img):\n",
        "    \"\"\"\n",
        "    Extracts the lone contour from the image annotation\n",
        "    seg_img: a binary image representing an annotation\n",
        "    \"\"\"\n",
        "    cnts, hierarchy = cv2.findContours(seg_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    return cnts[0]"
      ],
      "metadata": {
        "id": "TgSG8O2e-aY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "def flip_point(point, line_point, angle_deg):\n",
        "    \"\"\"\n",
        "    A helper function that reflects a point over an arbitrary line\n",
        "    This requires a lot of math, so don't worry if it's not intuitive\n",
        "    point: the point we are trying to reflect\n",
        "    line_point: a point that goes through the line\n",
        "    angle_deg: the angle that defines the slope of the line\n",
        "    \"\"\"\n",
        "    # Convert the angle from degrees to radians\n",
        "    angle_rad = math.radians(angle_deg)\n",
        "\n",
        "    # Calculate the coordinates of the point in a coordinate system where line_point is the origin\n",
        "    translated_point = (point[0] - line_point[0], point[1] - line_point[1])\n",
        "\n",
        "    # Rotate this coordinate system by an angle of -angle_rad\n",
        "    rotated_point = (translated_point[0]*math.cos(angle_rad) + translated_point[1]*math.sin(angle_rad),\n",
        "                     -translated_point[0]*math.sin(angle_rad) + translated_point[1]*math.cos(angle_rad))\n",
        "\n",
        "    # Reflect the point over the x-axis\n",
        "    reflected_point = (rotated_point[0], -rotated_point[1])\n",
        "\n",
        "    # Rotate the coordinate system back by an angle of angle_rad and translate back to original coordinate system\n",
        "    reflected_translated_back = (reflected_point[0]*math.cos(-angle_rad) + reflected_point[1]*math.sin(-angle_rad),\n",
        "                                 -reflected_point[0]*math.sin(-angle_rad) + reflected_point[1]*math.cos(-angle_rad))\n",
        "    final_point = (reflected_translated_back[0] + line_point[0], reflected_translated_back[1] + line_point[1])\n",
        "\n",
        "    return final_point\n",
        "\n",
        "def flip_contour(contour, center, angle_deg):\n",
        "    \"\"\"\n",
        "    A helper function reflects an entire contour over its major axis\n",
        "    contour: the contour\n",
        "    center: the center of the contour's fit ellipse\n",
        "    angle_deg: the angle of the contour's fit ellipse\n",
        "    \"\"\"\n",
        "    # Create an array to store the flipped contour points\n",
        "    flipped_contour = []\n",
        "\n",
        "    # Flip each point in the contour\n",
        "    for point in contour:\n",
        "        flipped_point = flip_point(point[0], center, angle_deg)\n",
        "        flipped_contour.append(flipped_point)\n",
        "\n",
        "    # Convert the flipped contour list to an array\n",
        "    flipped_contour = np.array(flipped_contour, dtype=np.int32).reshape(-1, 1, 2)\n",
        "\n",
        "    return flipped_contour\n",
        "\n",
        "def get_hausdorff_distance(cnt1, cnt2):\n",
        "    \"\"\"\n",
        "    A helper function to compute the Haussdorf distance between two contours\n",
        "    cnt2: the first contour\n",
        "    cnt2: the second contour\n",
        "    \"\"\"\n",
        "    pts1 = np.array(cnt1).squeeze()\n",
        "    pts2 = np.array(cnt2).squeeze()\n",
        "    distances = cdist(pts1, pts2)\n",
        "    return np.max(np.min(distances, axis=0))"
      ],
      "metadata": {
        "id": "0im5cSDimPmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_asymmetry(img, cnt):\n",
        "    \"\"\"\n",
        "    Compute the asymmetry of the skin lesion by comparing the contour with a\n",
        "    reflected version of itself\n",
        "    img: the image of the skin lesion\n",
        "    cnt: the contour of the skin lesion\n",
        "    \"\"\"\n",
        "    # Get the min enclosing ellipse\n",
        "    center, axes, angle = cv2.fitEllipse(cnt)\n",
        "\n",
        "    # Flip the contour of the ellipse's major axis\n",
        "    flipped_cnt = flip_contour(cnt, center, -angle)\n",
        "\n",
        "    # Measure the difference between the two contours as the Haussdorff distance\n",
        "    distance = get_hausdorff_distance(cnt, flipped_cnt)\n",
        "\n",
        "    # Scale the distance according to the diameter for fair comparison\n",
        "    _, r = cv2.minEnclosingCircle(cnt)\n",
        "    d = 2*r\n",
        "    return distance / d"
      ],
      "metadata": {
        "id": "FNZOOcXsdISL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_border(cnt):\n",
        "    \"\"\"\n",
        "    Compute the jaggedness of the skin lesion's border by comparing the\n",
        "    perimeter of the actual border to the perimeter of the convex hull\n",
        "    cnt: the contour of the skin lesion\n",
        "    \"\"\"\n",
        "    # Compute the perimeter\n",
        "    perimeter = cv2.arcLength(cnt, True)\n",
        "\n",
        "    # Approximate the contour as a convex hull\n",
        "    hull = cv2.convexHull(cnt)\n",
        "\n",
        "    # Compute the perimeter of the convex hull\n",
        "    simplified_perimeter = cv2.arcLength(hull, True)\n",
        "\n",
        "    # Return the ratio between the two\n",
        "    return simplified_perimeter / perimeter"
      ],
      "metadata": {
        "id": "nt_TUVgzc4gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_color(img, cnt):\n",
        "    \"\"\"\n",
        "    Compute the color standard deviation of the skin lesion within the contour\n",
        "    img: the image of the skin lesion\n",
        "    cnt: the contour of the skin lesion\n",
        "    \"\"\"\n",
        "    # Convert the image to HSV\n",
        "    hsv_img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "    # Recreate the binary mask using the contour\n",
        "    mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
        "    cv2.drawContours(mask, [cnt], -1, (255), thickness=-1)\n",
        "\n",
        "    # Apply the mask to the image\n",
        "    masked_img = cv2.bitwise_and(img, img, mask=mask)\n",
        "\n",
        "    # Compute the variation in HSV color\n",
        "    mean, stdev = cv2.meanStdDev(masked_img, mask=mask)\n",
        "    return tuple(stdev.flatten())"
      ],
      "metadata": {
        "id": "ZOp5ASdMCMUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_diameter(cnt):\n",
        "    \"\"\"\n",
        "    Compute the radius of the skin lesion according to the min enclosing circle\n",
        "    cnt: the contour of the skin lesion\n",
        "    \"\"\"\n",
        "    _, r = cv2.minEnclosingCircle(cnt)\n",
        "    return 2*r"
      ],
      "metadata": {
        "id": "Bnz0KZtDCQ_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is largerly the same as well. However, there are a few small housekeeping changes we will need to make:\n",
        "1. **Terminology (features):** What we originally called `info_dict` and `info_df` are now called `feature_dict` and `features_df` to reflect the fact that the metrics we extracted from our images will serve as our features.\n",
        "2. **Terminology (labels):** What we originally called `diagnosis_df` is now called `labels_df` to reflect the fact that the diagnoses will serve as our labels.\n",
        "3. **Converting strings to numerics:** Because machine learning algorithms operate on numerical data, we have converted the label to a binary variable (`'benign'` = 0, `'malignant'` = `1`). Of course, we can reverse this conversion once we need to have human-interpretable results."
      ],
      "metadata": {
        "id": "sn5KcjldX3St"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_img(filename):\n",
        "    \"\"\"\n",
        "    Process a skin lesion image and produce all of the features according to\n",
        "    the ABCD(E) rule as a dictionary (one value per key)\n",
        "    filename: the name of the skin lesion image without the file extension\n",
        "    \"\"\"\n",
        "    # Get the contour filename\n",
        "    rgb_filename = filename + '.jpg'\n",
        "    seg_filename = filename + '_Segmentation.png'\n",
        "\n",
        "    # Get both of the images (RGB and segmentation annotation)\n",
        "    img = cv2.imread(os.path.join(image_folder, rgb_filename))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    seg_img = cv2.imread(os.path.join(segmentation_folder, seg_filename))\n",
        "    seg_img = cv2.cvtColor(seg_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Get the contour\n",
        "    cnt = extract_contour(seg_img)\n",
        "\n",
        "    # Extract features from the image\n",
        "    asymmetry = compute_asymmetry(img, cnt)\n",
        "    border = compute_border(cnt)\n",
        "    color = compute_color(img, cnt)\n",
        "    diameter = compute_diameter(cnt)\n",
        "\n",
        "    # Combine everything into a feature vector\n",
        "    feature_dict = {'Asymmetry': asymmetry,\n",
        "                    'Border': border,\n",
        "                    'Color Stdev (H)': color[0],\n",
        "                    'Color Stdev (S)': color[1],\n",
        "                    'Color Stdev (V)': color[2],\n",
        "                    'Diameter': diameter}\n",
        "    return feature_dict"
      ],
      "metadata": {
        "id": "-6Egsxlfil5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all the filenames but remove the extension\n",
        "img_filenames = os.listdir(image_folder)\n",
        "img_filenames = sorted([f[:-4] for f in img_filenames])\n",
        "\n",
        "# Iterate through the filenames\n",
        "features_df = pd.DataFrame()\n",
        "for img_filename in img_filenames:\n",
        "    # Generate the features\n",
        "    feature_dict = process_img(img_filename)\n",
        "\n",
        "    # Add the image name\n",
        "    feature_dict['Image Name'] = img_filename\n",
        "    feature_df = pd.DataFrame([feature_dict])\n",
        "    features_df = pd.concat([features_df, feature_df], axis=0)\n",
        "\n",
        "# Set the index to the image name\n",
        "features_df.set_index(['Image Name'], inplace=True)\n",
        "features_df"
      ],
      "metadata": {
        "id": "vyt2LUL7i1BC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate labels\n",
        "labels_df = pd.read_csv(label_filename, header=None)\n",
        "labels_df.rename(columns={0: 'Image Name', 1: 'Label'}, inplace=True)\n",
        "labels_df.set_index(['Image Name'], inplace=True)\n",
        "labels_df['Label'].replace({'benign': 0, 'malignant': 1}, inplace=True)\n",
        "labels_df"
      ],
      "metadata": {
        "id": "Xkr2TodFhmN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = features_df.merge(labels_df, left_index=True, right_index=True)\n",
        "df"
      ],
      "metadata": {
        "id": "IGmw_RJsZXqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Decide How the Data Should Be Split for Training and Testing"
      ],
      "metadata": {
        "id": "ryaahUysaOHD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The organizers of the ISIC challenge technically provided separate datasets for model training and testing. However, we are going to make our own splits for the sake of practice."
      ],
      "metadata": {
        "id": "TQA7ZLmsCAXb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we only have one image per person, we can treat the images independently and do not have to worry about splitting our dataset in any fancy way. We are going to do a simple 80%-20% split where 80% of the images will be used for model training and the rest will be used for model testing. We can do this by using the `train_test_split()` function, which takes two input parameters:\n",
        "1. **arrays:** A list, `numpy` array, or `DataFrame` containing our data\n",
        "2. **test_size:** The fraction of the data that will be assigned to the test split"
      ],
      "metadata": {
        "id": "7OyleQcjfJba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df, test_size=0.2)\n",
        "print(f'Number of samples in train data: {len(train_df)}')\n",
        "print(train_df.head())\n",
        "print(f'Number of samples in test data: {len(test_df)}')\n",
        "print(test_df.head())"
      ],
      "metadata": {
        "id": "uFqD0FMLmobM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The splits are randomly decided, which means that we will get a different split each time we call this function. Randomization is important since we want to avoid fine-tuning our pipeline for a very specific configuration. However, randomization can also make it more difficult to debug our code since we won't be able to tell whether we are getting different results because of the randomness or because of changes we made."
      ],
      "metadata": {
        "id": "jASpe_r7-1i1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One way to avoid this issue is by setting a ***random seed*** â€” an arbitrarily selected number that controls how random numbers are generated. As we are building our pipeline, we can set the random seed so that we get the same results every time. Once we are confident that everything is working properly, we can \"turn off\" the random seed by setting it to `None`. We will keep the random seed set in this notebook so that everyone gets the same results when they get to the end."
      ],
      "metadata": {
        "id": "k6EWrUy4BBbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed to an arbitrary number of your choosing\n",
        "np.random.seed(42)\n",
        "\n",
        "# Rerunning this code will always have the same outcome\n",
        "train_df, test_df = train_test_split(df, test_size=0.2)\n",
        "print(f'Number of samples in train data: {len(train_df)}')\n",
        "print(train_df.head())\n",
        "print(f'Number of samples in test data: {len(test_df)}')\n",
        "print(test_df.head())"
      ],
      "metadata": {
        "id": "dtSB2DFjA_FG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we have our train and test splits, we will separate our data back into features and labels since `scikit-learn` models require `numpy` arrays as input."
      ],
      "metadata": {
        "id": "5nqH3xU-bH32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train_df.drop('Label', axis=1).values\n",
        "y_train = train_df['Label'].values\n",
        "x_test = test_df.drop('Label', axis=1).values\n",
        "y_test = test_df['Label'].values"
      ],
      "metadata": {
        "id": "rECmsVbb8305"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: (Optional) Add Feature Selection"
      ],
      "metadata": {
        "id": "gmMs1P1tabse"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given that we only have a few features and they are informed by domain expertise, we are going to skip this step and assume that we have a reasonable set of features."
      ],
      "metadata": {
        "id": "Qv-3GvQCcG1_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: (Optional) Balance Your Dataset"
      ],
      "metadata": {
        "id": "90Fwfakplyu8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can check the balance of our dataset by looking at the frequency of values in our labels column. We can do this by checking either the `DataFrames` or the `numpy` arrays:"
      ],
      "metadata": {
        "id": "2a3BVu0lm6wD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_label_dist(y):\n",
        "    \"\"\"\n",
        "    Prints out the balance between positive and negative samples\n",
        "    y: a 1D array of labels\n",
        "    \"\"\"\n",
        "    num_neg = np.count_nonzero(y == 0)\n",
        "    num_pos = np.count_nonzero(y == 1)\n",
        "    print(f'Number of benign samples: {num_neg}')\n",
        "    print(f'Number of malignant samples: {num_pos}')\n",
        "    print(f'Fraction of positive samples: {num_pos/(num_pos+num_neg):0.2f}')"
      ],
      "metadata": {
        "id": "9GiFmcuIsMWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_label_dist(df['Label'].values)"
      ],
      "metadata": {
        "id": "kEgoSbL7q83R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that we have many more benign cases than we do malingant ones in our overall dataset. This imbalance trickles down once we split our data into train and test sets."
      ],
      "metadata": {
        "id": "CqHeGBAeryyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_label_dist(y_train)"
      ],
      "metadata": {
        "id": "1VMYNfIAr-dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_label_dist(y_test)"
      ],
      "metadata": {
        "id": "4sAHQmA-su9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For now, we are going to leave this undisturbed, but we will revisit this issue the next time we look at this model."
      ],
      "metadata": {
        "id": "SHfP4CDpl5RH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Select an Appropriate Model"
      ],
      "metadata": {
        "id": "TUuv3wRJaVer"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`scikit-learn` provides numerous classification model architectures with their own advantages and disadvantages. For now, we are going to stick with a ***random forest classifier***, which uses a collection of decision trees to make a decision."
      ],
      "metadata": {
        "id": "IiS0RhPymQwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier()"
      ],
      "metadata": {
        "id": "-ZejuzTe8X3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: (Optional) Select Your Hyperparameters"
      ],
      "metadata": {
        "id": "A-AcODJ3aYx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For now, we are going to stick with the default hyperparameters for our model."
      ],
      "metadata": {
        "id": "5J5xnuJkC3Lp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8: Train and Test Your Model"
      ],
      "metadata": {
        "id": "-fpM5JCVcS_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are finally ready to train our machine learning model! All we need to do is call the `.fit()` method while providing the features and labels from our training dataset. Underneath the hood, the model will adjust its underlying parameters and decision boundaries in order to optimize its performance on that data."
      ],
      "metadata": {
        "id": "fndMkb0u7_-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "i4DkQNLRDH3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we've trained the model, we can see how the model would classify a set of features by calling the `.predict()` method. People often forgo generating predictions for the training dataset since it will not give us a real indication of how the model will perform on previously unseen data. However, we will generate predictions for both our training and test data so that we can compare the model accuracy on both sets."
      ],
      "metadata": {
        "id": "7CqgEKuyDsYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = clf.predict(x_train)\n",
        "y_test_pred = clf.predict(x_test)"
      ],
      "metadata": {
        "id": "LZBGUjVnDbce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To plot an ROC curve, we actually need to generate our predictions a slightly different way. Rather than generating binary predictions (`0` or `1`), we will need to generate probabilistic predictions that indicate the likelihood that the given sample belongs to the positive class."
      ],
      "metadata": {
        "id": "PKAqvdEyfS9o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can do this by calling `.predict_proba()` instead of `.predict()` on our model. This function produces an $n \\times c$ array. $n$ is the number of samples, and $c$ is the number of classes we have in our dataset. The number in row $n_i$ and column $c_j$ indicates the likelihood that sample $i$ belongs to class $j$ according to our model."
      ],
      "metadata": {
        "id": "rhLsp_xfiaDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compare the output of `.predict()` and `.predict_proba()` on a subset of our training dataset features:"
      ],
      "metadata": {
        "id": "PuVEa-GRh3F7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_binary = clf.predict(x_train[:10, :])\n",
        "y_prob = clf.predict_proba(x_train[:10, :])\n",
        "print(y_binary)\n",
        "print(y_prob)"
      ],
      "metadata": {
        "id": "a7ZExfdEfvjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that only the 7th row has a `1` in the output of `.predict()`, indicating that it was the only sample that was predicted to be malignant out of the 10 samples. The corresponding row in the output of `predict_proba()` is the only one where the value on the left is less than the value on the right, reflecting the fact that the model was more confident that the sample was malignant instead of benign."
      ],
      "metadata": {
        "id": "IxTBl10ilXqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we only have two classes, we are simply going to save the rightmost column, which indicates the likelihood that each sample belongs to the positive class (`malignant`) according to our model."
      ],
      "metadata": {
        "id": "QgADZEG9i1dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred_prob = clf.predict_proba(x_train)[:, 1]\n",
        "y_test_pred_prob = clf.predict_proba(x_test)[:, 1]"
      ],
      "metadata": {
        "id": "tOESgRqUi8ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 9: Use an Appropriate Method for Interpreting Results"
      ],
      "metadata": {
        "id": "hT0cnOFdafEF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have predictions, we will examine a variety of metrics to see how well our model performed. Most of the functions we will discuss in this section require two inputs:\n",
        "1. **y_true:** The known ground-truth labels from our dataset\n",
        "2. **y_pred:** The labels predicted from the model"
      ],
      "metadata": {
        "id": "zj0apvZTbn5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will start by examining how well our model worked on the training dataset, after which we will revisit them for our test dataset."
      ],
      "metadata": {
        "id": "XNg-2m-LO0S0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix"
      ],
      "metadata": {
        "id": "WwE9unOpIbm2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can manually generate and save a confusion matrix using the `confusion_matrix()` function:"
      ],
      "metadata": {
        "id": "SMYizHnQNcbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(y_train, y_train_pred)\n",
        "print(cm)\n",
        "\n",
        "# Split the confusion matrix according to decision outcomes\n",
        "tn = cm[0][0]\n",
        "fp = cm[0][1]\n",
        "fn = cm[1][0]\n",
        "tp = cm[1][1]\n",
        "print(f'True positives: {tp}')\n",
        "print(f'True negatives: {tn}')\n",
        "print(f'False positives: {fp}')\n",
        "print(f'False negatives: {fn}')"
      ],
      "metadata": {
        "id": "6ttSfs4qNgg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, most people prefer to generate a figure that shows the visualization since that's what ends up getting put into a paper or report. `scikit-learn` provides a handy class called `ConfusionMatrixDisplay` for creating such a visualization."
      ],
      "metadata": {
        "id": "6wDANVl5LyQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "classes = ['benign', 'malignant']\n",
        "ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred,\n",
        "                                        display_labels=classes)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f7nOnbhUMBZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification Accuracy Rates"
      ],
      "metadata": {
        "id": "e87qpxdPIsga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `metrics` module provides numerous functions you can call to calcluate various scores. A few examples are provided below:"
      ],
      "metadata": {
        "id": "zvZqiWh9bU7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "print(f'Accuracy: {accuracy_score(y_train, y_train_pred)}')\n",
        "print(f'F1 Score: {f1_score(y_train, y_train_pred)}')\n",
        "print(f'Precision: {precision_score(y_train, y_train_pred)}')\n",
        "print(f'Recall: {recall_score(y_train, y_train_pred)}')"
      ],
      "metadata": {
        "id": "U4JQn0MdbmdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately, it does not provide functions for calculating sensitivity and specificity, which are commonly used in medical applications. However, we can calculate these ourselves using the entries of the confusion matrix:"
      ],
      "metadata": {
        "id": "_hXQscbbbBCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the confusion matrix\n",
        "cm = confusion_matrix(y_train, y_train_pred)\n",
        "tn = cm[0][0]\n",
        "fp = cm[0][1]\n",
        "fn = cm[1][0]\n",
        "tp = cm[1][1]\n",
        "\n",
        "# Calculate sensitivity and specificity\n",
        "sens = tp / (tp+fn)\n",
        "spec = tn / (tn+fp)\n",
        "print(f'Sensitivity: {sens}')\n",
        "print(f'Specificity: {spec}')"
      ],
      "metadata": {
        "id": "kV6Ft-Q5cQWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`classification_report()` provides a quick printout of commonly used classification accuracy metrics. This table breaks down the performance across the individual classes, which can be useful for determining whether your model is performing better for one class versus another. This table breaks down what each of the numbers represents:\n",
        "\n",
        "| |Precision|Recall|F1-Score|Support|\n",
        "|-----|-----|-----|-----|-----|\n",
        "| **Benign** | Precision if it considered `benign` to be the positive label | Recall if it considered `benign` to be considered the positive label | F1-score if it considered `benign` to be considered the positive label | The number of examples that were labeled `benign` |\n",
        "| **Malignant** | Precision if it considered `malignant` to be the positive label | Recall if it considered `malignant` to be considered the positive label | F1-score if it considered `malignant` to be considered the positive label | The number of examples that were labeled `malignant` |\n",
        "| **Accuracy** | | | The F1-score across the entire dataset | The nubmer of examples in the entire dataset |\n",
        "| **Macro avg** | The unweighted average precision across both classes | The unweighted average recall across both classes | The unweighted average F1-score across both classes | The nubmer of examples in the entire dataset |\n",
        "| **Weighted avg** | The weighted average precision across both classes | The weighted average recall across both classes | The weighted average F1-score across both classes | The nubmer of examples in the entire dataset |\n"
      ],
      "metadata": {
        "id": "ZMtDXPjuJT89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_train, y_train_pred, target_names=classes))"
      ],
      "metadata": {
        "id": "4CqItIfgdVfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ROC Curve"
      ],
      "metadata": {
        "id": "iikCuJ_eeHUj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can generate the raw data for an ROC curve using `roc_curve()` and the area under the curve (AUC) using `auc_roc_score()`. Instead of providing the predicted binary labels from our model, we will need to provide the predicted likelihood scores that were output by `.predict_proba()`."
      ],
      "metadata": {
        "id": "mnTIpaN-f6To"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "fpr, tpr, thresholds = roc_curve(y_train, y_train_pred_prob)\n",
        "auc = roc_auc_score(y_train, y_train_pred_prob)\n",
        "print(f'AUC: {auc}')"
      ],
      "metadata": {
        "id": "MqZFsJvff_l8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to what we said about confusion matrices, however, `scikit-learn` provides a handy function for generating an ROC curve visualization for us."
      ],
      "metadata": {
        "id": "6BmYqGIStnB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import RocCurveDisplay\n",
        "RocCurveDisplay.from_predictions(y_train, y_train_pred_prob)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CpqrSRthoqyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing Performance on Train and Test Data"
      ],
      "metadata": {
        "id": "uvtSJXQxeJE9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a function that will generate a detailed classification accuracy report combining a subset of the aforementioned metrics and visualizations:"
      ],
      "metadata": {
        "id": "dOvMA31Y8EYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classification_evaluation(y_true, y_pred, y_pred_prob):\n",
        "    \"\"\"\n",
        "    Generate a series of graphs that will help us determine the performance of\n",
        "    a binary classifier model\n",
        "    y_true: the target binary labels\n",
        "    y_pred: the predicted binary labels\n",
        "    y_pred_prob: the predicted likelihood scores for a positive label\n",
        "    \"\"\"\n",
        "    # Calculate f1 score, sensitivity, and specificity\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    tn = cm[0][0]\n",
        "    fp = cm[0][1]\n",
        "    fn = cm[1][0]\n",
        "    tp = cm[1][1]\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    sens = tp / (tp+fn)\n",
        "    spec = tn / (tn+fp)\n",
        "\n",
        "    # Generate the confusion matrix\n",
        "    cm_title = f'Confusion Matrix \\n(Sensitivity: {sens:0.2f}, Specificity: {spec:0.2f})'\n",
        "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred, display_labels=classes)\n",
        "    plt.title(cm_title)\n",
        "    plt.show()\n",
        "\n",
        "    # Display the ROC curve\n",
        "    roc_title = f'ROC Curve \\n(Acc: {acc:0.2f}, F1 score: {f1:0.2f})'\n",
        "    RocCurveDisplay.from_predictions(y_true, y_pred_prob)\n",
        "    plt.title(roc_title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "b1LxWw82eXkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's run this function on both our train and test predictions to see the disparity in performance:"
      ],
      "metadata": {
        "id": "PeRsPC3cjgwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classification_evaluation(y_train, y_train_pred, y_train_pred_prob)"
      ],
      "metadata": {
        "id": "A-eEyZjjjl_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_evaluation(y_test, y_test_pred, y_test_pred_prob)"
      ],
      "metadata": {
        "id": "DnvfgKLRjrCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So what can we learn from all of these results:\n",
        "* As we saw earlier, our dataset has many more benign cases than it does malignant cases. This imbalance could bias our model to assume that skin lesions are benign.\n",
        "* Our model achieved perfect accuracy on our training dataset, which means that the model was able to learn something useful from the features we provided.\n",
        "* While it looks like we achieved high accuracy on our test dataset as well, that is because most of our test data involved benign cases and our model was biased towards making benign predictions. If we look more closely at sensitivity and F1 score, we can confirm that this model is actually performing poorly on the test dataset."
      ],
      "metadata": {
        "id": "73HEAeGwqoEr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To summarize, our model was able to learn from the features we provided, but it did not generalize to the unseen test dataset. We are going to revisit this machine learning pipeline in a later session to see how we can improve its ability to generalize to new data."
      ],
      "metadata": {
        "id": "Wkt4YdgS_PJK"
      }
    }
  ]
}