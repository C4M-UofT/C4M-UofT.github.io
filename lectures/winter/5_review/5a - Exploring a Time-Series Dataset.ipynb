{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["DekAnzq1b82b","buga415hls_2","a890NkWf-aBm","H9lOJqqR-r3L","wXrLzsja-gNj","a4Fwmubg_Df8","0f6l4Z24_GRE","OrgAiKEgNmBZ","SY3s63jSnDGb","_x89cEEcycSt","QxpSzGO1ypCX","4Uap4StJe2WX","aA2s9Vvhermg"],"authorship_tag":"ABX9TyNckiwXqzt9Xbp/frld0thn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["In this notebook, we're going to explore a time-series gait dataset collected from patients with Parkinson's disease. The data is taken from a [PhysioNet](https://www.physionet.org/) repository called [Gait in Parkinson's Disease](https://www.physionet.org/content/gaitpdb/1.0.0/) by Jeffrey Hausdorff."],"metadata":{"id":"BDaO9cuMWe83"}},{"cell_type":"markdown","source":["# Important: Run this code cell each time you start a new session!"],"metadata":{"id":"DekAnzq1b82b"}},{"cell_type":"code","source":["!pip install numpy\n","!pip install pandas\n","!pip install matplotlib\n","!pip install os\n","!pip install librosa\n","!pip install scikit-learn\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","import librosa\n","import sklearn"],"metadata":{"id":"jrO0X1ZMxMN5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget -rNcnp https://physionet.org/files/gaitpdb/1.0.0/"],"metadata":{"id":"bASFcdZNZuGJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Overview of the Dataset"],"metadata":{"id":"xP4sP_ekZxqW"}},{"cell_type":"markdown","source":["Parkinson's disease is a chronic and progressive neurological disorder that affects the central nervous system. It primarily affects movement and is characterized by a variety of symptoms, including tremors, stiffness, slow movements, and difficulty with balance and coordination. A disturbed gait is a common, debilitating symptom; patients with severe gait disturbances are prone to falls and may lose their functional independence."],"metadata":{"id":"CXg2PYdjevCJ"}},{"cell_type":"markdown","source":["The goal of this dataset is enable researchers to investigate whether characteristics of gait can be used to automatically monitor the severity of Parkinson's disease over time. This dataset is actually composed of data collected by three institutions. Together, these institutions recruited 93 patients with idiopathic PD and 73 healthy controls. During enrollment, subjects were asked to complete a number of clinical scales to assess the severity of their Parkinsonian symptoms. The clinical scale we will focus on the most is the Unified Parkinson's Disease Rating Scale (UPDRS). This scale is composed of four different parts, but we will focus on the portion that deals with motor control function (Part III).\n"],"metadata":{"id":"BBrNiJenan-A"}},{"cell_type":"markdown","source":["During the study itself, subjects were asked to walk at their usual pace for approximately 2 minutes on level ground. Subjects were asked to repeat this protocol for multiple trials depending on the institution where the data was collected. Underneath each foot were 8 sensors that measure force (in Newtons) as a function of time; the researchers who compiled this dataset refer to the sensor data as the vertical ground reaction force (VGRF).  The output of each of these 16 sensors has been digitized and recorded at 100 Hz, and the records also include two signals that reflect the sum of the 8 sensor outputs for each foot."],"metadata":{"id":"QYrG6r4EVNEV"}},{"cell_type":"markdown","source":["| Column # | Description |\n","|----------|-------------|\n","| 1 | Time in seconds|\n","| 2–9 | VGRF on each of the 8 sensors located under the left foot |\n","|10–17 | VGRF on each of the 8 sensors located under the right foot |\n","| 18 | Total force under the left foot |\n","| 19 | Total force under the right foot |"],"metadata":{"id":"KTU_l5HRMbL3"}},{"cell_type":"markdown","source":["The recording files are named according to the following convention: `{study_prefix}{subject_type}{subject_id}_{trial_id}.txt` (e.g., `GaCo01_01.txt`)\n","\n","* `study_prefix`: Specifies the institution where the subject was recruited (either `Ga`, `Ju`, or `Si`)\n","* `subject_type`: Specifies whether the subject was a control (`Co`) or a patient (`Pt`)\n","* `subject_id`: Numerical identifier indicating the subject's number within the institution's cohort\n","* `trial_id`: Numerical identifier indicating the trial number. We will be looking at all trials except for any numbered `10`, which relates to a special protocol used by a single institution."],"metadata":{"id":"8X30ZmeSfXPM"}},{"cell_type":"markdown","source":["All of our data, which has already been downloaded, is located in the folder `physionet.org/files/gaitpbd/1.0.0/`. Along with the recording files, we will also look at the file `demographics.xls`, which contains both subject demographics and their clinical assessment scores."],"metadata":{"id":"Jt63WLFDqCgJ"}},{"cell_type":"code","source":["# The relevant folders and files associated with this dataset\n","base_folder = os.path.join('physionet.org', 'files', 'gaitpdb', '1.0.0')\n","demo_filename = os.path.join(base_folder, 'demographics.xls')"],"metadata":{"id":"tjO9wyZHMg9O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In this notebook, we are going to see if we can extract useful information from the VGRF time-series data that is correlated with patients' UDPRS scores. We are only going to exclude the healthy controls from our analyses so that we do not have an excess of negligible UPDRS scores. Nevertheless, most of the steps in this notebook could be repeated with that population if you so choose."],"metadata":{"id":"sdZhpbU3XDH6"}},{"cell_type":"markdown","source":["# Inspecting the Dataset"],"metadata":{"id":"XXy14O09UM3L"}},{"cell_type":"markdown","source":["Before we start trying to extract information from our images, let's look at a hand-selected example of VGRF time-series data to see what we are working with."],"metadata":{"id":"9lWAWkZ2UjdD"}},{"cell_type":"code","source":["# The names of the columns in the recordings\n","column_names = ['Time']\n","for i in range(1, 9):\n","    column_names.append(f'Left Sensor {i}')\n","for i in range(1, 9):\n","    column_names.append(f'Right Sensor {i}')\n","column_names.append('Left Foot')\n","column_names.append('Right Foot')"],"metadata":{"id":"3hotHPk3Ui6E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Show the structure of one of the files\n","example_filename = 'GaCo01_01.txt'\n","example_df = pd.read_csv(os.path.join(base_folder, example_filename),\n","                         sep=\"\\t\", header=None, names=column_names)\n","example_df"],"metadata":{"id":"nlbjx-aIDbFe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Inspecting time-series data in a table will only give us information about the duration of the recording and the range of values the measurement can take. It's usually a good idea to plot time-series data so we can get a better understanding of its structure."],"metadata":{"id":"ec8iSBqXXzV6"}},{"cell_type":"code","source":["# Plot the data\n","plt.figure(figsize=(9, 3))\n","plt.subplot(1, 2, 1)\n","plt.plot(example_df['Time'], example_df['Left Foot'], 'k-', label='Left')\n","plt.xlabel('Time (s)'), plt.ylabel('VGRF (N)'), plt.title('Entire Recording, Single Foot')\n","plt.subplot(1, 2, 2)\n","plt.plot(example_df['Time'], example_df['Left Foot'], 'k-', label='Left')\n","plt.plot(example_df['Time'], example_df['Right Foot'], 'r-', label='Right')\n","plt.xlabel('Time (s)'), plt.ylabel('VGRF (N)'), plt.title('Short Snippet, Both Feet')\n","plt.xlim(0, 5)\n","plt.legend()\n","plt.show()"],"metadata":{"id":"SdmFJoR5ko5L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can verify that the data makes sense for a couple of reasons:\n","* The measurements recorded from each foot fluctuate between 0 N and roughly 1000 N. While the magnitude of the range's upper limit may not have an intuitive interpretation, the fact that the signals periodically approach zero makes sense since there should be negligible force exerted by the foot while it is up in the air.\n","* The measurements recorded on each foot oppose one another. In other words, if one signal is high, the other is low. This makes sense since feet alternate when they touch the ground whiel a person is walking."],"metadata":{"id":"wNe1-tFZsZwk"}},{"cell_type":"markdown","source":["Let's look at the measurements for a single foot according to three different representations:\n","1. In the time domain (force vs. time)\n","2. In the frequency domain as an FFT (FFT amplitude vs. frequency)\n","3. In the frequency domain as a spectrogram (FFT amplitude vs. frequency vs. time)"],"metadata":{"id":"SGl6ywUDNoaI"}},{"cell_type":"code","source":["from numpy.fft import fftfreq\n","from scipy.fftpack import fft\n","from scipy import signal\n","def view_recording(filename, column_names, fs=100):\n","    \"\"\"\n","    Show the force measurements over time from the left foot according to\n","    three different representations\n","    filename: the name of the file that should be loaded\n","    column_names: the names of the file's columns\n","    fs: the sampling rate of our data (set to 100 Hz since we know\n","    that is the case for our dataset)\n","    \"\"\"\n","    # Load the file\n","    df = pd.read_csv(os.path.join(base_folder, filename),\n","                     sep=\"\\t\", header=None, names=column_names)\n","    time = df['Time'].values\n","    values = df['Left Foot'].values\n","\n","    # Calculate the FFT\n","    values_centered = values - values.mean()\n","    fft_mag = np.abs(fft(values_centered))\n","    fft_freqs = fftfreq(len(values_centered), 1/fs)\n","\n","    # Calculate the spectrogram\n","    spec_freqs, spec_times, spectro = signal.spectrogram(values_centered, fs)\n","\n","    # Show the three signal representations\n","    plt.figure(figsize=(12, 3))\n","    plt.subplot(1, 3, 1)\n","    plt.plot(time, values)\n","    plt.xlabel('Time (s)'), plt.ylabel('VGRF (N)')\n","    plt.title('Time Domain')\n","\n","    plt.subplot(1, 3, 2)\n","    plt.stem(fft_freqs, fft_mag, markerfmt=\" \", basefmt=\"-\")\n","    plt.xlabel('Freq (Hz)'), plt.ylabel('FFT Amplitude')\n","    plt.ticklabel_format(axis='y', style='sci', scilimits=(4,4))\n","    plt.xlim(-0.1, 8)\n","    plt.title('Frequency Domain: FFT')\n","\n","    plt.subplot(1, 3, 3), plt.pcolormesh(spec_times, spec_freqs, spectro, shading='gouraud')\n","    plt.xlabel('Time (s)'), plt.ylabel('Frequency (Hz)')\n","    plt.ylim(0, 8)\n","    plt.title('Frequency Domain: Spectrogram')\n","    plt.show()"],"metadata":{"id":"TgSG8O2e-aY2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["view_recording(example_filename, column_names)"],"metadata":{"id":"fMaDF7r0Dd-g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here are a few notes and observations about this function:\n","* We removed the mean of the overall signal in the time domain before translating our data into the frequency domain in order to remove the FFT components at 0 Hz.\n","* Since our data was recorded at 100 Hz, Nyquist–Shannon Sampling Theorem states that we should be able to extract frequency information as high as 50 Hz. However, given that we are talking about gross motor coordination, we aren't going to worry too much about frequency information beyond 8 Hz.\n","* We could apply a digital filter to clean up our data a bit, but given that there does not seem to be a great deal of high-frequency information, we will forgo that step for now."],"metadata":{"id":"Dnho0OgRqXOb"}},{"cell_type":"markdown","source":["# Extracting Information from a Recording"],"metadata":{"id":"buga415hls_2"}},{"cell_type":"markdown","source":["In a previous session, we discussed various time-domain and frequency-domain analysis techniques to summarize time-series data. If we apply all of these techniques, we will be left with hundreds of different metrics we will need to sort through. Although this can be an unbiased way of approaching data analysis, it can also be very time-consuming. For this dataset, we will look at a few standard calculations for each recording; however, we will also apply domain expertise about the problem we are trying to solve to extract information that should ideally be more meaningful to us."],"metadata":{"id":"t9huu6aTluCV"}},{"cell_type":"markdown","source":[" There are four cardinal symptoms of Parkinson's disease:\n","\n","1. **Tremor:** Tremor is one of the most common symptoms of Parkinson's disease. It usually begins with a slight trembling or shaking of a hand, finger, or thumb. The tremor typically occurs when the affected limb is at rest and may subside during voluntary movement.\n","\n","2. **Bradykinesia:** Bradykinesia refers to slowness of movement and is another key symptom of Parkinson's disease. It can manifest as a general reduction in spontaneous movements, including reduced arm swinging while walking, difficulty initiating movement, and a gradual decline in the speed of repetitive actions.\n","\n","3. **Rigidity:** Rigidity is characterized by stiffness and resistance to movement in the muscles. It can be noticed as increased muscle tone that causes stiffness and resistance, leading to decreased range of motion, muscle aches, and general discomfort.\n","\n","4. **Postural Instability:** Postural instability is commonly observed in the later stages of Parkinson's disease. It may result in impaired balance and increased risk of falling. People with Parkinson's disease may have difficulty making rapid, automatic, and involuntary adjustments to maintain balance.\n","\n","Because tremor is more prominent in the hands and arms than it is the legs, we are going to skip that symptom and focus on the latter three."],"metadata":{"id":"txTEh8fNYCB5"}},{"cell_type":"markdown","source":["Knowing how to translate these English explanations into code is a difficult skill that comes with practice, exposure to a diverse toolbox of techniques, and a healthy amount of internet searching for code examples and academic papers. We will cover one way of extracting information related to each rule in order of increasing complexity, but bear in mind two things:\n","\n","1. There are likely alternative ways of implementing each rule that are just as valid.\n","2. Some of these techniques are not going to be obvious at first glance, but this is a skill you will develop over time."],"metadata":{"id":"GPRFzzhm-TKU"}},{"cell_type":"markdown","source":["## Standard Time-Domain Calculations"],"metadata":{"id":"a890NkWf-aBm"}},{"cell_type":"markdown","source":["To start, let's extract some simple descriptive statistics in the time-domain that will summarize the amplitude of the entire signal. We will calculate the average, standard deviation, 95th percentile, and root mean square (RMS). All of these numbers should be higher under two conditions:\n","1. Subjects who exert a greater force with their foot (i.e., higher amplitude)\n","2. Subjects who maintain foot contact for longer periods of time (i.e., wider width)."],"metadata":{"id":"zXJsc4xYtZ8U"}},{"cell_type":"code","source":["def compute_arbitrary_time_domain_metrics(times, values, fs=100):\n","    \"\"\"\n","    Calculates generic time-domain statistics on the signal\n","    times: the times associated with the VGRF data\n","    values: the VGRF data\n","    fs: the sampling rate\n","    \"\"\"\n","    return {'average VGRF': np.mean(values),\n","            'stdev VGRF': np.std(values),\n","            '95th percentile VGRF': np.percentile(values, 95),\n","            'rms VGRF': np.sqrt(np.mean(values**2))}"],"metadata":{"id":"gtMjoTpsulKG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Standard Frequency-Domain Calculations"],"metadata":{"id":"H9lOJqqR-r3L"}},{"cell_type":"markdown","source":["Let's also calculate some standard metrics in the frequency domain. We will look at peak frequency a bit later, but for now, we are going to look at the signal's power at different frequency ranges."],"metadata":{"id":"D00zqHJx-wDu"}},{"cell_type":"markdown","source":["When we inspected a randomly selected signal in the frequency domain, we saw that most of the frequency information was within 0–3 Hz, and looking beyond 8 Hz did not give us much new information given how smooth the signal already is. Therefore, we will use 0–3 Hz to define our \"low frequency\" information and 3–8 Hz to define our \"high frequency\" information. These decisions are somewhat arbitrary though, so you could try different ranges and see how the influence your results down the road."],"metadata":{"id":"NFoQV_N_J2ar"}},{"cell_type":"markdown","source":["The total power within these frequency ranges is heavily correlated with the overall magnitude with which the subject is walking. The harder their steps, the more power there is likely to be across both ranges. To quantify how the frequency content is distributed across these ranges, we will calculate the ratio between the total power in the two ranges."],"metadata":{"id":"ys36l6t4J_aK"}},{"cell_type":"code","source":["def compute_arbitrary_freq_domain_metrics(times, values, fs=100):\n","    \"\"\"\n","    Calculates generic frequency-domain statistics on the signal\n","    times: the times associated with the VGRF data\n","    values: the VGRF data\n","    fs: the sampling rate\n","    \"\"\"\n","    # Calculate the FFT\n","    values_centered = values - values.mean()\n","    fft_mag = np.abs(fft(values_centered))\n","    fft_freqs = fftfreq(len(values_centered), 1/fs)\n","\n","    # Calculate the indices relevant to our frequency bands of interest\n","    low_indices = np.where((fft_freqs >= 0) & (fft_freqs <= 3))\n","    high_indices = np.where((fft_freqs >= 3) & (fft_freqs <= 8))\n","\n","    # Calculate the power at the low and high frequencies\n","    low_power = np.sum(fft_mag[low_indices]**2)\n","    high_power = np.sum(fft_mag[high_indices]**2)\n","\n","    # Calculate the power within the frequency range\n","    high_to_low_ratio = 10*np.log10(high_power / low_power)\n","    return {'power at low freqs': low_power,\n","            'power at high freqs': high_power,\n","            'high-to-low power ratio': high_to_low_ratio}"],"metadata":{"id":"sy1KLrzRvBzy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Amplitude Measurements for Rigidity and Postural Instability"],"metadata":{"id":"wXrLzsja-gNj"}},{"cell_type":"markdown","source":["The descriptive statistics we have calculated so far have a couple limitations:\n","1. They do not account for the fact that person's gait characterstics can change over time (e.g., speed up, slow down)\n","2. For the time-domain calculations in particular, the rate at which the person walks and the force with which they step can affect these statistics."],"metadata":{"id":"lg40ZwfVbTwj"}},{"cell_type":"markdown","source":["To account for these shortcomings, we will calculate the signal amplitude (according to RMS) over non-overlapping 5-second windows. This will give us a collection of amplitude measurements that we can aggregate to summarize the entire signal. The decision to use non-overlapping windows is strictly for computational efficiency. The decision to use a 5-second window is somewhat arbitrary, but the general intuition is that it is long enough to include multiple steps and short enough to capture a relatively consistent gait pattern."],"metadata":{"id":"y0gevbt9RuGt"}},{"cell_type":"markdown","source":["The more stiff someone is, the more likely they are to take soft steps. Therefore, we will take the average of the amplitude measurements as a potential metric of rigidity. People who have an unstable gait are more likely to vary their walking behavior over time. Therefore, we will also calculate the standard deviation of the amplitude measurements as a potential metric for postural instability."],"metadata":{"id":"BqKh5rvpRPl1"}},{"cell_type":"code","source":["def compute_amplitude_metrics(times, values, fs=100):\n","    \"\"\"\n","    Calculate metrics related to the transient amplitude of the signal over time\n","    using a 5-second window with 0% overlap\n","    times: the times associated with the VGRF data\n","    values: the VGRF data\n","    fs: the sampling rate\n","    \"\"\"\n","    # Set the sliding window parameters\n","    window_width = 5\n","    start_time = 0\n","    end_time = window_width\n","    sample_period = 1/fs\n","    middle_idx = int((window_width / sample_period) // 2)\n","\n","    # Stop generating windows it would go past the end of the signal\n","    window_amplitudes = []\n","    while end_time < times.max():\n","        # Grab the current window by filtering indexes according to time\n","        window_idxs = (times >= start_time) & (times <= end_time)\n","        window_values = values[window_idxs]\n","\n","        # Calculate the amplitude\n","        window_rms = np.sqrt(np.mean(window_values**2))\n","        window_amplitudes.append(window_rms)\n","\n","        # Move the window over by a stride\n","        start_time += window_width\n","        end_time += window_width\n","\n","    # Summarize the amplitude over time\n","    return {'average amplitude': np.mean(window_amplitudes),\n","            'stdev amplitude': np.std(window_amplitudes)}"],"metadata":{"id":"FNZOOcXsdISL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Cadence Measurements for Bradykinesia and Postural Instability"],"metadata":{"id":"a4Fwmubg_Df8"}},{"cell_type":"markdown","source":["Walking speed is considered by some clinical researchers to be the \"6th vital sign\", which makes it an important metric for most gait analyses. Although we cannot easily determine subjects' walking speed in meters per second, we can establish the cadence of their gait in steps per second."],"metadata":{"id":"tEJ9SGpNMSp6"}},{"cell_type":"markdown","source":["To calculate a subject's cadence over time, we will generate a spectrogram and then look for the peak frequency within each time window. We will then aggregate those frequencies in a similar fashion to how we aggregated the RMS amplitudes earlier. More specifically, we will calculate the average peak frequency over time as a potential metric of bradykinesia, and we will calculate the standard deviation of the peak frequency over time as a potential metric of postural instability."],"metadata":{"id":"7LXSDgV7UVOY"}},{"cell_type":"code","source":["def compute_cadence_metrics(times, values, fs=100):\n","    \"\"\"\n","    Calculate metrics related to the transient peak frequency of the signal\n","    over time\n","    times: the times associated with the VGRF data\n","    values: the VGRF data\n","    fs: the sampling rate\n","    \"\"\"\n","    # Calculate the spectrogram\n","    values_centered = values - values.mean()\n","    spec_freqs, spec_times, spectro = signal.spectrogram(values_centered, fs)\n","\n","    # Find the largest bin along the frequency dimension\n","    dominant_bins = np.argmax(spectro, axis=0)\n","\n","    # Map those bin indeces to frequencies\n","    peak_freqs = spec_freqs[dominant_bins]\n","\n","    # Summarize the step rate over time\n","    return {'average cadence': np.mean(peak_freqs),\n","            'stdev cadence': np.std(peak_freqs)}"],"metadata":{"id":"XXS1hhmcq7MM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Difference Measurements for Postural Instability"],"metadata":{"id":"0f6l4Z24_GRE"}},{"cell_type":"markdown","source":["We could calculate most of the aforementioned features for both the left and right foot separately, which would nearly double the number of metrics we have. However, should we interpret the step cadence on the left side any differently than the step cadence on the right side? Would we interpret them differently if they were flipped? Probably not."],"metadata":{"id":"jyi10hPOLsb3"}},{"cell_type":"markdown","source":["To make our lives simple, we are going to only calculate the aforementioned metrics on a single side of the body (left). However, it is important to know if the two sides are different. For example, a subject who has a limp may have a heavier footstep on one side compared to the other."],"metadata":{"id":"Mgnj0QbiU3tb"}},{"cell_type":"markdown","source":["Therefore, we are going to calculate the difference between corresponding metrics on the left and right side of the body. Since we do not care whether the higher value is on the right or left side, we will compute the absolute value of the difference."],"metadata":{"id":"Cg5APvMvMGR6"}},{"cell_type":"code","source":["def compute_differences(left, right):\n","    \"\"\"\n","    Compares corresponding metrics across two feet\n","    left: the dictionary of metrics from the left side\n","    right: the dictionary of metrics from the right side\n","    \"\"\"\n","    diffs_dict = {}\n","    for key in left:\n","        diffs_dict[key] = np.abs(left[key] - right[key])\n","    return diffs_dict"],"metadata":{"id":"3Hicu3U1rD28"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Processing a Single Recording"],"metadata":{"id":"OrgAiKEgNmBZ"}},{"cell_type":"markdown","source":["Now that we have helper functions to extract information from our recordings, let's put everything together into a single function. This function will take a single recording filename as input and return all of the information calculated for that recording as a `dict`."],"metadata":{"id":"jnI4rsL6YeAm"}},{"cell_type":"code","source":["def process_recording(filename):\n","    \"\"\"\n","    Process a VGRF recording and produce all of the metrics as a dictionary\n","    (one value per key)\n","    filename: the name of the recording file\n","    \"\"\"\n","    # Get the useful columns\n","    df = pd.read_csv(os.path.join(base_folder, filename),\n","                     sep=\"\\t\", header=None, names=column_names)\n","    time = df['Time'].values\n","    left_values = df['Left Foot'].values\n","    right_values = df['Right Foot'].values\n","\n","    # Extract metrics from the left side\n","    left_time = compute_arbitrary_time_domain_metrics(time, left_values)\n","    left_freq = compute_arbitrary_freq_domain_metrics(time, left_values)\n","    left_amplitude = compute_amplitude_metrics(time, left_values)\n","    left_cadence = compute_cadence_metrics(time, left_values)\n","\n","    # Extract metrics from the right side\n","    right_time = compute_arbitrary_time_domain_metrics(time, right_values)\n","    right_freq = compute_arbitrary_freq_domain_metrics(time, right_values)\n","    right_amplitude = compute_amplitude_metrics(time, right_values)\n","    right_cadence = compute_cadence_metrics(time, right_values)\n","\n","    # Extract difference metrics\n","    diff_time = compute_differences(left_time, right_time)\n","    diff_freq = compute_differences(left_freq, right_freq)\n","    diff_amplitude = compute_differences(left_amplitude, right_amplitude)\n","    diff_cadence = compute_differences(left_cadence, right_cadence)\n","\n","    # Combine everything into a dictionary\n","    info_dict = {}\n","    for left_dict in [left_time, left_freq, left_amplitude, left_cadence]:\n","        for key in left_dict:\n","            info_dict['Single foot ' + key] = left_dict[key]\n","    for diff_dict in [diff_time, diff_freq, diff_amplitude, diff_cadence]:\n","        for key in diff_dict:\n","            info_dict['Difference ' + key] = diff_dict[key]\n","    return info_dict"],"metadata":{"id":"-6Egsxlfil5v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test our function\n","process_recording(example_filename)"],"metadata":{"id":"6YynXU1C-J7j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Creating Our Processed Dataset"],"metadata":{"id":"SY3s63jSnDGb"}},{"cell_type":"markdown","source":["To process all of our images, we will iterate through all of the files and call our `process_recording()` function on each recording. Because there are a variety of files in our data folder, we will want to ignore any files that either (1) are not recording files, (2) come from control subjects, or (3) are numbered as trial 10. We will gather the results in a single `DataFrame`."],"metadata":{"id":"wXntyzHBC-tQ"}},{"cell_type":"code","source":["data_filenames = os.listdir(base_folder)\n","\n","# Iterate through the filenames\n","info_df = pd.DataFrame()\n","for data_filename in data_filenames:\n","    # Skip the file if we want to ignore it\n","    patient_name = data_filename[0:6]\n","    patient_type = data_filename[2:4]\n","    trial_id = data_filename[7:9]\n","    if (patient_type == 'Co') or (trial_id == '10') or not ('_' in data_filename):\n","        continue\n","\n","    # Generate the features\n","    result_dict = process_recording(data_filename)\n","\n","    # Add the patient's name as the identifier\n","    result_dict['ID'] = patient_name\n","    result_df = pd.DataFrame([result_dict])\n","    info_df = pd.concat([info_df, result_df], axis=0)\n","\n","# Set the index to the image name\n","info_df.set_index(['ID'], inplace=True)\n","info_df"],"metadata":{"id":"vyt2LUL7i1BC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Because some subjects had multiple recordings, their ID will appear multiple times in the index. That is usually not ideal for ensuring that that the each index uniquely points to a single row; however, we are only going to be using the index to combine information about subjects' recordings with their UPDRS scores, so this will not be a big issue."],"metadata":{"id":"Qf_a0kMog3dx"}},{"cell_type":"code","source":["info_df.loc['JuPt15']"],"metadata":{"id":"nEoBx891hZhT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["On that note, the demographic information about our subjects is provided in an `.xls` file (note: they are also provided in a tab-limited `.txt` file, but that file has a formatting issue). Let's load this file and see what it looks like:"],"metadata":{"id":"CvWsGcLPkXvy"}},{"cell_type":"code","source":["demo_df = pd.read_excel(demo_filename, index_col='ID')\n","demo_df"],"metadata":{"id":"Xkr2TodFhmN8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This file contains many different columns, but we are only going to concern ourselves with the UPDRSM score (i.e., UPDRS Part III) for now."],"metadata":{"id":"L5lpU6etOgHd"}},{"cell_type":"markdown","source":["We are going to do a few things to make this `DataFrame` better serve our needs:\n","1. We will get rid of all of the rows corresponding to healthy controls\n","2. We will get rid of all of the columns except for the index and the UPDRSM score."],"metadata":{"id":"nCIOkgRulnca"}},{"cell_type":"code","source":["# Keep only patient data\n","demo_df = demo_df[demo_df['Group'] == 'PD']\n","\n","# Get rid of unnecessary columns\n","score_df = demo_df['UPDRSM']\n","score_df"],"metadata":{"id":"2e_PIVlqk6CT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We now have two `DataFrames` (or technically, a `DataFrame` and a `Series`):\n","1. `info_df`, which holds all of the characteristics we have extracted from our recordings\n","2. `score_df`, which holds the UPDRSM scores associated with the subjects\n","\n","To combine them together, we can use the function `pd.merge()`, which combines the information across two `pandas` structures according to a shared index or column. Since we have set the index of `info_df` and `score_df` to be the subject ID, we can use this column as our reference for merging."],"metadata":{"id":"o3X2B4qVY32p"}},{"cell_type":"markdown","source":["It is important to note that each subject completed multiple trials. If we just do a plain `pd.merge()`, also known as an ***inner join***, we will only have a single row for each subject since that is the list of indices that both `DataFrames` have in common. If we want to have a single row per recording, we will need to do a single-sided join."],"metadata":{"id":"L9kqC0cwujpw"}},{"cell_type":"markdown","source":["Imagine that we have `score_df` on the left and `info_df` on the right. A ***left join*** would result in a `DataFrame` with the same indices `demo_df`, but it will add all of the information associated with those indices from `info_df`. A ***right join*** would do the opposite."],"metadata":{"id":"UbfEJvVk0Wal"}},{"cell_type":"code","source":["df = pd.merge(score_df, info_df, how='right', left_index=True, right_index=True)\n","df"],"metadata":{"id":"IGmw_RJsZXqg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can confirm this worked by making sure that we still have multiple entries for subjects who contributed multiple trials."],"metadata":{"id":"oUdwPNtliybk"}},{"cell_type":"code","source":["df.loc['JuPt15']"],"metadata":{"id":"g-MWmRa8jgSE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["It is also important to note that some subjects did not complete the UPDRS, so they will have `NaN` as their entry under that column. We will get rid of those rows so that we do not have to deal with missing data:"],"metadata":{"id":"OwnUd9lTqDAv"}},{"cell_type":"code","source":["df = df[~pd.isna(df['UPDRSM'])]\n","df"],"metadata":{"id":"jaPC5o17qb1C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exploring Our Recording Characterstics"],"metadata":{"id":"_x89cEEcycSt"}},{"cell_type":"markdown","source":["At this point, you could export your `DataFrame` into a `.csv` and explore the image characteristics using any tool that you desire (e.g., R, Excel). Nevertheless, we're going to stick with Python to explore our processed dataset."],"metadata":{"id":"6osH7tZCd_ZA"}},{"cell_type":"markdown","source":["To make it easy for us to test all of the relevant columns in our `DataFrame`, we will generate a list that holds all of the names of our recording characteristics:"],"metadata":{"id":"5e2m_BjpWV_X"}},{"cell_type":"code","source":["characteristics = list(info_df.columns)\n","characteristics"],"metadata":{"id":"a6nzJMa0WHS-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Descriptive Statistics"],"metadata":{"id":"QxpSzGO1ypCX"}},{"cell_type":"markdown","source":["Let's start by extracting some descriptive statistics from our data. We can use the `.describe()` method to compute statistics like the mean and range for each column in our entire `DataFrame`:"],"metadata":{"id":"NudnzYD0DfRP"}},{"cell_type":"code","source":["df.describe()"],"metadata":{"id":"NSYi6Bw3Dgh7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Using these results, we can get a sanity check of whether the values we are calculating follow our expectations. Here are some example observations:\n","* **Single foot 95th percentile VGRF**: Nearly of the recordings have VGRF values that go as high as 950 N while a person is walking.\n","* **Difference in cadence**: For the most part, subjects have a neglible difference between the cadence of their left and right feet. This makes sense considering most people walk at an even pace.\n"],"metadata":{"id":"TiG1MOF9EHQY"}},{"cell_type":"markdown","source":["## Histograms"],"metadata":{"id":"4Uap4StJe2WX"}},{"cell_type":"markdown","source":["Although descriptive statistics can distill a lot of data into a small handful of numbers, they can also hide important information about the distribution of our data. Therefore, it can be helpful to generate histograms of our recording characteristics."],"metadata":{"id":"mW96Qn1FFF94"}},{"cell_type":"markdown","source":["The most intuitive way of generating histograms is by calling the corresponding `matplotlib` function. Since we have lots of recording characteristics, we will only display the histograms for the first five:"],"metadata":{"id":"P1TERuRRKxpr"}},{"cell_type":"code","source":["def generate_histogram(df, col):\n","    plt.figure(figsize=(3,3))\n","    plt.hist(df[col], bins=20, color='blue', edgecolor='black',\n","            alpha=0.7)\n","    plt.xlabel(col)\n","    plt.ylabel('Frequency')\n","    plt.title(f'Histogram of {col}')\n","    plt.show()"],"metadata":{"id":"6v5o15ieuABC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for col in characteristics[:5]:\n","    generate_histogram(df, col)"],"metadata":{"id":"vp_YAvHeu86z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["If you are interested in shortcuts, `pandas` has built-in methods for generating histograms on `Series`:"],"metadata":{"id":"Fu3k0tGHMNPI"}},{"cell_type":"code","source":["def generate_histogram(df, col):\n","    plt.figure(figsize=(3,3))\n","    df[col].hist(bins=20, alpha=0.7, legend=True)\n","    plt.xlabel(col)\n","    plt.ylabel('Frequency')\n","    plt.title(f'Histogram of {col}')\n","    plt.show()"],"metadata":{"id":"HgjXw4q8xUaz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for col in characteristics[:5]:\n","    generate_histogram(df, col)"],"metadata":{"id":"N2R3qJD0xUaz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Correlations"],"metadata":{"id":"aA2s9Vvhermg"}},{"cell_type":"markdown","source":["Up until now, we have only looked at the distribution of individual recording characteristics without any other context. We have not looked at how they vary with respect to UPDRSM score."],"metadata":{"id":"3L_WOBRFjp7b"}},{"cell_type":"markdown","source":["One way we can do that is by calculating the correlation coefficient between the UPDRSM score and each recording characteristic. Visually, we can already tell that most of our variables are non-normally distributed. Therefore, we will calculate ***Spearman's rank-order correlation coefficient***. If we knew that our variables were normally distributed, we would use ***Pearson's correlation coefficient***. We can calculate these using functions in the `scipy` library."],"metadata":{"id":"ZVtdLUf2lsr4"}},{"cell_type":"code","source":["from scipy import stats\n","\n","for col in characteristics:\n","    r, p_value = stats.pearsonr(df[col], df['UPDRSM'])\n","    print(f\"Pearson r for {col}: {r:0.2f}, p-value is {p_value:0.3f}\")"],"metadata":{"id":"J_Kn01OgqzFV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can also also generate a graph illustrate the correlation between these pairs of variables. We will only look at one of the statistically significant pairs for brevity:"],"metadata":{"id":"Eb_xvIUDoYsP"}},{"cell_type":"code","source":["def show_correlation(df, col):\n","    plt.figure(figsize=(3,3))\n","    plt.plot(df[col], df['UPDRSM'], '*')\n","    plt.xlabel(col)\n","    plt.ylabel('UPDRSM')\n","    plt.title(f'Correlation between UPDRSM and \\n{col}')\n","    plt.show()"],"metadata":{"id":"48oLslE3lpk8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for col in characteristics[:5]:\n","    show_correlation(df, col)"],"metadata":{"id":"etVoweP_x25c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here are some example observations:\n","* **Weak correlations:** Nearly all of the correlation coefficient are between ±0.2, indicating that there isn't a single variable strongly associated with UPDRSM\n","* **Statistically significant results:** At the very least, we do see a few recording characteristics with statistically signficiant correlations, such as \"Single foot average VGRF\", \"Single foot average cadence\", and \"Difference power at high freqs\""],"metadata":{"id":"mPAAeTD1pDf3"}},{"cell_type":"markdown","source":["Although these results may be less than ideal for trying to predict a subject's UPDRSM score, that's okay! We're working with real data, and real data is usually messy. In the near future, we will see how machine learning can be used to make sense of this data to achieve that very task."],"metadata":{"id":"u4XNnT7zsXK_"}}]}