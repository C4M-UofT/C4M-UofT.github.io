{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DekAnzq1b82b",
        "xP4sP_ekZxqW",
        "GNveiKj-B0Mu",
        "buga415hls_2",
        "nCoHftTzHdY7",
        "HMxfBnunHbw-",
        "9EE0WYb4HaJx",
        "OGuqI2yadkun",
        "mxG8aDgyNXEE",
        "2gLiPr2p6ymF",
        "h6-LwnNSWE8B",
        "Z9oiFzp3FB69",
        "ldQCSnDbFE9q",
        "oBSGWZoFJGCu"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we're going to explore an image dataset containing benign and malignant skin lesions. The data is taken from a competition published by the [International Skin Imaging Collaboration (ISIC)](https://challenge.isic-archive.com/data/) in 2016."
      ],
      "metadata": {
        "id": "BDaO9cuMWe83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important: Run this code cell each time you start a new session!"
      ],
      "metadata": {
        "id": "DekAnzq1b82b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install os\n",
        "!pip install opencv-python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2"
      ],
      "metadata": {
        "id": "jrO0X1ZMxMN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -Ncnp https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part3_Training_Data.zip"
      ],
      "metadata": {
        "id": "bASFcdZNZuGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -n ISBI2016_ISIC_Part3_Training_Data.zip"
      ],
      "metadata": {
        "id": "2hP2UnPrcEdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -Ncnp https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part3_Training_GroundTruth.csv"
      ],
      "metadata": {
        "id": "hIBYeAPogvAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -Ncnp https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part1_Training_GroundTruth.zip"
      ],
      "metadata": {
        "id": "b3tho-Kt9q_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -n ISBI2016_ISIC_Part1_Training_GroundTruth.zip"
      ],
      "metadata": {
        "id": "Ebi3lsSm-poa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview of the Dataset"
      ],
      "metadata": {
        "id": "xP4sP_ekZxqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Skin cancer is caused by the uncontrolled growth of abnormal skin cells. There are several types of skin cancer, including basal cell carcinoma, squamous cell carcinoma, and melanoma. Regular self-examinations of the skin and annual skin checks with a dermatologist are crucial for early detection and treatment of skin cancer. However, even the most diligent people can struggle to discern malignant and benign skin lesions."
      ],
      "metadata": {
        "id": "uYdZYBDhBtwg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The overarching goal of the ISIC 2016 Challenge was to develop image analysis tools that automatically diagnose of melanoma from dermoscopic images. The dataset is composed of the following components which we have already downloaded:\n",
        "\n",
        "| Folder / File | Explanation |\n",
        "|:---------------|:-------------|\n",
        "|`ISBI2016_ISIC_Part3_Training_Data` | This folder contains a collection of of 1022 $\\times$ 767 px (w $\\times$ h) images gathered from distinct patients. The images files are named according to the following convention: `ISIC_{image_id}.jpg` (e.g., `ISIC_0000001.jpg`)|\n",
        "| `ISBI2016_ISIC_Part3_Training_GroundTruth.csv` | Each image was determined to be benign or malignant based on the judgment of a dermatologist, and this file holds those determinations. |\n",
        "| `ISBI2016_ISIC_Part1_Training_GroundTruth` | To save people time with their image analysis pipelines, the researchers provided black-and-white images indicating the precise borders of all the skin lesions. |"
      ],
      "metadata": {
        "id": "BBrNiJenan-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The relevant folders and files associated with this dataset\n",
        "image_folder = 'ISBI2016_ISIC_Part3_Training_Data'\n",
        "diagnosis_filename = 'ISBI2016_ISIC_Part3_Training_GroundTruth.csv'\n",
        "segmentation_folder = 'ISBI2016_ISIC_Part1_Training_GroundTruth'"
      ],
      "metadata": {
        "id": "tjO9wyZHMg9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we are going to see if we can extract useful information from the images to help us discriminate benign skin lesions from malignant ones."
      ],
      "metadata": {
        "id": "e8tQO6exj_sr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspecting the Dataset"
      ],
      "metadata": {
        "id": "GNveiKj-B0Mu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we start trying to extract information from our images, let's look at hand-selected examples of a benign skin lesion and a malignant skin lesion to see what we are working with."
      ],
      "metadata": {
        "id": "Z748xzvhFI5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load two pre-selected image files to show what they look like\n",
        "benign_filename = 'ISIC_0000000.jpg'\n",
        "malignant_filename = 'ISIC_0000002.jpg'\n",
        "benign_img = cv2.imread(os.path.join(image_folder, benign_filename))\n",
        "benign_img = cv2.cvtColor(benign_img, cv2.COLOR_BGR2RGB)\n",
        "malignant_img = cv2.imread(os.path.join(image_folder, malignant_filename))\n",
        "malignant_img = cv2.cvtColor(malignant_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Show the images and their labels\n",
        "plt.figure(figsize=(6, 3))\n",
        "plt.subplot(1, 2, 1), plt.imshow(benign_img), plt.title('Benign')\n",
        "plt.subplot(1, 2, 2), plt.imshow(malignant_img), plt.title('Malignant')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nlbjx-aIDbFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Properly segmenting a skin lesion from a image is difficult for multiple reasons:\n",
        "* Skin lesions can be red, brown, black, or purple, so a single color filter won't suffice\n",
        "* People can have different skin tones, so a dynamic brightness threshold wouldn't work either\n",
        "* Hair can cover skin lesions and make it more difficult to accurately detect edges"
      ],
      "metadata": {
        "id": "3AuuR-B8-RJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to skip this step and rely on image annotations provided by the ISIC challenge organizers. These annotations indicate where the skin lesion is according to a binary image where white pixels belong to the skin lesion and black pixels correspond to everything else."
      ],
      "metadata": {
        "id": "bKxZ3hG3BExA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the corresponding segmentation file\n",
        "benign_seg_filename = benign_filename[:-4] + '_Segmentation.png'\n",
        "benign_seg_img = cv2.imread(os.path.join(segmentation_folder, benign_seg_filename))\n",
        "benign_seg_img = cv2.cvtColor(benign_seg_img, cv2.COLOR_BGR2GRAY)\n",
        "malignant_seg_filename = malignant_filename[:-4] + '_Segmentation.png'\n",
        "malignant_seg_img = cv2.imread(os.path.join(segmentation_folder, malignant_seg_filename))\n",
        "malignant_seg_img = cv2.cvtColor(malignant_seg_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Show the image with its annotation\n",
        "plt.figure(figsize=(6, 3))\n",
        "plt.subplot(1, 2, 1), plt.imshow(benign_img), plt.title('RGB Image')\n",
        "plt.subplot(1, 2, 2), plt.imshow(benign_seg_img, cmap='gray'), plt.title('Annotation')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sBJV1uzcBcOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To extract the contour from the image on the right, all we need to do is call `cv2.findContours()` and return the first (and only) contour from the list:"
      ],
      "metadata": {
        "id": "7oUh3HrCBdpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_contour(seg_img):\n",
        "    \"\"\"\n",
        "    Extracts the lone contour from the image annotation\n",
        "    seg_img: a binary image representing an annotation\n",
        "    \"\"\"\n",
        "    cnts, hierarchy = cv2.findContours(seg_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    return cnts[0]"
      ],
      "metadata": {
        "id": "TgSG8O2e-aY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting Information from an Image"
      ],
      "metadata": {
        "id": "buga415hls_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Knowing the image processing techniques we've covered can only take us so far in extracting useful information from our images. Combining our understanding of image processing with some knowledge about dermatology will guide our analysis procedure and ultimately lead to a data science pipeline that is more interpretable for everyone."
      ],
      "metadata": {
        "id": "qR8lk7PkF-Jn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to use the ABCDE rule of dermatology to guide how we process our images. This rule is a handy tool that dermatologists use to visually screen for potential signs of melanoma. It stands for:\n",
        "\n",
        "* **Asymmetry (A):** Melanomas are often asymmetric, meaning one half of the mole or lesion does not mirror the other half.\n",
        "* **Border (B):** Melanomas typically have irregular, ragged, or blurred borders, rather than smooth and well-defined edges.\n",
        "* **Color (C):** Melanomas often exhibit a variety of colors within the same lesion, such as different shades of brown, black, red, or blue.\n",
        "* **Diameter (D):** Melanomas tend to be larger in size compared to benign moles. Although the exact threshold may vary, a diameter greater than 6 millimeters is often considered a warning sign.\n",
        "* **Evolution (E):** Any significant change in size, shape, color, or texture of a mole or lesion over time should be closely monitored.\n",
        "\n",
        "We will only be looking a single image of each skin lesion, so we will only be able to extract features representing the first four components of the rule."
      ],
      "metadata": {
        "id": "txTEh8fNYCB5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Knowing how to translate these English explanations into code is a difficult skill that comes with practice, exposure to a diverse toolbox of techniques, and a healthy amount of internet searching for code examples and academic papers. We will cover one way of extracting information related to each rule in order of increasing complexity, but bear in mind two things:\n",
        "\n",
        "1. There are likely alternative ways of implementing each rule that are just as valid.\n",
        "2. Some of these techniques are not going to be obvious at first glance, but this is a skill you will develop over time."
      ],
      "metadata": {
        "id": "zluEY9jcGmUH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Diameter (D)"
      ],
      "metadata": {
        "id": "nCoHftTzHdY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not all skin lesions are perfectly round. However, it is probably safe to assume that this rule is suggesting that the widest part of the skin lesion should not be larger than 6 millimeters. We can get this measurement by extracting the diameter of the minimum enclosing circle (i.e., the smallest circle that can enclose all of the contour's points)."
      ],
      "metadata": {
        "id": "0Igp_peFKFAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_diameter(cnt):\n",
        "    \"\"\"\n",
        "    Compute the radius of the skin lesion according to the min enclosing circle\n",
        "    cnt: the contour of the skin lesion\n",
        "    \"\"\"\n",
        "    _, r = cv2.minEnclosingCircle(cnt)\n",
        "    return 2*r"
      ],
      "metadata": {
        "id": "Bnz0KZtDCQ_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that this diameter is measured in pixels. If we wanted to report it in millimeters, we would need to know the scaling factor between pixels and millimeters (e.g., 15 px/mm). Ideally, there would be a ruler or grid with known spacing in every image that would enable us to calculate this scaling factor ourselves, but we do not have such a visual aid in our images. Instead, we will assume that all of the skin lesions are photographed at a constant but unknown scale. This means we will leave our measurements in pixels."
      ],
      "metadata": {
        "id": "vr8dR7ckNpwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Color (C)"
      ],
      "metadata": {
        "id": "HMxfBnunHbw-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we discussed earlier, there are many different color spaces we can use to describe the color of an object. For the sake of interpretability, we are going to use the HSV color space."
      ],
      "metadata": {
        "id": "-y5SAOK0KHXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to apply a function on an arbitrary subset of pixels within the image, we will first need to create a binary mask. Once we have done that, we can calculate the variation of pixel colors within the mask by calling `cv2.std()`, passing both the image in HSV and the binary mask."
      ],
      "metadata": {
        "id": "HXlA7sPqOx7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_color(img, seg_img):\n",
        "    \"\"\"\n",
        "    Compute the color standard deviation of the skin lesion within the contour\n",
        "    img: the image of the skin lesion\n",
        "    cnt: the binary mask of the skin lesion\n",
        "    \"\"\"\n",
        "    # Convert the image to HSV\n",
        "    hsv_img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "    # Compute the variation in HSV color\n",
        "    mean, stdev = cv2.meanStdDev(hsv_img, mask=seg_img)\n",
        "    return tuple(stdev.flatten())"
      ],
      "metadata": {
        "id": "ZOp5ASdMCMUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Border (B)"
      ],
      "metadata": {
        "id": "9EE0WYb4HaJx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The border rule is concerned with irregular, ragged, or blurred borders. Each of these terms have their own meanings, but we are going to focus on characterizing the jaggedness of a skin lesion."
      ],
      "metadata": {
        "id": "wVIJWIPfKH7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jagged contours require many points in order to define all their nooks and crannies, whereas smooth contours require fewer points. Therefore, we can establish the smoothness of a contour by comparing it to its own convex hull. As a reminder, the convex hull is the shape formed by connecting the outermost points in such a way that the resulting polygon is convex, meaning that no portion of the polygon bends inward.\n",
        "\n",
        "If a contour is jagged, then its convex hull is going to look very different since the convex hull cannot have any points that bend inward. If a contour is already smooth and convex, then it should look similar to its convex hull."
      ],
      "metadata": {
        "id": "KVYE2J5lTGT8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An example of a skin lesion and its convex hull are shown below. Notice that the two contours overlap where the lesion is smooth and are far apart where the lesion is jagged."
      ],
      "metadata": {
        "id": "fBDVGeoXe8tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the contour\n",
        "malignant_cnt = extract_contour(malignant_seg_img)\n",
        "\n",
        "# Simplify the contour using the convex hull\n",
        "hull = cv2.convexHull(malignant_cnt)\n",
        "\n",
        "# Draw the results\n",
        "output_img = malignant_img.copy()\n",
        "cv2.drawContours(output_img, [malignant_cnt], -1, (255, 0, 0), 5)\n",
        "cv2.drawContours(output_img, [hull], -1, (0, 255, 0), 5)\n",
        "\n",
        "# Show the results\n",
        "import matplotlib.lines as mlines\n",
        "line1 = mlines.Line2D([], [], color='red', linewidth=2, linestyle='-', label='Original')\n",
        "line2 = mlines.Line2D([], [], color='green', linewidth=2, linestyle='-', label='Convex Hull')\n",
        "plt.figure(figsize=(3,3))\n",
        "plt.imshow(output_img)\n",
        "plt.legend(handles=[line1, line2])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w8hGJWHHU5IS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "But how do we measure the similarity between the original contour and its convex hull? Since we know the contours are going to be relatively similar in their shape, we can compare them by taking the ratio of their perimeter. The more dissimilar the two shapes are, the further the ratio will be from 1. This relative measurement also helps us ensure that jaggedness does not depend on the size of the original contour."
      ],
      "metadata": {
        "id": "37FSwR_gdL27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To summarize, we will measure the jaggedness of the skin lesion by taking the ratio between the perimeter of its convex hull over the perimeter of its original contour. The more jagged the shape, the lower this ratio will be."
      ],
      "metadata": {
        "id": "P_e0QbBcY4Nb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_border(cnt):\n",
        "    \"\"\"\n",
        "    Compute the jaggedness of the skin lesion's border by comparing the\n",
        "    perimeter of the actual border to the perimeter of the convex hull\n",
        "    cnt: the contour of the skin lesion\n",
        "    \"\"\"\n",
        "    # Compute the perimeter\n",
        "    perimeter = cv2.arcLength(cnt, True)\n",
        "\n",
        "    # Calculate the convex hull\n",
        "    hull = cv2.convexHull(cnt)\n",
        "\n",
        "    # Compute the perimeter of the convex hull\n",
        "    simplified_perimeter = cv2.arcLength(hull, True)\n",
        "\n",
        "    # Return the ratio between the two\n",
        "    return simplified_perimeter / perimeter"
      ],
      "metadata": {
        "id": "nt_TUVgzc4gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Asymmetry (A)"
      ],
      "metadata": {
        "id": "OGuqI2yadkun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately, `opencv` does not have a simple function we can use to quantify the symmetry of a contour. At a high level, bilateral asymmetry entails comparing to \"halves\" of a shape. Those halves are defined by a straight line that runs through the \"middle\" of the shape. While this concept is relatively simple to describe in words, implementing it in code will be our most complicated exercise so far."
      ],
      "metadata": {
        "id": "qBAjey6VKITV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will start by first identifying an axis of symmetry. We can do this by fitting our contour to an ellipse and then extracting the ellipse's major axis. We can define a line according to a single point and an angle; in this case, the point will be the ellipse's center and the orientation of the ellipse will dictate the angle:"
      ],
      "metadata": {
        "id": "k63OsBHmBDvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "# Get the contour\n",
        "malignant_cnt = extract_contour(malignant_seg_img)\n",
        "\n",
        "# Fit it to an ellipse\n",
        "ellipse = cv2.fitEllipse(malignant_cnt)\n",
        "\n",
        "# Draw the fitted ellipse on the image\n",
        "output_img = malignant_img.copy()\n",
        "cv2.ellipse(output_img, ellipse, (255, 0, 0), 3)\n",
        "\n",
        "# Draw a line through the major axis\n",
        "center, (major_axis, minor_axis), angle = ellipse\n",
        "angle_rad = (angle-90) * (math.pi / 180)\n",
        "x1 = int(center[0] - minor_axis / 2 * math.cos(angle_rad))\n",
        "y1 = int(center[1] - minor_axis / 2 * math.sin(angle_rad))\n",
        "x2 = int(center[0] + minor_axis / 2 * math.cos(angle_rad))\n",
        "y2 = int(center[1] + minor_axis / 2 * math.sin(angle_rad))\n",
        "cv2.line(output_img, (x1, y1), (x2, y2), (255, 0, 0), 5)\n",
        "\n",
        "# Show the results\n",
        "plt.figure(figsize=(3,3))\n",
        "plt.imshow(output_img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vlnUkrN9zXaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've established an axis for establishing symmetry, we need to compare the contour's shape on either side. We can do this by reflecting the shape over the line we have and then comparing the pre- and post-reflected shapes. The more asymmetric the contour is, then the more dissimilar the pre- and post-reflected shapes will appear. Let's write some helper function to help us reflect a contour over a line:"
      ],
      "metadata": {
        "id": "3pCCE8b9zWSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flip_point(point, line_point, angle_deg):\n",
        "    \"\"\"\n",
        "    A helper function that reflects a point over an arbitrary line\n",
        "    This requires a lot of math, so don't worry if it's not intuitive\n",
        "    point: the point we are trying to reflect\n",
        "    line_point: a point that goes through the line\n",
        "    angle_deg: the angle that defines the slope of the line\n",
        "    \"\"\"\n",
        "    # Convert the angle from degrees to radians\n",
        "    angle_rad = math.radians(angle_deg)\n",
        "\n",
        "    # Calculate the coordinates of the point in a coordinate system where line_point is the origin\n",
        "    translated_point = (point[0] - line_point[0], point[1] - line_point[1])\n",
        "\n",
        "    # Rotate this coordinate system by an angle of -angle_rad\n",
        "    rotated_point = (translated_point[0]*math.cos(angle_rad) + translated_point[1]*math.sin(angle_rad),\n",
        "                     -translated_point[0]*math.sin(angle_rad) + translated_point[1]*math.cos(angle_rad))\n",
        "\n",
        "    # Reflect the point over the x-axis\n",
        "    reflected_point = (rotated_point[0], -rotated_point[1])\n",
        "\n",
        "    # Rotate the coordinate system back by an angle of angle_rad and translate back to original coordinate system\n",
        "    reflected_translated_back = (reflected_point[0]*math.cos(-angle_rad) + reflected_point[1]*math.sin(-angle_rad),\n",
        "                                 -reflected_point[0]*math.sin(-angle_rad) + reflected_point[1]*math.cos(-angle_rad))\n",
        "    final_point = (reflected_translated_back[0] + line_point[0], reflected_translated_back[1] + line_point[1])\n",
        "\n",
        "    return final_point"
      ],
      "metadata": {
        "id": "pYHPNxPYiCDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flip_contour(contour, center, angle_deg):\n",
        "    \"\"\"\n",
        "    A helper function reflects an entire contour over its major axis\n",
        "    contour: the contour\n",
        "    center: the center of the contour's fit ellipse\n",
        "    angle_deg: the angle of the contour's fit ellipse\n",
        "    \"\"\"\n",
        "    # Create an array to store the flipped contour points\n",
        "    flipped_contour = []\n",
        "\n",
        "    # Flip each point in the contour\n",
        "    for point in contour:\n",
        "        flipped_point = flip_point(point[0], center, angle_deg)\n",
        "        flipped_contour.append(flipped_point)\n",
        "\n",
        "    # Convert the flipped contour list to an array\n",
        "    flipped_contour = np.array(flipped_contour, dtype=np.int32).reshape(-1, 1, 2)\n",
        "\n",
        "    return flipped_contour"
      ],
      "metadata": {
        "id": "HzeNjrKl5umC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the contour\n",
        "malignant_cnt = extract_contour(malignant_seg_img)\n",
        "\n",
        "# Get the min enclosing ellipse\n",
        "center, axes, angle = cv2.fitEllipse(malignant_cnt)\n",
        "\n",
        "# Rotate the contour so that it is upright\n",
        "flipped_cnt = flip_contour(malignant_cnt, center, -angle)\n",
        "\n",
        "# Draw the results\n",
        "output_img = malignant_img.copy()\n",
        "cv2.drawContours(output_img, [malignant_cnt], -1, (255, 0, 0), 5)\n",
        "cv2.drawContours(output_img, [flipped_cnt], -1, (0, 255, 0), 5)\n",
        "\n",
        "# Show the results\n",
        "import matplotlib.lines as mlines\n",
        "line1 = mlines.Line2D([], [], color='red', linewidth=2, linestyle='-', label='Original')\n",
        "line2 = mlines.Line2D([], [], color='green', linewidth=2, linestyle='-', label='Flipped')\n",
        "plt.figure(figsize=(3,3))\n",
        "plt.imshow(output_img)\n",
        "plt.legend(handles=[line1, line2])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TXvAZ1qzBYeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To quantify the difference between the two contours, we are going to use a measurement called the Hausdorff distance. We are not going to concern ourselves with the details of this metric, but just know that such metrics exist:"
      ],
      "metadata": {
        "id": "Hv0Sh4tXnU-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cdist\n",
        "def get_hausdorff_distance(cnt1, cnt2):\n",
        "    \"\"\"\n",
        "    A helper function to compute the Haussdorf distance between two contours\n",
        "    cnt2: the first contour\n",
        "    cnt2: the second contour\n",
        "    \"\"\"\n",
        "    pts1 = np.array(cnt1).squeeze()\n",
        "    pts2 = np.array(cnt2).squeeze()\n",
        "    distances = cdist(pts1, pts2)\n",
        "    return np.max(np.min(distances, axis=0))"
      ],
      "metadata": {
        "id": "s2dQRvFFBfjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Hausdorff distance is sensitive to the size of the contours (i.e., larger contours will have larger distances). Therefore, we will need to account for this confound if we want to compare the asymmetry of two differently sized skin lesions. For simplicity, we will do this by dividing the Hausdorff distance by the diameter of the skin lesion."
      ],
      "metadata": {
        "id": "m3HSQPN9BZp4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When it's all said and done, this is the function we will use to quantify the asymmetry of a skin lesion:"
      ],
      "metadata": {
        "id": "7QV_T6l6oiZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_asymmetry(cnt):\n",
        "    \"\"\"\n",
        "    Compute the asymmetry of the skin lesion by comparing the contour with a\n",
        "    reflected version of itself\n",
        "    cnt: the contour of the skin lesion\n",
        "    \"\"\"\n",
        "    # Get the min enclosing ellipse\n",
        "    center, axes, angle = cv2.fitEllipse(cnt)\n",
        "\n",
        "    # Flip the contour of the ellipse's major axis\n",
        "    flipped_cnt = flip_contour(cnt, center, -angle)\n",
        "\n",
        "    # Measure the difference between the two contours as the Haussdorff distance\n",
        "    distance = get_hausdorff_distance(cnt, flipped_cnt)\n",
        "\n",
        "    # Scale the distance according to the diameter for fair comparison\n",
        "    _, r = cv2.minEnclosingCircle(cnt)\n",
        "    d = 2*r\n",
        "    return distance / d"
      ],
      "metadata": {
        "id": "FNZOOcXsdISL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing a Single Image"
      ],
      "metadata": {
        "id": "mxG8aDgyNXEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have helper functions to extract information from our images, let's put everything together into a single function. This function will take a single image as input and return all of the information calculated for that image as a `dict`."
      ],
      "metadata": {
        "id": "jnI4rsL6YeAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_img(filename):\n",
        "    \"\"\"\n",
        "    Process a skin lesion image and produce all of the features according to\n",
        "    the ABCD(E) rule as a dictionary (one value per key)\n",
        "    filename: the name of the skin lesion image without the file extension\n",
        "    \"\"\"\n",
        "    # Get the contour filename\n",
        "    rgb_filename = filename + '.jpg'\n",
        "    seg_filename = filename + '_Segmentation.png'\n",
        "\n",
        "    # Get both of the images (RGB and segmentation annotation)\n",
        "    img = cv2.imread(os.path.join(image_folder, rgb_filename))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    seg_img = cv2.imread(os.path.join(segmentation_folder, seg_filename))\n",
        "    seg_img = cv2.cvtColor(seg_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Get the contour\n",
        "    cnt = extract_contour(seg_img)\n",
        "\n",
        "    # Extract information from the image\n",
        "    asymmetry = compute_asymmetry(cnt)\n",
        "    border = compute_border(cnt)\n",
        "    color = compute_color(img, seg_img)\n",
        "    diameter = compute_diameter(cnt)\n",
        "\n",
        "    # Combine everything into a dictionary\n",
        "    info_dict = {'Asymmetry': asymmetry,\n",
        "                 'Border': border,\n",
        "                 'Color Stdev (H)': color[0],\n",
        "                 'Color Stdev (S)': color[1],\n",
        "                 'Color Stdev (V)': color[2],\n",
        "                 'Diameter': diameter}\n",
        "    return info_dict"
      ],
      "metadata": {
        "id": "-6Egsxlfil5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test our function\n",
        "filename = 'ISIC_0000000'\n",
        "process_img(filename)"
      ],
      "metadata": {
        "id": "6YynXU1C-J7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Our Processed Dataset"
      ],
      "metadata": {
        "id": "2gLiPr2p6ymF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To process all of our images, we will iterate through all of the files and call our `process_image()` function on each image. We will gather the results in a single `DataFrame`. Running this will take some time since we have lots of images."
      ],
      "metadata": {
        "id": "wXntyzHBC-tQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all the filenames but remove the extension\n",
        "img_filenames = os.listdir(image_folder)\n",
        "img_filenames = sorted([f[:-4] for f in img_filenames])\n",
        "\n",
        "# Iterate through the filenames\n",
        "info_df = pd.DataFrame()\n",
        "for img_filename in img_filenames:\n",
        "    # Generate the features\n",
        "    result_dict = process_img(img_filename)\n",
        "\n",
        "    # Add the image name\n",
        "    result_dict['Image Name'] = img_filename\n",
        "    result_df = pd.DataFrame([result_dict])\n",
        "    info_df = pd.concat([info_df, result_df], axis=0)\n",
        "\n",
        "# Set the index to the image name\n",
        "info_df.set_index(['Image Name'], inplace=True)\n",
        "info_df"
      ],
      "metadata": {
        "id": "vyt2LUL7i1BC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The diagnosis associated with each image is provided in a `.csv` file. Let's load it and see what it looks like:"
      ],
      "metadata": {
        "id": "CvWsGcLPkXvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diagnosis_df = pd.read_csv(diagnosis_filename, header=None)\n",
        "diagnosis_df.rename(columns={0: 'Image Name', 1: 'Diagnosis'}, inplace=True)\n",
        "diagnosis_df.set_index(['Image Name'], inplace=True)\n",
        "diagnosis_df"
      ],
      "metadata": {
        "id": "Xkr2TodFhmN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The index of this `DataFrame` is the name of each image file (without the extension), and the `DataFrame` has a lone column indicating the diagnosis associated with each image."
      ],
      "metadata": {
        "id": "X9WHluLPkeFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have two `DataFrames`:\n",
        "1. `info_df`, which holds all of the characteristics we have extracted from our images\n",
        "2. `diagnosis_df`, which holds the diagnoses associated with our images\n",
        "\n",
        "To combine them together, we can use the function `pd.merge()`, which combines the information across two `DataFrames` according to a shared index or column. Since we have set the index of each `DataFrame` to be the image name, we can use this column as our reference for merging."
      ],
      "metadata": {
        "id": "sy_edmVyi-0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.merge(info_df, diagnosis_df, left_index=True, right_index=True)\n",
        "df"
      ],
      "metadata": {
        "id": "IGmw_RJsZXqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring Our Image Characteristics"
      ],
      "metadata": {
        "id": "h6-LwnNSWE8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point, you could export your `DataFrame` into a `.csv` and explore the image characteristics using any tool that you desire (e.g., R, Excel). Nevertheless, we're going to stick with Python to explore our processed dataset."
      ],
      "metadata": {
        "id": "QxpSzGO1ypCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make it easy for us to test all of the relevant columns in our `DataFrame`, we will generate a list that holds all of the names of our image metrics:"
      ],
      "metadata": {
        "id": "5e2m_BjpWV_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = list(info_df.columns)\n",
        "metrics"
      ],
      "metadata": {
        "id": "a6nzJMa0WHS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descriptive Statistics"
      ],
      "metadata": {
        "id": "Z9oiFzp3FB69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start by extracting some descriptive statistics from our data. We can use the `.describe()` method to compute statistics like the mean and range for each column in our entire `DataFrame`:"
      ],
      "metadata": {
        "id": "NudnzYD0DfRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "NSYi6Bw3Dgh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using these results, we can get a sanity check of whether the values we are calculating follow our expectations. Here are some two example observations:\n",
        "* **Border**: All of these values are under 1, which makes sense since a contour should never be larger than its convex hull. Furthermore, over 75% of these values are above 0.81, which makes sense since we don't expect skin lesions to have too much jaggedness.\n",
        "* **Diameter**: At least 75% of these values are under 1022 px, which makes sense since that is the widest dimension of our images. However, notice how the largest diameter value is 3715 px. That's it is odd that we have a measurement\n"
      ],
      "metadata": {
        "id": "TiG1MOF9EHQY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While these observations are useful for verifying that our image processing techniques are working as expected, they don't tell us much about whether the characteristics we have calculated are useful for our target task: discerning benign skin lesions from malignant ones."
      ],
      "metadata": {
        "id": "ofnrnjLZEScH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One way we can do that is by splitting our `DataFrame` into two halves: one that contains the benign cases and another that contains the malignant cases. We can call the `.describe()` method on these `DataFrames` individually to see how they differ."
      ],
      "metadata": {
        "id": "bfDzsMktHJws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "benign_df = df[df['Diagnosis'] == 'benign']\n",
        "benign_df.describe()"
      ],
      "metadata": {
        "id": "W85yQeVAEfct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "malignant_df = df[df['Diagnosis'] == 'malignant']\n",
        "malignant_df.describe()"
      ],
      "metadata": {
        "id": "evVYGRANEoT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While splitting up the dataset in this way did not take much effort, there is a convenient method we can use called `.groupby()`. This method allows us to aggregate our data into groups according to one column and then apply another operation like `.describe()` on those groups independently. You will notice that the structure of this `DataFrame` will be very different, using tiered columns to report the results."
      ],
      "metadata": {
        "id": "p9DDGwCzEsnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('Diagnosis').describe()"
      ],
      "metadata": {
        "id": "ybymTSSrE1vG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in metrics:\n",
        "    print(col)\n",
        "    print(df.groupby('Diagnosis').describe()[col])\n",
        "    print('-----------------')"
      ],
      "metadata": {
        "id": "7bTT4nX_E7do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So what can we learn from looking at these numbers? Here are some example observations:\n",
        "* **Asymmetry:** According to multiple metrics (mean, 25%-75% percentile), it seems like the asymmetry scores of the malignant skin lesions tends to be higher than those of the benign skin lesions. This is something that we wanted to see, although we don't know whether it's significant or not.\n",
        "* **Diameter:** Similar observations can be made about the diameter as malignant skin lesions tended to be larger."
      ],
      "metadata": {
        "id": "6qwdxIP1Ja3P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Histograms"
      ],
      "metadata": {
        "id": "ldQCSnDbFE9q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although descriptive statistics can distill a lot of data into a small handful of numbers, they can also hide important information about the distribution of our data. Therefore, it can be helpful to generate histograms of our image characteristics."
      ],
      "metadata": {
        "id": "mW96Qn1FFF94"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to jump straight into generating separate histograms for benign and malignant skin lesions. The most intuitive way of doing this is by calling the requisite `matplotlib` functions on our manually split `DataFrames`:"
      ],
      "metadata": {
        "id": "P1TERuRRKxpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(3,3))\n",
        "plt.hist(benign_df['Diameter'], bins=20, color='blue', edgecolor='black',\n",
        "         alpha=0.7, label='Benign')\n",
        "plt.hist(malignant_df['Diameter'], bins=20, color='orange', edgecolor='black',\n",
        "         alpha=0.7, label='Malignant')\n",
        "plt.xlabel('Diameter')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.title('Histogram of Diameter')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "10sk8uvzK94F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are interested in shortcuts, `pandas` has built-in methods for generating histograms on `Series`. The code block below showcases this method, and we have run it on all of our columns to see the results."
      ],
      "metadata": {
        "id": "Fu3k0tGHMNPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_histograms(df, col):\n",
        "    plt.figure(figsize=(3,3))\n",
        "    grouped_df = df.groupby('Diagnosis')[col]\n",
        "    grouped_df.plot.hist(bins=20, alpha=0.7, legend=True)\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title(f'Histogram of {col}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "6v5o15ieuABC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in metrics:\n",
        "    compare_histograms(df, col)"
      ],
      "metadata": {
        "id": "vp_YAvHeu86z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is plenty we could do to make these graphs more informative (e.g., a couple of large outliers in the asymmetry scores is skewing those histograms). Still, these graphs can help us better appreciate the values we have calculated."
      ],
      "metadata": {
        "id": "onsZ7b1rMk1i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Statistical Tests"
      ],
      "metadata": {
        "id": "oBSGWZoFJGCu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far, we have been eyeballing the differences between our distributions. If we want to be more confident about whether these differences are meaningful, we can turn to statistical testing."
      ],
      "metadata": {
        "id": "3lkUh0k2N1bI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `scipy` package provides an assortment of statistical tests you may be familiar with from other courses. Since we are comparing two distributions of the same outcome variable, we will want to use a ***t-test*** if the data is normally distributed or a ***Mann-Whitney U test*** if the data is not normally distributed. To determine whether the data is normally distributed, we will use D'Agostino's K$^2$, but there are other alternatives that have their own tradeoffs."
      ],
      "metadata": {
        "id": "KZEEi5tpOYrS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function below checks the normality of the data in a given column and then applies the corresponding test of differences across the benign and malignant skin lesions."
      ],
      "metadata": {
        "id": "LaLoqOHXRHk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "def compare_distributions(df, col):\n",
        "    # Get the relevant data\n",
        "    data = df[col]\n",
        "    benign_data = df[df['Diagnosis'] == 'benign'][col]\n",
        "    malignant_data = df[df['Diagnosis'] == 'malignant'][col]\n",
        "\n",
        "    # Check of the data is normally distributed\n",
        "    statistic, p_value = stats.normaltest(data)\n",
        "    test = None\n",
        "    if p_value > 0.05:\n",
        "        # Data is normally distributed, use t-test\n",
        "        test = 't-test'\n",
        "        statistic, p_value = stats.ttest_ind(benign_data, malignant_data)\n",
        "    else:\n",
        "        # Data is not normally distributed, use Mann-Whitney U Test\n",
        "        test = 'Mann-Whitney U test'\n",
        "        statistic, p_value = stats.mannwhitneyu(benign_data, malignant_data)\n",
        "\n",
        "    print(f'Result of {test} for {col}: {statistic}, p-value is {p_value:0.3f}')"
      ],
      "metadata": {
        "id": "kUlm9qmPJHaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in metrics:\n",
        "    compare_distributions(df, col)"
      ],
      "metadata": {
        "id": "m3cscikbPXIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are some example observations:\n",
        "* **Asymmetry and Diameter:** The differences we observed earlier are statistically significant.\n",
        "* **Color Stdev (H, V):** We haven't commented on the color dimensions yet, but we also have some statistically significant differences here too. Looking at the descriptive statistics from earlier, we can see that the color variation in malignant skin lesions tends to be higher as expected.\n",
        "\n",
        "All in all, we can see some promising results here for trying to discriminate benign skin lesions from malignant ones! In the near future, we will see how these insights will be useful for developing a machine learning model to achieve that very task."
      ],
      "metadata": {
        "id": "avGn13VR1iOU"
      }
    }
  ]
}