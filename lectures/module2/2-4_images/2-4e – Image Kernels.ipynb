{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OBADxK39qJDx",
        "KitdrJL61mYs",
        "p0lQj077Eko5",
        "U_0yU6tLQNov",
        "Mf5YKt7rRdeB",
        "TOtTvkMCRrV3",
        "6GUlsffli92g",
        "Gx0z8advG-ty",
        "JyVWbjMMihoN",
        "UtD_kMxu_yBb"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we're going to talk about how we can manipulate and extract information from images using a sliding window."
      ],
      "metadata": {
        "id": "zKBYPS5L5yWH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important: Run this code cell each time you start a new session!"
      ],
      "metadata": {
        "id": "OBADxK39qJDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install os\n",
        "!pip install opencv-python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2"
      ],
      "metadata": {
        "id": "yuzcYs-MUBvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -Ncnp https://images.fineartamerica.com/images-medium-large-5/coloured-mri-scan-of-brain-in-sagittal-se-geoff-tompkinson.jpg"
      ],
      "metadata": {
        "id": "bASFcdZNZuGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "orig_file = os.path.join('coloured-mri-scan-of-brain-in-sagittal-se-geoff-tompkinson.jpg')\n",
        "\n",
        "os.rename(orig_file, 'color_mri.jpg')"
      ],
      "metadata": {
        "id": "R_p2CEmcxA5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sliding Windows with Images"
      ],
      "metadata": {
        "id": "KitdrJL61mYs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we talked about time-series data, we discussed the importance of using a sliding window to break down a sequence into smaller, more managable chunks. The sliding window had a width and stride that were both measured in time."
      ],
      "metadata": {
        "id": "SbLSpJ0XWiMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It turns out that similar considerations hold true for images. When we view a picture of a person's face, it feels like we recognize it as a face in an instant. However, our mind actually goes through the following process to reach within fractions of a second:\n",
        "* We see edges and smooth regions\n",
        "* Those visual features combine into corners\n",
        "* Those visual features combine into shapes (e.g., eyes and mouth)\n",
        "* Those visual features combine into an entire face\n",
        "\n",
        "In other words, we see visual features in small subregions of the image, and then we combine those visual features in our head to get a high-level understanding of the entire image."
      ],
      "metadata": {
        "id": "7eS5_KrGByTo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With image data, a sliding window is defined by its height, width, and stride in both directions. All of these parameters are measured in pixels.\n",
        "\n",
        "Sliding windows are often square in order to treat the height and width dimensions the same, so we really only care about the same two dimensions as before: window width and window stride."
      ],
      "metadata": {
        "id": "lTrAReeCCOs4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Play around with the animation below to see how a sliding window moves across an image:"
      ],
      "metadata": {
        "id": "tU_DiM0TNDlg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.animation as animation\n",
        "from matplotlib import rc\n",
        "rc('animation', html='jshtml')\n",
        "\n",
        "def show_animated_window(img, width, stride):\n",
        "    # Calculate bounds\n",
        "    h, w, _ = img.shape\n",
        "\n",
        "    # Create the figure and show the image\n",
        "    fig, ax = plt.subplots(figsize=(5, 3))\n",
        "    _ = ax.imshow(img)\n",
        "\n",
        "    # Create the animated box and add it to the graph\n",
        "    box = plt.Rectangle((0, 0), width, width,\n",
        "                        fill=True, color='orange', alpha=0.5)\n",
        "    ax.add_patch(box)\n",
        "\n",
        "    # Calculate and update the new box position\n",
        "    def update(frame):\n",
        "        max_windows_horiz = (w-width) // stride + 1\n",
        "        max_windows_vert = (h-width) // stride\n",
        "        new_x = (frame % max_windows_horiz) * stride\n",
        "        new_y = frame // max_windows_horiz * stride\n",
        "        box.set_x(new_x)\n",
        "        box.set_y(new_y)\n",
        "        return [box]\n",
        "\n",
        "    # Create the animation\n",
        "    num_windows = 20\n",
        "    anim = animation.FuncAnimation(fig, update, frames=range(num_windows), interval=1000)\n",
        "    return anim"
      ],
      "metadata": {
        "id": "F9KaXBqoEqJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_width = 100 #@param {name:\"test\", type:\"slider\", min:25, max:100, step:25}\n",
        "window_stride = 100 #@param {name:\"test\", type:\"slider\", min:25, max:100, step:25}\n",
        "\n",
        "img = cv2.imread('color_mri.jpg')\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "show_animated_window(img, window_width, window_stride)"
      ],
      "metadata": {
        "id": "F0-LzrUsGcYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Kernels"
      ],
      "metadata": {
        "id": "p0lQj077Eko5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An ***image kernel*** is a special kind of sliding window with a stride of 1 that applies a mathematical operation at every location of an image. The mathematical operation, called a ***convolution***, depends on the contents of the image kernel.\n",
        "\n",
        "The pseudocode for doing convolution with an image kernel is as follows:\n",
        "```\n",
        "initialize an empty image to store results\n",
        "\n",
        "for each position of the sliding window:\n",
        "   grab the subregion that is overlapped by the window\n",
        "   compute the element-wise product between the kernel and the subregion\n",
        "   compute the sum of those values\n",
        "   put that sum in the result image at the middle of the window\n",
        "```"
      ],
      "metadata": {
        "id": "3bJOiR_yHNO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The animation below illustrates this process. Notice that in order to get a value for every pixel in the result image, the sliding window needs to move outside of the bounary of the image where there are no values. There are various strategies that get used to address this boundary issue. In this particular animation, the values at the boundaries are simply repeated."
      ],
      "metadata": {
        "id": "v0C4AgAmSQvr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1Sey_Uj3Oxn1u4WZoFVoOJfp8dH-_I8cH\" width=300px/>"
      ],
      "metadata": {
        "id": "P9NdizDfA0-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function for applying a kernel to an image is `cv2.filter2D()`. This function takes the following parameters:\n",
        "* **img**: The image we want to process\n",
        "* **ddepth**: The depth of the resulting image in terms of number of channels and data format (e.g., `uint8`). Using `-1` will preserve the characteristics of the original image, applying the kernel to each color channel independently.\n",
        "* **kernel**: The 2D `numpy` array that defines the values in your kernel."
      ],
      "metadata": {
        "id": "jb0WPHNdQtt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function below will allow us to apply a kernel on an image (we will look at a colored MRI) and compare the results before and after the transformation."
      ],
      "metadata": {
        "id": "1K0FAnptVAuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the image\n",
        "img = cv2.imread('color_mri.jpg')\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "def apply_kernel(kernel, img_pre=img, img_post=None):\n",
        "    \"\"\"\n",
        "    kernel: the kernel that we would like to apply to the image\n",
        "    img_pre: the pre-kernel image if we generated it elsewhere\n",
        "    img_post: the post-kernel image if we generated it elsewhere\n",
        "    \"\"\"\n",
        "    if img_post is None:\n",
        "        # Apply the kernel\n",
        "        img_post = cv2.filter2D(img_pre, ddepth=-1, kernel=kernel)\n",
        "\n",
        "    # Display the results\n",
        "    plt.figure(figsize=(5, 3))\n",
        "    plt.subplot(1, 2, 1), plt.imshow(img_pre, cmap='gray'), plt.title('Pre-Kernel')\n",
        "    plt.subplot(1, 2, 2), plt.imshow(img_post, cmap='gray'), plt.title('Post-Kernel')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "8NLzrJhXQvjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following sections, we will discuss different kinds of kernels and their utility."
      ],
      "metadata": {
        "id": "XYJdnycDHbNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identity Kernel"
      ],
      "metadata": {
        "id": "U_0yU6tLQNov"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A 3 $\\times$ 3 identity kernel has the following structure:\n",
        "\n",
        "$\n",
        "\\begin{bmatrix}\n",
        "\t0 & 0 & 0 \\\\\n",
        "\t0 & 1 & 0 \\\\\n",
        "\t0 & 0 & 0 \\\\\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "As we increase the kernel size to a size $k$, all of the values remain 0 except for the value in the absolute center."
      ],
      "metadata": {
        "id": "cD_tqIRnQaLi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So what happens when we apply this filter to an image? The sum we put at each position of the result image is simply the value of the pixel in the middle of the kernel in the original image. Therefore, this identity kernel does nothing!"
      ],
      "metadata": {
        "id": "kuzNFUzQQqOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_size = 15 #@param {type:\"slider\", min:3, max:21, step:2}\n",
        "\n",
        "identity_kernel = np.zeros((kernel_size, kernel_size))\n",
        "identity_kernel[int(kernel_size/2), int(kernel_size/2)] = 1\n",
        "apply_kernel(identity_kernel)"
      ],
      "metadata": {
        "id": "dGWEPOoPVPBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Box Blur"
      ],
      "metadata": {
        "id": "Mf5YKt7rRdeB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A 3 $\\times$ 3 box kernel has the following structure:\n",
        "\n",
        "$\\frac{1}{9}\n",
        "\\begin{bmatrix}\n",
        "\t1 & 1 & 1 \\\\\n",
        "\t1 & 1 & 1 \\\\\n",
        "\t1 & 1 & 1 \\\\\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "As we increase the kernel size to a size $k$, all of the values remain 1, but the fraction multiplied at the beginning changes so that it is $\\frac{1}{k^2}$ ."
      ],
      "metadata": {
        "id": "dt_aVxUlRi71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By summing the values within the sliding window and then dividing by the quantity of numbers in the sum, we are calculating the average pixel value at that position. Like a moving average, this causes the image to become more blurred. The larger the kernel, the more significant the blurring."
      ],
      "metadata": {
        "id": "DyTg1eOYaPei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_size = 21 #@param {type:\"slider\", min:3, max:21, step:2}\n",
        "\n",
        "box_kernel = (1/kernel_size**2)*np.ones((kernel_size, kernel_size))\n",
        "apply_kernel(box_kernel)"
      ],
      "metadata": {
        "id": "BpQrchvpaonK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gaussian Blur Kernel"
      ],
      "metadata": {
        "id": "TOtTvkMCRrV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A 3 $\\times$ 3 Gaussian blur kernel has the following structure:\n",
        "\n",
        "$\\frac{1}{16}\n",
        "\\begin{bmatrix}\n",
        "\t1 & 2 & 1 \\\\\n",
        "\t2 & 4 & 2 \\\\\n",
        "\t1 & 2 & 1 \\\\\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "As we increase the kernel size to a size $k$, the values follow the equation for a 2D Gaussian curve:\n",
        "\n",
        "$f(x,y) = \\frac{1}{2\\pi\\sigma^2} e^{-\\frac{x^2 + y^2}{2\\sigma^2}}$\n",
        "\n",
        "where $\\sigma$ is the standard deviation along both dimensions."
      ],
      "metadata": {
        "id": "RNdyP6kmc1G1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This kernel is similar to the box kernel in that we are taking a weighted average of all the values in the image. However, greater importance is given to the values in the middle, and less importance is given to the values in the periphery."
      ],
      "metadata": {
        "id": "MMIHn1YUc1G3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating this kernel can be a bit of a pain. Fortunately, `opencv` provides a function called `cv2.GaussianBlur()` that automatically computes the kernel and applies it on our image:"
      ],
      "metadata": {
        "id": "kEa4N5GriIzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_size = 21 #@param {type:\"slider\", min:3, max:21, step:2}\n",
        "\n",
        "img = cv2.imread('color_mri.jpg')\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "blur_img = cv2.GaussianBlur(img, (kernel_size, kernel_size), sigmaX=10)\n",
        "\n",
        "apply_kernel(None, img_post=blur_img)"
      ],
      "metadata": {
        "id": "rk2ILJF6c1HA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unidirectional Edge Detection Kernel"
      ],
      "metadata": {
        "id": "6GUlsffli92g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are a couple different formulations for edge detection kernels. We will focus on a class of kernels called ***Sobel operators***. A 3 $\\times$ 3 Sobel operator for vertical edge detection has the following structure:\n",
        "\n",
        "$\n",
        "\\begin{bmatrix}\n",
        "\t-1 & 0 & 1 \\\\\n",
        "\t-2 & 0 & 2 \\\\\n",
        "\t-1 & 0 & 1 \\\\\n",
        "\\end{bmatrix}\n",
        "$"
      ],
      "metadata": {
        "id": "N-IJdfDL1AfY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the first time we've seen a kernel with a negative value. By having a mix of negative and positive values, we are taking the difference between values on opposite sides of the kernel, which essentially serves as a form of comparison. Mathematically, the Sobel operator approximates a derivative, or ***gradient***, in the direction opposite of the edges we are trying to detect. In this case, we are trying to find locations with large horizontal gradients in order to detect vertical edges.\n"
      ],
      "metadata": {
        "id": "7Cxeea4YzXqh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The table below enumerates the possible combinations that the kernel might encounter:\n",
        "\n",
        "| Left Side | Right Side | Convolution Result |\n",
        "|:--------------:|:-----------:|:-----------:|\n",
        "| Low values (dark) | Low values (dark) | Close to zero (no edge) |\n",
        "| Low values (dark) | High values (bright) | Very positive (edge) |\n",
        "| High values (bright) |Low values (dark) | Very negative (edge) |\n",
        "| High values (bright) | High values (bright) |  Close to zero (no edge) |"
      ],
      "metadata": {
        "id": "qVQAYpvO1ctJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to the Gaussian blur kernel, `opencv` provides a function for the Sobel operator called `cv2.Sobel()` that allows us to create multiple kinds of Sobel operators. Let's start with the vertical edge detector:"
      ],
      "metadata": {
        "id": "XzyDvnfw5Lfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_size = 3 #@param {type:\"slider\", min:3, max:7, step:2}\n",
        "\n",
        "vert_img = cv2.Sobel(img, ddepth=-1,\n",
        "                     dx=1, dy=0, ksize=kernel_size)\n",
        "\n",
        "apply_kernel(None, img_post=vert_img)"
      ],
      "metadata": {
        "id": "eG8Uly6Z1Afe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that this image is quite colorful. That's because we're applying this kernel to all three color channels separately and then combining the result. Let's apply this kernel to a grayscale image so that it's easier to interpret:"
      ],
      "metadata": {
        "id": "Xvr0Ed-hCJll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_size = 3 #@param {type:\"slider\", min:3, max:7, step:2}\n",
        "\n",
        "gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "sobelx_img = cv2.Sobel(gray_img, ddepth=-1,\n",
        "                       dx=1, dy=0, ksize=kernel_size)\n",
        "\n",
        "apply_kernel(None, img_pre=gray_img, img_post=sobelx_img)"
      ],
      "metadata": {
        "id": "b0UJhaiNDITF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's touch on the key observations:\n",
        "* The output is black wherever the original image was smooth\n",
        "* Along the right side of the head in particular, we can see prominent lines corresponding to edges.\n",
        "* Along the chin and the top of the head, the lines are not as prominent.\n",
        "\n",
        "Most of the edges in this image are not strictly horizontal or vertical. However, some are more vertical than others and vice versa. The more vertical the edge in the image, the more intense the color will be in that region after the Sobel operator."
      ],
      "metadata": {
        "id": "7wj1BStbAbaq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Sobel operator for horizontal edge detection takes a similar structure:\n",
        "\n",
        "$\n",
        "\\begin{bmatrix}\n",
        "\t1 & 2 & 1 \\\\\n",
        "\t0 & 0 & 0 \\\\\n",
        "\t-1 & -2 & -1 \\\\\n",
        "\\end{bmatrix}\n",
        "$"
      ],
      "metadata": {
        "id": "X49l57ne40ma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we can see how these results are similar to the ones we had with the vertical operator, only that the horizontal edges are highlighted more."
      ],
      "metadata": {
        "id": "sJh_LpcfIuuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_size = 3 #@param {type:\"slider\", min:3, max:7, step:2}\n",
        "\n",
        "gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "sobely_img = cv2.Sobel(gray_img, ddepth=-1,\n",
        "                       dx=0, dy=1, ksize=kernel_size)\n",
        "\n",
        "apply_kernel(None, img_pre=gray_img, img_post=sobely_img)"
      ],
      "metadata": {
        "id": "d_31haYrA1Hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a catch to the Sobel operator. Recall that the numbers in our image are stored as `uint8`, which stands for *unsigned* integers. Depending on whether the edge is going from black-to-white or white-to-black, one of the directions is going lead to negative number after the convolution. The way around this is by casting your array to a signed data type (e.g., signed 16-bit). However, we're going to forgo this exercise since there are better ways of finding edges."
      ],
      "metadata": {
        "id": "inKctx11GxKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Omnidirectional Edge Detection Kernel"
      ],
      "metadata": {
        "id": "Gx0z8advG-ty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chances are that you will want to detect edges along both directions at the same time. One way you can do this is by combining the results from the horizontal $S_x$ and vertical $S_y$ Sobel operators as follows:\n",
        "\n",
        "$S_{mag} = \\sqrt{S_x^2 + S_y^2}$\n",
        "\n",
        "$S_{angle} = \\arctan(\\frac{S_y}{S_x})$"
      ],
      "metadata": {
        "id": "AYFUjkwJES8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "# Apply the Sobel kernels\n",
        "sobelx_img = cv2.Sobel(gray_img, ddepth=-1,\n",
        "                       dx=1, dy=0, ksize=3)\n",
        "sobely_img = cv2.Sobel(gray_img, ddepth=-1,\n",
        "                       dx=0, dy=1, ksize=3)\n",
        "\n",
        "# Calculate the magnitude and the direction\n",
        "sobel_img_mag = np.sqrt(sobelx_img**2 + sobely_img**2)\n",
        "sobel_img_dir = np.arctan2(sobely_img, sobelx_img)\n",
        "\n",
        "# Show the results\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.subplot(1, 2, 1), plt.imshow(sobel_img_mag, cmap='gray'), plt.title('Magnitude')\n",
        "plt.subplot(1, 2, 2), plt.imshow(sobel_img_dir, cmap='gray'), plt.title('Angle')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EE-TPGCOHP8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, the quicker way of finding edges in multiple directions is by using a ***Laplacian operator***. As a 3 $\\times$ 3 kernel, the Laplacian operator has the following structure:\n",
        "\n",
        "$\n",
        "\\begin{bmatrix}\n",
        "\t0 & 1 & 0 \\\\\n",
        "\t1 & -4 & 1 \\\\\n",
        "\t0 & 1 & 0 \\\\\n",
        "\\end{bmatrix}\n",
        "$"
      ],
      "metadata": {
        "id": "ciHWusTaHDe7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the function `cv2.Laplacian()` as follows:"
      ],
      "metadata": {
        "id": "ZLry5G7EGKB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_size = 3 #@param {type:\"slider\", min:3, max:7, step:2}\n",
        "\n",
        "gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "laplace_img = cv2.Laplacian(gray_img, ddepth=-1,\n",
        "                            ksize=kernel_size)\n",
        "\n",
        "apply_kernel(None, img_pre=gray_img, img_post=laplace_img)"
      ],
      "metadata": {
        "id": "RS-QibRzGNUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sharpening Kernel"
      ],
      "metadata": {
        "id": "JyVWbjMMihoN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last kernel we will cover is a 3 $\\times$ 3 sharpening kernel, which takes the following structure:\n",
        "\n",
        "$\n",
        "\\begin{bmatrix}\n",
        "\t0 & -1 & 0 \\\\\n",
        "\t-1 & 5 & -1 \\\\\n",
        "\t0 & -1 & 0 \\\\\n",
        "\\end{bmatrix}\n",
        "$"
      ],
      "metadata": {
        "id": "i_HPiSVIinhW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to our Laplacian operator, this kernel produces high values whenever there are major differences between the middle point and those that surround it. However, this kernel emphasizes points whenver they have a significantly different value from those that surround it, causing it to enhance the edges that appear in the image."
      ],
      "metadata": {
        "id": "UUdT0ItiJ7B3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_size = 9 #@param {type:\"slider\", min:3, max:21, step:2}\n",
        "\n",
        "sharpen_kernel = np.zeros((kernel_size, kernel_size))\n",
        "sharpen_kernel[int(kernel_size/2), :] = -1\n",
        "sharpen_kernel[:, int(kernel_size/2)] = -1\n",
        "sharpen_kernel[int(kernel_size/2), int(kernel_size/2)] = (kernel_size-1)*2+1\n",
        "\n",
        "apply_kernel(sharpen_kernel)"
      ],
      "metadata": {
        "id": "bvlvR8Fuza2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A Precursor to Deep Learning"
      ],
      "metadata": {
        "id": "UtD_kMxu_yBb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although we have yet to extract useful summary data from our images, understanding kernels and convolutions is vital to understanding a slew of concepts you will encounter in digital signal processing and machine learning."
      ],
      "metadata": {
        "id": "S3pulNMABKD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The diagram below illustrates the architecture of a convolutional neural network (CNN) — the structure that many deep learning models rely upon to work with image data."
      ],
      "metadata": {
        "id": "Z9U6oRXE7Vf1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1aYq_6S6Plf2NFlFipAYdZbcuv00Z9jUe\" width=500px/>"
      ],
      "metadata": {
        "id": "to9G-so2BDOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first stage of the model (on the left), passes a series of kernels along the input image and produces a series of new images that encode different characteristics of the input. The second stage repeats the same process, but the input to this process is now the output from the previous stage. As the model goes through multiple stages, it is gradually able to combine features across the entire image, similar to how we need to see eyes and mouths before we can identify faces."
      ],
      "metadata": {
        "id": "wCP_OmmO8xvs"
      }
    }
  ]
}