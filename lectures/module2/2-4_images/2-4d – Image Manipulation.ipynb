{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OBADxK39qJDx",
        "_vfpAdxZ1WEE",
        "JLL49OZM1fwy",
        "nHXvty4mLG64",
        "1wApF--11jTc"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we're going to talk about how we can load and manipulate image files."
      ],
      "metadata": {
        "id": "zKBYPS5L5yWH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important: Run this code cell each time you start a new session!"
      ],
      "metadata": {
        "id": "OBADxK39qJDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install os\n",
        "!pip install opencv-python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2"
      ],
      "metadata": {
        "id": "yuzcYs-MUBvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -Ncnp https://images.fineartamerica.com/images-medium-large-5/coloured-mri-scan-of-brain-in-sagittal-se-geoff-tompkinson.jpg"
      ],
      "metadata": {
        "id": "bASFcdZNZuGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "orig_file = os.path.join('coloured-mri-scan-of-brain-in-sagittal-se-geoff-tompkinson.jpg')\n",
        "\n",
        "os.rename(orig_file, 'color_mri.jpg')"
      ],
      "metadata": {
        "id": "R_p2CEmcxA5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Images"
      ],
      "metadata": {
        "id": "_vfpAdxZ1WEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you have seen in some of our earlier notebooks, we can load images using the function `cv2.imread()`. The function returns the image as a `numpy` array of `uint8` values. Let's open an image of an MRI:"
      ],
      "metadata": {
        "id": "etOXHgGi1Xjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('color_mri.jpg')\n",
        "\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "crPIC8ID2m7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that this image doesn't look atypical heatmap. `opencv` actually loads images in BGR (blue-green-red) rather than in RGB (red-green-blue). This is because hardware and software manufacturers historically represented color images in the BGR format, and this convention is baked into `opencv`."
      ],
      "metadata": {
        "id": "G6nXjxqP2tm-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`opencv` has its own function for displaying BGR images as you would expect: `cv2.imshow()`. However, this function does not interface well with Jupyter notebooks, so Google Colab provides a function called `cv2_imshow()` that achieves the same functionality:"
      ],
      "metadata": {
        "id": "FlTaOlUpAwOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "iC5Jbq0GA8Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Still, working with images in BGR can be counterintuitive considering that the standard is now RGB. Therefore, it's usually good practice to convert your image from BGR to RGB immediately after loading it:"
      ],
      "metadata": {
        "id": "234-1Vx5BLCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.imshow(img_rgb)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lWCrGZTd3SUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that this conversion is actually fairly straightforward, as all it is doing is switching the first and third color channels."
      ],
      "metadata": {
        "id": "h4U9Kbeh3vAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The manual way of converting from BGR to RGB\n",
        "img = cv2.imread('color_mri.jpg')\n",
        "img_b = img[:, :, 0].copy()\n",
        "img[:, :, 0] = img[:, :, 2]\n",
        "img[:, :, 2] = img_b\n",
        "\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o9GqBVovBnPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want to compute the dimensions of our image, we can pull them from the attribute `.shape`:"
      ],
      "metadata": {
        "id": "nZP-3XA9IIvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# h, w, ch = img.shape\n",
        "h = img.shape[0]\n",
        "w = img.shape[1]\n",
        "ch = img.shape[2]\n",
        "print(f'Height: {h}, Width: {w}, Number of color channels: {ch}')"
      ],
      "metadata": {
        "id": "bSbz27d9IVOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cropping"
      ],
      "metadata": {
        "id": "JLL49OZM1fwy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since images are encoded as `numpy` arrays, cropping is as simple as slicing the array according to a set of indeces. Remember that `numpy` indexing requires specifying rows before columns. That means slicing an array should take the form `img[startY:endY, startX:endX]`, where `(startX, startY)` and `(endX, endY)` are the top-left and bottom-right corners respective of our ***region of interest (ROI)***, i.e., the subset of the image that is relevant or significant for further analysis."
      ],
      "metadata": {
        "id": "y3Rja9ol1i3d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you already know the corners of your ROI, you can simply use the syntax described above to crop:"
      ],
      "metadata": {
        "id": "zqc_ALjICbGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "startX = 50 #@param {type:\"slider\", min:0, max:850, step:50}\n",
        "startY = 50 #@param {type:\"slider\", min:0, max:850, step:50}\n",
        "endX = 150 #@param {type:\"slider\", min:0, max:850, step:50}\n",
        "endY = 150 #@param {type:\"slider\", min:0, max:850, step:50}\n",
        "\n",
        "# Check that the crop is valid\n",
        "if startX >= endX or startY >= endY:\n",
        "    raise Exception('Invalid slice')\n",
        "\n",
        "# Draw the crop region on an image copy\n",
        "img_rect = cv2.rectangle(img.copy(), (startX, startY), (endX, endY),\n",
        " (0, 255, 0), 10)\n",
        "\n",
        "# Extract the ROI\n",
        "img_crop = img[startY:endY, startX:endX]\n",
        "\n",
        "# Show the results\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.subplot(1, 2, 1), plt.imshow(img_rect), plt.title('Original')\n",
        "plt.subplot(1, 2, 2), plt.imshow(img_crop), plt.title('Cropped')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eg2xsVjw4H9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In other situations, however, you might find it more helpful to explain the ROI according to a single coordinate and the size of the box. Let's say we know the top-left corner and the size of our ROI. We could then do the following:"
      ],
      "metadata": {
        "id": "09xpjL3NDQDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "startX = 50 #@param {type:\"slider\", min:0, max:850, step:50}\n",
        "startY = 50 #@param {type:\"slider\", min:0, max:850, step:50}\n",
        "width = 500 #@param {type:\"slider\", min:0, max:850, step:50}\n",
        "height = 500 #@param {type:\"slider\", min:0, max:850, step:50}\n",
        "\n",
        "# Compute bottom right coordinate\n",
        "endX = startX + width\n",
        "endY = startY + height\n",
        "\n",
        "# Check that the crop is valid\n",
        "if endX >= img.shape[1] or endY >= img.shape[0]:\n",
        "    raise Exception('Invalid slice')\n",
        "\n",
        "# Draw the crop region on an image copy\n",
        "img_rect = cv2.rectangle(img.copy(), (startX, startY), (endX, endY),\n",
        " (0, 255, 0), 10)\n",
        "\n",
        "# Extract the ROI\n",
        "img_crop = img[startY:endY, startX:endX]\n",
        "\n",
        "# Show the results\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.subplot(1, 2, 1), plt.imshow(img_rect), plt.title('Original')\n",
        "plt.subplot(1, 2, 2), plt.imshow(img_crop), plt.title('Cropped')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iHKMuoDwDQsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resizing"
      ],
      "metadata": {
        "id": "nHXvty4mLG64"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To resize an image, we can use the function `cv2.resize()`:"
      ],
      "metadata": {
        "id": "2E5ggq4mLIXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "width = 75 #@param {type:\"slider\", min:0, max:850, step:50}\n",
        "height = 75 #@param {type:\"slider\", min:0, max:850, step:50}\n",
        "\n",
        "img_resize = cv2.resize(img, (width, height))\n",
        "\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.subplot(1, 2, 1), plt.imshow(img), plt.title('Original')\n",
        "plt.subplot(1, 2, 2), plt.imshow(img_resize), plt.title('Resized')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fbn5MCpDLGcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that this function does not care about the ***aspect ratio*** (i.e., the width-to-height ratio) of our original image. If we resize our image to a different aspect ratio, the image becomes stretched and distorted."
      ],
      "metadata": {
        "id": "aKd_lc0HPjd4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to resize your image while avoiding distortion, you will need to scale both dimensions by the same factor. If you do this, note that the `cv2.resize()` function requires that the new dimensions are specified as integers since there is no such thing as a fractional pixel."
      ],
      "metadata": {
        "id": "cCOrnqslQJh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scale_factor = 1.25 #@param {type:\"slider\", min:0.25, max:1.5, step:0.25}\n",
        "\n",
        "h, w, _ = img.shape\n",
        "new_h = int(h*scale_factor)\n",
        "new_w = int(w*scale_factor)\n",
        "img_resize = cv2.resize(img, (new_w, new_h))\n",
        "\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.subplot(1, 2, 1), plt.imshow(img), plt.title('Original')\n",
        "plt.subplot(1, 2, 2), plt.imshow(img_resize), plt.title('Resized')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fZWM7Rt9Qs2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rotating"
      ],
      "metadata": {
        "id": "1wApF--11jTc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While you likely won't need to rotate images very often for the sake of image analysis, it can be useful to know how to do it if you are given images in the wrong orientation. `opencv` does not provide a clean function for rotating images, but what it does provide is a function called `cv2.warpAffine()`. This function allows you to use matrix multiplication to map each point ($x$, $y$) in your original image to a new point ($x'$, $y'$) in a new image."
      ],
      "metadata": {
        "id": "gLBTACFT1ma5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`opencv` also provides a function called `cv2.getRotationMatrix2D()` that allows us to generate the matrix we would need to rotate an image by `angle` degrees around a point `center`. Positive angles rotate the image counter-clockwise, while negative angles rotate the image clockwise. Most of the time, we are going to want to rotate an image around the middle, so the code would look as follows:"
      ],
      "metadata": {
        "id": "GH4C8rf2UqEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "theta = 45 #@param {type:\"slider\", min:0, max:360, step:45}\n",
        "\n",
        "h, w, _ = img.shape\n",
        "center = (w // 2, h // 2)\n",
        "M = cv2.getRotationMatrix2D(center, angle=theta, scale=1.0)\n",
        "img_rotate = cv2.warpAffine(img, M, (w, h))\n",
        "\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.subplot(1, 2, 1), plt.imshow(img), plt.title('Original')\n",
        "plt.subplot(1, 2, 2), plt.imshow(img_rotate), plt.title('Rotated')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CoOP_LI2R81E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You'll notice that for angles that are not a multiple of 90$^\\circ$, some parts of the image get clipped and other parts of the image become black. That's because the size of the image array does not change during this process. Therefore, you will need to think carefully about the implications of rotating your image. For example, if you only care about the middle of the rotated image, you might consider cropping an ROI so that the result does not have any blank spaces."
      ],
      "metadata": {
        "id": "kA-YrNmnVeki"
      }
    }
  ]
}