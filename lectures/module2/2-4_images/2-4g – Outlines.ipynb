{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OBADxK39qJDx",
        "BFtg01-yN19g",
        "HY0uM-7q2OxE",
        "8Jiw531MglEC",
        "JS9o7KBLFLvB"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we're going to talk about some of the more sophisticated methods provided by `opencv` that we can used to detect edges and regions within an image."
      ],
      "metadata": {
        "id": "zKBYPS5L5yWH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important: Run this code cell each time you start a new session!"
      ],
      "metadata": {
        "id": "OBADxK39qJDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install os\n",
        "!pip install opencv-python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2"
      ],
      "metadata": {
        "id": "yuzcYs-MUBvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -Ncnp https://images.fineartamerica.com/images-medium-large-5/coloured-mri-scan-of-brain-in-sagittal-se-geoff-tompkinson.jpg"
      ],
      "metadata": {
        "id": "bASFcdZNZuGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "orig_file = os.path.join('coloured-mri-scan-of-brain-in-sagittal-se-geoff-tompkinson.jpg')\n",
        "\n",
        "os.rename(orig_file, 'color_mri.jpg')"
      ],
      "metadata": {
        "id": "R_p2CEmcxA5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Canny Edge Detection"
      ],
      "metadata": {
        "id": "BFtg01-yN19g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The edge detection kernels we looked at earlier simply generated a series of numbers that represented the prominence of the edges at each pixel of the image. However, this is a far cry from definitively telling us where the edges are and aren't. What we really want is a binary image with thin lines that trace around the major objects in our image."
      ],
      "metadata": {
        "id": "MbTP4VJtNtI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One way to do this is by using the ***Canny Edge Detection algorithm***. The steps of this algorithm are as follows:\n",
        "1. Smooth the image to reduce noise\n",
        "2. Apply Sobel operators to find the magnitude of the gradient at each location\n",
        "3. Use a technique called ***non-maximum suppression*** to identify the largest gradients near regions with lots of non-trivial gradients bunched together (e.g., thick edges)\n",
        "4. Threshold the gradients to keep only the prominent edges\n",
        "5. Reintroduce some pixels that would complete edges with gaps as long as they have a reasonably high gradient\n",
        "\n",
        "We've already covered how to perform steps 1, 2, and 4. The other steps are a bit more complicated, but fortunately, we don't need to do any of this ourselves."
      ],
      "metadata": {
        "id": "p5YH68W97CmO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`opencv` provides a function called `cv2.Canny()` that detects edges for us using this procedure. The function takes three parameters at minimum:\n",
        "1. **img:** A grayscale image from which we want to find edges\n",
        "2. **threshold1:** The minimum gradient magnitude of pixels that *could belong* to edges\n",
        "3. **threshold2:** The minimum gradient magnitude of pixels that *must belong* to edges\n",
        "\n",
        "Note that the input must be a grayscale image, as defining edges across multiple color channels can be ambiguous. The output of this function is a binary image that indicates the location of detected edges."
      ],
      "metadata": {
        "id": "Z1EzfFPJQ-ct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determining the two threshold values is typically a matter of trial-and-error. In general, lower threshold values will produce more edges. Play around with their values in the example below and see what you can come up with:"
      ],
      "metadata": {
        "id": "QSZ6eEoDBZ7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the image\n",
        "img = cv2.imread('color_mri.jpg')\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)"
      ],
      "metadata": {
        "id": "8rIWujzg_BiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold1 = 190 #@param {type:\"slider\", min:0, max:255, step:5}\n",
        "threshold2 = 235 #@param {type:\"slider\", min:0, max:255, step:5}\n",
        "\n",
        "# Check that the thresholds are reasonable\n",
        "if threshold1 >= threshold2:\n",
        "    raise Exception('threshold1 should be less than threshold2')\n",
        "\n",
        "# Apply the edge detector\n",
        "edges_img = cv2.Canny(gray_img, threshold1=threshold1, threshold2=threshold2)\n",
        "\n",
        "# Show the results\n",
        "plt.figure(figsize=(6, 3))\n",
        "plt.subplot(1, 2, 1), plt.imshow(gray_img, cmap='gray'), plt.title('Original Gray')\n",
        "plt.subplot(1, 2, 2), plt.imshow(edges_img, cmap='gray'), plt.title('Canny Edges')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Pk5rhHrHQaJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contour Detection"
      ],
      "metadata": {
        "id": "HY0uM-7q2OxE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Edges are great, but most people want to detect edges in order to find shapes. `opencv` provides a function called `cv2.findContours()` to extract the outlines of all the contiguous blobs in a image. This function requires a binary image (not just a grayscale one) in order to provide a clear definition of what is and isn't a meaningful shape."
      ],
      "metadata": {
        "id": "J8Jv31oLCHe2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`cv2.findContours()` is based on the following paper:\n",
        "\n",
        "> Suzuki, S. and Abe, K., Topological Structural Analysis of Digitized Binary Images by Border Following. CVGIP 30 1, pp 32-46 (1985)\n",
        "\n",
        "As the title of the paper implies, the algorithm involves tracing edges that can be readily identified in a binary image. The result is a list of ***contours*** that surround blobs of white pixels. Each contour is defined as a series of ($x$, $y$) coordinates that trace the boundary of the shape."
      ],
      "metadata": {
        "id": "_ISUBA9Nt64w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before talking about the parameters of the `cv2.findCountours()` function, it first helps to describe what it produces:\n",
        "1. **contours:** A list of detected contours\n",
        "2. **hierarchy:** An optional data structure that specifies which contours are contained in one another (e.g., a donut with an internal and external edge)"
      ],
      "metadata": {
        "id": "vDYlO2PuuJSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `cv2.findContours()` function requires the following parameters:\n",
        "1. **img:** The binary image from which we want to identify shapes\n",
        "2. **mode:** A special variable that specifies how the list of contours are arranged. For example, `cv2.RETR_EXTERNAL` retrieves only the extreme outer contours, `cv2.RETR_LIST` provides all of the contours in a list without any structure, and `cv2.RETR_TREE` provides a hierarchical structure that indicates which contours are contained in one another.\n",
        "3. **method:** A special variable that specifies how many data points are included in each contour. `cv2.CHAIN_APPROX_NONE` provides every point included in each contour, while  `cv2.CHAIN_APPROX_SIMPLE` provides the minimum number of points to accurately represent each contour."
      ],
      "metadata": {
        "id": "2QUqLMJ7Wrld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll also be using the function `cv2.drawContours()`, which requires the following parameters:\n",
        "1. **img:** The image onto which we want to draw the contours\n",
        "2. **contours:** The list of contours we want to draw (important: if you have one contour, it must be in a list)\n",
        "3. **contourIdx:** The index of the contour you want to draw within the list (-1 will draw all of them)\n",
        "4. **color:** The desired color of the contours that you draw\n",
        "5. **thickness:** The desired thickness of the contours that you draw (-1 will fill them in)"
      ],
      "metadata": {
        "id": "irtUlYXpjamk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are those two functions in action:"
      ],
      "metadata": {
        "id": "Kwg1cgT7ZWDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "brightness_threshold = 175 #@param {type:\"slider\", min:0, max:255, step:5}\n",
        "\n",
        "# Binarize the image to only keep the bright regions\n",
        "_, thresh_img = cv2.threshold(gray_img, brightness_threshold, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "# Locate the contours\n",
        "cnts, hierarchy = cv2.findContours(thresh_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Draw the contours on the original image\n",
        "output = gray_img.copy()\n",
        "output = cv2.cvtColor(output, cv2.COLOR_GRAY2RGB)\n",
        "cv2.drawContours(output, cnts, -1, (0, 255, 0), -1)\n",
        "\n",
        "# Show the results\n",
        "plt.figure(figsize=(6, 3))\n",
        "plt.subplot(1, 2, 1), plt.imshow(thresh_img, cmap='gray'), plt.title('Thresholded\\n Image')\n",
        "plt.subplot(1, 2, 2), plt.imshow(output), plt.title(f'Number of \\ncontours found: {len(cnts)}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T1CfvuvWFw3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the complexity of this image, we have quite a few contours:\n",
        "* Some contours are small and significant due to noise / speckling in the image\n",
        "* Some contours corresponding to individual regions of the brain are potentally and unintentionally split up into multiple subregions\n",
        "* Some contours are contained within others (e.g., parts of the brain that lie inside the skull)"
      ],
      "metadata": {
        "id": "Dea_-SPPIn83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We won't go through every possible technique we can do to improve our results, but here are a couple:\n",
        "1. Before we even threshold our image, we can smooth it out with a blur filter to reduce the noisiness of the binary image that goes into the `cv2.findContours()` function.\n",
        "2. Once the contours have been identified, we can check whether they satisfy a certain criteria (e.g., size, location)."
      ],
      "metadata": {
        "id": "yiWroq0DKJWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regarding the second point, there are a slew of contour properties we can calculate using `opencv`. Some of these properties are outlined below:\n",
        "\n",
        "| Function | Purpose |\n",
        "|:--------:|:-------|\n",
        "| `cv2.moments()` | Calculates properties of the contour's shape to identify features like the center of mass |\n",
        "| `cv2.contourArea()` | Calculates the area of the contour |\n",
        "| `cv2.arcLength()` | Calculates the perimeter of the contour |\n",
        "| `cv2.isContourConvex()` | Checks whether the shape is convex (i.e., all sides are curved outward) |\n",
        "| `cv2.convexHull()` | Approximates the shape of the contour as the smallest convex polygon containing all the given points |\n",
        "| `cv2.boundingRect()` | Calculates the smallest upright rectangle that will fit all the points in the contour |\n",
        "| `cv2.minAreaRect()` | Calculates the smallest rotated rectangle that will fit all the points in the contour |\n",
        "| `cv2.minEnclosingCircle()` | Calculates the smallest circle that will fit all the points in the contour |\n",
        "| `cv2.fitEllipse()` | Approximates the contour as an ellipse |"
      ],
      "metadata": {
        "id": "EAgeYKe3M9up"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To improve our contour detection algorithm from earlier, we will smooth our image and use `cv2.contourArea()` to ensure that we only keep reasonably-sized contours."
      ],
      "metadata": {
        "id": "y6vgEWODPMP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "brightness_threshold = 170 #@param {type:\"slider\", min:0, max:255, step:5}\n",
        "blur_kernel_size = 15 #@param {type:\"slider\", min:3, max:31, step:2}\n",
        "min_area = 1000 #@param {type:\"slider\", min:0, max:4000, step:500}\n",
        "max_area = 13000 #@param {type:\"slider\", min:0, max:15000, step:500}\n",
        "\n",
        "if min_area > max_area:\n",
        "    raise Exception(\"min_area should be less than max_area\")\n",
        "\n",
        "# Smooth the image\n",
        "blur_img = cv2.GaussianBlur(gray_img,\n",
        "                            ksize=(blur_kernel_size, blur_kernel_size), sigmaX=1)\n",
        "\n",
        "# Binarize the image to only keep the bright regions\n",
        "_, thresh_img = cv2.threshold(blur_img, brightness_threshold, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "# Locate the contours\n",
        "cnts, _ = cv2.findContours(thresh_img.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Only keep the contours that pass the size check\n",
        "final_cnts = []\n",
        "for cnt in cnts:\n",
        "    cnt_area = cv2.contourArea(cnt)\n",
        "    if min_area < cnt_area < max_area:\n",
        "        final_cnts.append(cnt)\n",
        "\n",
        "# Draw the contours on the original image\n",
        "output = gray_img.copy()\n",
        "output = cv2.cvtColor(output, cv2.COLOR_GRAY2RGB)\n",
        "cv2.drawContours(output, final_cnts, -1, (0, 255, 0), -1)\n",
        "\n",
        "# Show the results\n",
        "plt.figure(figsize=(6, 3))\n",
        "plt.subplot(1, 2, 1), plt.imshow(thresh_img, cmap='gray'), plt.title('Thresholded\\n Image')\n",
        "plt.subplot(1, 2, 2), plt.imshow(output), plt.title(f'Number of \\ncontours found: {len(final_cnts)}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uMSQE2vgPaZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Masking"
      ],
      "metadata": {
        "id": "8Jiw531MglEC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identifying contours allows us to isolate a region of interest (ROI) for further analyses. To enable this, many of the functions provided by `opencv` accept an optional `mask` parameter. By default, these functions assume that you want to compute the operation across the entire image. However, you can provide a ***binary mask*** where white pixels indicate the areas of interest to be selected and black pixels represent the areas to be ignored."
      ],
      "metadata": {
        "id": "_RcCxLtLgniE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The easiest way to create a binary mask is by generating a black image and then drawing a filled-in contour in white. The example below goes through this exact process for an arbitrarilty selected contour:"
      ],
      "metadata": {
        "id": "pwLrlJ63oIqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a random large contour\n",
        "blur_img = cv2.GaussianBlur(gray_img, ksize=(15, 15), sigmaX=1)\n",
        "_, thresh_img = cv2.threshold(blur_img, 170, 255, cv2.THRESH_BINARY)\n",
        "cnts, _ = cv2.findContours(thresh_img.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "largest_cnt, largest_cnt_size = [], 0\n",
        "for cnt in cnts:\n",
        "    cnt_area = cv2.contourArea(cnt)\n",
        "    if largest_cnt_size < cnt_area:\n",
        "        largest_cnt = cnt\n",
        "        largest_cnt_size = cnt_area\n",
        "\n",
        "# Recreate the binary mask using the contour\n",
        "mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
        "cv2.drawContours(mask, [largest_cnt], -1, (255), thickness=-1)\n",
        "\n",
        "# Show the results\n",
        "plt.figure(figsize=(6, 3))\n",
        "plt.subplot(1, 2, 1), plt.imshow(img), plt.title('Full Image')\n",
        "plt.subplot(1, 2, 2), plt.imshow(mask, cmap='gray'), plt.title('Binary Mask')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Uj3X636CgtWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To show this binary mask in action, we use it inside the function `cv2.mean()` in order to calculate the average color of the pixels only within the region of interest:"
      ],
      "metadata": {
        "id": "n2pms-jZhTSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the average RGB color\n",
        "avg_color = cv2.mean(img, mask=mask)[:3]\n",
        "avg_color = np.round(avg_color, 0)\n",
        "\n",
        "# Generate a masked image just to show where the computation is being done\n",
        "masked_img = cv2.bitwise_and(img, img, mask=mask)\n",
        "\n",
        "# Show the results\n",
        "plt.figure(figsize=(6, 3))\n",
        "plt.subplot(1, 2, 1), plt.imshow(img), plt.title('Full Image')\n",
        "plt.subplot(1, 2, 2), plt.imshow(masked_img), plt.title(f'Color within mask: {avg_color}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k0jS2zQAhTrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary"
      ],
      "metadata": {
        "id": "JS9o7KBLFLvB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "During this session, we went from talking about the color of a single pixel to identifying shapes in an entire image. These methods form the building blocks of many image processing pipelines."
      ],
      "metadata": {
        "id": "7e7cQmXwFQAf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even though deep learning has become the industry standard for performing tasks with images, being comfortable with thinking about images as multidimensional arrays will be a major step in working to that point."
      ],
      "metadata": {
        "id": "bQVq3U9Ag1h_"
      }
    }
  ]
}