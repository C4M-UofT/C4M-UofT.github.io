{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OBADxK39qJDx",
        "P0ObcD3agpum",
        "qY6X-NcFIDzT"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we're going to talk about different statistical methods for summarizing time-series data. We will cover a variety of Python libraries: some that we've already discussed (`numpy`, `pandas`) and then [`scipy`](https://scipy.org/) — a scientific computing library with many tools for digital signal processing.\n"
      ],
      "metadata": {
        "id": "Vj8n7JvdwZ8S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important: Run this code cell each time you start a new session!"
      ],
      "metadata": {
        "id": "OBADxK39qJDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install scipy\n",
        "!pip install os\n",
        "!pip install mne\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "import os\n",
        "import mne"
      ],
      "metadata": {
        "id": "yuzcYs-MUBvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -Ncnp https://physionet.org/files/chbmit/1.0.0/chb01/chb01_03.edf"
      ],
      "metadata": {
        "id": "Q8hsDyCZ8Hrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep track of useful information for the dataset\n",
        "sampling_rate_hz = 256\n",
        "eeg_col = 'FP1-F7'\n",
        "\n",
        "# Read in the data and create a time column\n",
        "edf = mne.io.read_raw_edf('chb01_03.edf')\n",
        "df = pd.DataFrame(edf.get_data().T, columns=edf.ch_names)\n",
        "df['Time'] = np.arange(0, df.shape[0])* (1/sampling_rate_hz)\n",
        "\n",
        "# Rename and keep useful columns\n",
        "keep_cols = ['Time', eeg_col]\n",
        "df = df[keep_cols]\n",
        "df.rename(columns={eeg_col: 'EEG'}, inplace=True)\n",
        "\n",
        "# Split off useful chunks of the recording according to annotations\n",
        "df = df[(df['Time']>=10) & (df['Time']<=15)]\n",
        "df['Time'] = df['Time'] - df['Time'].min()\n",
        "df.to_csv('eeg.csv',index=False)"
      ],
      "metadata": {
        "id": "3b4MgOU-8Rrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descriptive Statistics"
      ],
      "metadata": {
        "id": "P0ObcD3agpum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this notebook, we are going to look at a brief segment of EEG data recorded from a pediatric subject:"
      ],
      "metadata": {
        "id": "SOETuv2371Vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('eeg.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "NlRKW_VC76HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(df['Time'], df['EEG'])\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('EEG (V)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vE2sjy6T-_sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are some common statistical features you might encounter:\n",
        "\n",
        "| Statistic | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Equation &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;| Purpose |\n",
        "|:--------------:|:-----------:|:-------:|\n",
        "| Minimum | $\\displaystyle x_{min} = \\min(x_i)$ | Smallest value of the signal |\n",
        "| Maximum | $\\displaystyle x_{max} = \\max(x_i)$ | Largest value of the signal |\n",
        "| Mean | $\\displaystyle \\mu = \\frac{1}{n}\\sum_{i=1}^{n} x_i$ | Average value of the signal |\n",
        "| Standard deviation | $\\displaystyle \\sigma = \\left[ \\frac{1}{n-1}\\sum_{i=1}^{n} (x_i-\\mu)^2 \\right]^{1/2}$  | Signal variation |\n",
        "| Root mean square | $\\displaystyle x_{RMS} = \\left[ \\frac{1}{n}\\sum_{i=1}^{n} x_i^2 \\right]^{1/2}$ | Signal variation |\n",
        "| Skewness | $\\displaystyle x_{skew} = \\frac{\\sum_{i=1}^{n} (x_i-\\mu)^3}{(n-1)\\sigma^3} $ | Degree of asymmetry |\n",
        "| Kurtosis | $\\displaystyle x_{kurt} = \\frac{\\sum_{i=1}^{n} (x_i-\\mu)^4}{(n-1)\\sigma^4}$ | Degree of peakedness |"
      ],
      "metadata": {
        "id": "DQsNXEbNcg2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another set of descriptive statistics that is worth remembering is a ***percentile***, which is value below which a certain percent of numerical data falls. For example, the 0th-percentile is equivalent to the minimum because no values are lower than it, while the 100th-percentile is equivalent to the maximum because all values are lower than it.\n",
        "\n",
        "Percentiles can be useful for situations when we want to understand the range of our data without being overly sensitive to extreme outliers. Imagine that we are monitoring a patient's daily step count. If they typically take 5,000 $\\pm$ 500 steps a day but go on a hike on the weekend that took 15,000 steps, we may not want to count that hike when we are identifying the most steps that patient typically takes."
      ],
      "metadata": {
        "id": "Eo9w8oBSCACb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fortunately, many data science libraries — `numpy`, `pandas`, and `scipy` — provide functions and methods for most of the standard statistical measures you will likely need in order to summarize useful information about your time-series data."
      ],
      "metadata": {
        "id": "5haVBZq1g1_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Standard deviation: {np.std(df['EEG'])} V\")\n",
        "print(f\"0th percentile: {np.percentile(df['EEG'], 0)} V\")\n",
        "print(f\"50th percentile: {np.percentile(df['EEG'], 50)} V\")"
      ],
      "metadata": {
        "id": "KqHG6NpxGHgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember the code we wrote to make a peak detector earlier? `scipy` provides a much fancier one with all sorts of parameters we can configure, such as the required height of a valid peak or the minimum spacing between successive peaks."
      ],
      "metadata": {
        "id": "RC_IkOfGg4WT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import find_peaks\n",
        "min_height = 0.00002 #@param {type:\"slider\", min:1e-5, max:5e-5, step:1e-5}\n",
        "min_distance_samples = 50 #@param {type:\"slider\", min:25, max:100, step:25}\n",
        "\n",
        "times = df['Time'].values\n",
        "eeg = df['EEG'].values\n",
        "peaks, _ = find_peaks(eeg, height=min_height, distance=min_distance_samples)\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.plot(times, eeg)\n",
        "plt.plot(times[peaks], eeg[peaks], \"k*\")\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('EEG (V)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oZmxWok1iCtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are just some examples of the thousands of tools libraries provide to help you manipulate time-series data. We will touch on some more specific examples as we begin to work on other kinds of data (e.g., images, audio), but you should now have enough background to understand how to use much of what's available to you!"
      ],
      "metadata": {
        "id": "vM7zPBl_g5vg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descriptive Statistics Over Time"
      ],
      "metadata": {
        "id": "qY6X-NcFIDzT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use everything we've learned to extract meaningful information about our EEG signal. In this example, we want to identify periods of low- and high-activity levels as the signal evolves over time."
      ],
      "metadata": {
        "id": "IzREeOZUDDNX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the sake of simplicity, we are going to use a 0.5-second window with 0% overlap in order to split our signal into distinct chunks. For each window, we will compute the standard deviation to determine how much activity is happening in that part of the signal. We will apply a hand-selected threshold to see if that part of the signal has high or low variance, and we will label that chunk accordingly. The pseudocode for this algorithm is as follows:"
      ],
      "metadata": {
        "id": "7BzSr3Ogg3dI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "initialize our window\n",
        "add a DataFrame column to store the activity level\n",
        "assume that activity level is LOW for all samples\n",
        "\n",
        "while the window had not reached the end of the signal:\n",
        "    grab the data within the window\n",
        "    compute the standard deviation in the window\n",
        "    if it is above a threshold\n",
        "        set the activity level for that data to HIGH\n",
        "    move the window\n",
        "```"
      ],
      "metadata": {
        "id": "47FWrPRCgjo5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And this is one way we can implement this algorithm:"
      ],
      "metadata": {
        "id": "oH-p9ChcinDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_activity(df, width, threshold):\n",
        "    \"\"\"\n",
        "    df: a DataFrame containing EEG values over time\n",
        "    width: the width of the windows measured in seconds\n",
        "    threshold: the minimum threshold for high activity level\n",
        "    \"\"\"\n",
        "    # Initialize the start and end of the window\n",
        "    start_time = 0\n",
        "    end_time = start_time + width\n",
        "\n",
        "    # Set the stride to be the same as the width for 0% overlapping windows\n",
        "    stride = width\n",
        "\n",
        "    # Initialize the column for storing activity level\n",
        "    df['IsActivityHigh'] = False\n",
        "\n",
        "    # Stop generating windows if it would go past the end of the signal\n",
        "    signal_duration = df['Time'].max()\n",
        "    while end_time <= signal_duration:\n",
        "        # Grab the current window by filtering indexes according to time\n",
        "        row_selector = (df['Time'] >= start_time) & (df['Time'] <= end_time)\n",
        "        window_times = df['Time'][row_selector]\n",
        "        window_data = df['EEG'][row_selector]\n",
        "\n",
        "        # Calculate the activity level\n",
        "        window_activity_level = window_data.std()\n",
        "\n",
        "        # Update the activity level if it is high\n",
        "        if window_activity_level > threshold:\n",
        "            df.loc[row_selector, 'IsActivityHigh'] = True\n",
        "\n",
        "        # Move the window over by a stride\n",
        "        start_time += stride\n",
        "        end_time = start_time + width\n",
        "\n",
        "    # Show the activity level using transparency\n",
        "    plt.figure(figsize=(5,3))\n",
        "    plt.plot(df['Time'], df['EEG'])\n",
        "    for idx in range(1, df.shape[0]):\n",
        "        if df['IsActivityHigh'].iloc[idx]:\n",
        "            plt.axvspan(df['Time'].iloc[idx-1], df['Time'].iloc[idx],\n",
        "                        color='r', alpha=0.5, lw=0)\n",
        "        else:\n",
        "            plt.axvspan(df['Time'].iloc[idx-1], df['Time'].iloc[idx],\n",
        "                        color='g', alpha=0.5, lw=0)\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('EEG (V)')\n",
        "    plt.title('Activity Level (green = low, red = high)')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "xMaxHA2ixXy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_width = 0.5 #@param {type:\"slider\", min:0.5, max:1, step:0.25}\n",
        "activity_threshold = 0.00005 #@param {type:\"slider\", min:1e-5, max:5e-5, step:1e-5}\n",
        "classify_activity(df, window_width, activity_threshold)"
      ],
      "metadata": {
        "id": "44yh_j1frxFJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}