{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Gy4LKGAMk5pw",
        "nioZlzmj2CYT",
        "PmsHKqE72QLD",
        "crQxwokQ6wpT",
        "1YgRgmJG56n_",
        "RYZS80ej58yf",
        "etiLFaQV1wkC",
        "iYxGqrRS3U9B"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is a demo notebook for showcasing some of the steps required for training a convolutional neural network (CNN) for image classification. This particular model is designed to discriminate between parasitized and uninfected cells from the thin blood smear slide images of segmented cells in a dataset for [malaria detection](https://www.tensorflow.org/datasets/catalog/malaria).\n",
        "\n",
        "Note that this notebook is best run using a programming environment that is connected to a GPU. In Google Colab, you can check this by going to \"Runtime\" > \"Change Runtime Type\" and then selecting \"T4 GPU\". This notebook can work with other environments, but it also needs to include support for other software packages like `opencv`."
      ],
      "metadata": {
        "id": "cywoi2E62VEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important: Run this code cell each time you start a new session!"
      ],
      "metadata": {
        "id": "Gy4LKGAMk5pw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import copy\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tqdm.notebook import tqdm\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, UpSampling2D, Dropout, Concatenate, Input, Reshape, MaxPooling2D, Dense, Conv2DTranspose, Softmax, Flatten, BatchNormalization, Activation\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "xOyCRmw9R3nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Dataset"
      ],
      "metadata": {
        "id": "nioZlzmj2CYT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep learning requires lots of data for model training. Loading all of the training data at once can be extremely resource intensive for computers, making it nearly impossible to train on all of the data at the same time. Instead, we must instead feed the data into the model in small ***batches***.\n",
        "\n",
        "Larger batch sizes can lead to more stable updates to the model's parameters but require more memory, while smaller batch sizes can provide noisier updates but consume less memory."
      ],
      "metadata": {
        "id": "JA7znKxjr2CA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below prepares a data structure that will allow us to load the dataset. It then prepares a series of operations that will resize the images, apply one-hot encoding to the labels, and then load up the data in batches.\n",
        "\n",
        "Note that this function is not actually loading the data right away; it is simply creating the objects that will load the data on demand once we are ready to train."
      ],
      "metadata": {
        "id": "apZLfjJusdLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (100, 100)"
      ],
      "metadata": {
        "id": "vHNmAa4VkZnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.data.ops.dataset_ops import ShuffleDataset\n",
        "import copy\n",
        "\n",
        "def load_dataset(num_train_samples, batch_size):\n",
        "    # Create the objects that will load data for us on the fly\n",
        "    # Always use the last 20% of the data for testing\n",
        "    # Use num_train_samples for training\n",
        "    dataset_name = \"malaria\"\n",
        "    split_info = [f'train[:{num_train_samples}]', 'train[80%:]']\n",
        "    (ds_train, ds_test), ds_info = tfds.load(dataset_name, split=split_info,\n",
        "                                            with_info=True, as_supervised=True,\n",
        "                                            download=True, shuffle_files = True)\n",
        "\n",
        "    # Resize the images\n",
        "    ds_train = ds_train.map(lambda image, label: (tf.image.resize(image, image_size), label))\n",
        "    ds_test = ds_test.map(lambda image, label: (tf.image.resize(image, image_size), label))\n",
        "\n",
        "    # Convert the labels to one-hot encoding (e.g., 0 = [1, 0] and 1 = [0, 1])\n",
        "    def input_preprocess(image, label):\n",
        "        label = tf.one_hot(label, 2)\n",
        "        return image, label\n",
        "    ds_train = ds_train.map(input_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds_test = ds_test.map(input_preprocess)\n",
        "\n",
        "    # Prepare to load data in batches\n",
        "    ds_train = ds_train.batch(batch_size=batch_size, drop_remainder=True)\n",
        "    ds_test = ds_test.batch(batch_size=batch_size, drop_remainder=True)\n",
        "    return ds_train, ds_test"
      ],
      "metadata": {
        "id": "bweGki6-gchZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the data to see how it is formatted:"
      ],
      "metadata": {
        "id": "7nLcsYFSru6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train, ds_test = load_dataset(100, 5)\n",
        "for img_batch, label_batch in ds_train.take(1):\n",
        "    for img, label in zip(img_batch, label_batch):\n",
        "        img = img.numpy().astype(int)\n",
        "        plt.figure(figsize=(1, 1))\n",
        "        plt.imshow(img)\n",
        "        plt.title(f'Label: {label}')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "5-0Qx2dcvBH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the Model"
      ],
      "metadata": {
        "id": "PmsHKqE72QLD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to train a model, we first need to define its structure. Covering the ins and outs of this process will require nearly a semester's worth of lectures, so we are only going to discuss the process on a surface level."
      ],
      "metadata": {
        "id": "z2TMH8yhtLC6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Model Architecture"
      ],
      "metadata": {
        "id": "crQxwokQ6wpT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to going to use a ***convolutional neural network (CNN)***. This architecture is specifically designed for working with images. You might recall that we talked about this concept briefly when we discussed image kernels in the context of image processing."
      ],
      "metadata": {
        "id": "dAoXlPgKwdLg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1aYq_6S6Plf2NFlFipAYdZbcuv00Z9jUe\" width=500px/>"
      ],
      "metadata": {
        "id": "c4PRvBg_xduT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first stage of the model (on the left), passes a series of kernels along the input image and produces a series of new images that encode different characteristics of the input. The second stage repeats the same process, but the input to this process is now the output from the previous stage. As the model goes through multiple stages, it is gradually able to combine features across the entire image, similar to how we need to see eyes and mouths before we can identify faces."
      ],
      "metadata": {
        "id": "x-gVm7V-xgYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "1YgRgmJG56n_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training a deep learning model basically entails the following steps:\n",
        "1. Initialize the model's parameters (e.g., kernel weights) to some random values\n",
        "2. Use the model to generate predictions for a single batch of training data\n",
        "3. Measure the discrepancy between the predictions and the known labels for the batch\n",
        "4. Update the model's parameters depending on the discrepancy from step 3\n",
        "5. Repeat steps 2â€“4 until the model gets satisfactory performance"
      ],
      "metadata": {
        "id": "lP0fC3N06AFp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An apt analogy for this process might be learning multiplication tables from flash cards. When someone goes through the flash cards for the first time, they may get most of the answers wrong. As they go thorugh the same cards over and over, they hopefully adjust their understanding of multiplication to the point when they get most of the answers right."
      ],
      "metadata": {
        "id": "r2ojhXYUR-0Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All of these steps have significant nuance that we could discuss, but let's focus on steps 3 and 4. At any given moment during model training, bigger discrepancies between the model's predictions and the known labels should result in larger updates to the model; otherwise, the model isn't learning to improve itself. What this means is that the way we measure the discrepancy is very important."
      ],
      "metadata": {
        "id": "K-3FaEJnRIFG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most intuitive thing to do is to measure model performance using the metrics we've discussed already (e.g., mean-absolute error for regression, and accuracy for classification). However, there are flaws if we were to use some of these metrics to guide model training. Take classification accuracy for example. By using accuracy, a prediction for a single data point can either be right or wrong, nothing in between; there is no notion of being \"closer or further to the right answer\". Because this metric is so rigid, it's difficult to reflect when the model is making marginal improvements that will eventually get it to make the right predictions."
      ],
      "metadata": {
        "id": "HjJnvipFSaRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This leads to the idea of a ***loss function***. Like the performance metrics we've discussed already, a loss function measures the inconsistency between model predictions and known labels for a given batch, but it does so in a way that helps guide model training. The ultimate goal of model training is to minimize the loss, which should eventually result in improved performance."
      ],
      "metadata": {
        "id": "NEtEQazG6FEC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are different types of loss functions, each designed for specific types of machine learning tasks. For example, mean squared error (MSE) is often used for regression tasks, while something called ***categorical cross-entropy*** is used for multi-class classification tasks. We aren't going to go into this function in detail, but just know that it addresses the limitations of classification accuracy mentioned earlier."
      ],
      "metadata": {
        "id": "hJi0TwNR6IYB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning"
      ],
      "metadata": {
        "id": "RYZS80ej58yf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning model weights from scratch can take a significant amount of time and training data. However, we don't need to start from scratch. We can take advantage of a concept called ***transfer learning*** (or pre-training), where knowledge gained from solving one problem is applied to a different but related problem. In the case of images, we can rely on the fact that learning about edges, corners, and other shapes to classify images in one dataset may be useful for performing another image classification task, even if the datasets are distinct."
      ],
      "metadata": {
        "id": "t3BwbtC70UeI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For our specific problem, we are going to start with a CNN model called [EfficientNet](https://arxiv.org/abs/1905.11946) that was trained on the [ImageNet](https://image-net.org/) dataset. ImageNet is one of the foundational datasets that accelerated the evolution of deep learning models for images. If you look at the dataset, you'll notice that it contains images of generic objects like cats, dogs, and planes. Even though our target problem is very different, learning basic visual features from this dataset is better than starting completely from scratch."
      ],
      "metadata": {
        "id": "nS45L9A-2J9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we will see shortly, deep learning models have thousands of parameters that get learned during model training. We could use EfficientNet as a starting point and update all of the parameters when we introduce our data, but this could undo some of the benefits of transfer learning. Instead, we are going to force part of the model to stay \"frozen\" and create some extra layers at the end so that the it can be customized to our problem."
      ],
      "metadata": {
        "id": "PPdknPbB145b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the Entire Model"
      ],
      "metadata": {
        "id": "etiLFaQV1wkC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is defined using the code below. We don't have enough time to talk about each and every line, but the key steps are explained in the comments:"
      ],
      "metadata": {
        "id": "c-xKmwGr3XsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(pre_train, size):\n",
        "    # Create the base model structure,\n",
        "    # and load parameters from ImageNet if pretraining\n",
        "    weight_source = 'imagenet' if pre_train else None\n",
        "    base_model = EfficientNetB0(weights=weight_source, include_top=False)\n",
        "\n",
        "    # Add extra layers so that the model can be customized for our problem\n",
        "    channels = 3\n",
        "    for layer in base_model.layers[:-2]:\n",
        "        layer.trainable = False\n",
        "    x_in = Input(shape=(size[0], size[1], channels))\n",
        "    x = base_model(x_in)\n",
        "    x = Conv2D(64, 3, padding='same', activation='relu')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(100, activation='relu',\n",
        "              kernel_regularizer=regularizers.l2(1e-2),\n",
        "              bias_regularizer=regularizers.l2(1e-2))(x)\n",
        "    x_out = Dense(2, activation='softmax', # assuming 2 possible classes\n",
        "                  kernel_regularizer=regularizers.l2(1e-2),\n",
        "                  bias_regularizer=regularizers.l2(1e-2))(x)\n",
        "    model = Model(inputs=x_in, outputs=x_out)\n",
        "\n",
        "    # Add a loss function\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return base_model, model"
      ],
      "metadata": {
        "id": "80cNhq8N2u6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model, model = create_model(True, image_size)"
      ],
      "metadata": {
        "id": "n7bNynNqR4u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the structure of this model:"
      ],
      "metadata": {
        "id": "6myipINdzQlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.summary()"
      ],
      "metadata": {
        "id": "B-TC720wynF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observe that there are hundreds of thousands of trainable parameters in this model. These parameters are the values that go inside our image kernels, along with some other numbers that are learned towards the end of the model architecture. With any machine learning model, more trainable parameters require more training data to avoid overfitting. This is one of the many reasons why deep learning requires tons of training data."
      ],
      "metadata": {
        "id": "KM48cLFNycW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Putting It All Together"
      ],
      "metadata": {
        "id": "iYxGqrRS3U9B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code block below will allow you to train a model while tweaking four different settings:\n",
        "1. `train_samples`: The amount of data used for model training\n",
        "2. `batch_size`: The size of the batches that are used for model training\n",
        "3. `epochs`: The number of times that the entire train dataset is fed into the model for model training\n",
        "4. `pre-train`: Whether or not the model is pre-trained\n",
        "\n",
        "Play around with them to see how they affect model performance."
      ],
      "metadata": {
        "id": "IhWbUBUAuO3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples = 250 # @param {type: \"slider\", min:250, max:2001, step:250}\n",
        "batch_size = 32 # @param {type: \"slider\", min:32, max:128, step:32}\n",
        "epochs = 3  # @param {type: \"slider\", min:1, max:25}\n",
        "pre_train = True  # @param {type: \"boolean\"}\n",
        "\n",
        "ds_train, ds_test = load_dataset(train_samples, batch_size)\n",
        "base_model, model = create_model(pre_train, image_size)\n",
        "hist = model.fit(ds_train, epochs=epochs,\n",
        "                 validation_data=ds_test, verbose=1)"
      ],
      "metadata": {
        "id": "Wgu9Rgendx_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `.fit()` method already prints out a lot of useful information for us when we make it verbose (`verbose=1`). However, we can also print out what happens to the output of the loss function and the model's accuracy each time it has looked at the entire training dataset."
      ],
      "metadata": {
        "id": "jh4Izicjuhka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6, 3))\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QpPDOCyMsHg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6, 3))\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_brMx-aIrfjg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}