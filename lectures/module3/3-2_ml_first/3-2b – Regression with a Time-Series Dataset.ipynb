{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DekAnzq1b82b",
        "xP4sP_ekZxqW",
        "dF7vGVljaKp7",
        "ryaahUysaOHD",
        "Ft8ymn0J0Io4",
        "AUL_8Ns90M6f",
        "TUuv3wRJaVer",
        "A-AcODJ3aYx6",
        "gmMs1P1tabse",
        "hT0cnOFdafEF",
        "e87qpxdPIsga",
        "pcs02trXU1k5",
        "uvtSJXQxeJE9"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we're going to build a regression model that rates the motor impairment severity of patients with Parkinson's disease using time-series gait data from the [Gait in Parkinson's Disease](https://www.physionet.org/content/gaitpdb/1.0.0/) dataset we examined in a previous session."
      ],
      "metadata": {
        "id": "BDaO9cuMWe83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important: Run this code cell each time you start a new session!"
      ],
      "metadata": {
        "id": "DekAnzq1b82b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install os\n",
        "!pip install librosa\n",
        "!pip install scikit-learn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import librosa\n",
        "import sklearn"
      ],
      "metadata": {
        "id": "jrO0X1ZMxMN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -rNcnp https://physionet.org/files/gaitpdb/1.0.0/"
      ],
      "metadata": {
        "id": "bASFcdZNZuGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Define the Problem You Are Trying to Solve"
      ],
      "metadata": {
        "id": "xP4sP_ekZxqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a reminder, the goal of this dataset is to enable researchers to investigate whether characteristics of gait can be used to automatically monitor the severity of Parkinson's disease over time. This dataset is actually composed of data collected by three institutions. Together, these institutions recruited 93 patients with idiopathic PD and 73 healthy controls. During enrollment, subjects were asked to complete a number of clinical scales to assess the severity of their Parkinsonian symptoms. The clinical scale we will focus on the most is the Unified Parkinson's Disease Rating Scale (UPDRS). This scale is composed of four different parts, but we will focus on the portion that deals with motor control function (Part III)."
      ],
      "metadata": {
        "id": "RAtrOjflWIga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "During the study itself, subjects were asked to walk at their usual pace for approximately 2 minutes on level ground. Subjects were asked to repeat this protocol for multiple trials depending on the institution where the data was collected. Underneath each foot were 8 sensors that measure force (in Newtons) as a function of time; the researchers who compiled this dataset refer to the sensor data as the vertical ground reaction force (VGRF).  The output of each of these 16 sensors has been digitized and recorded at 100 Hz, and the records also include two signals that reflect the sum of the 8 sensor outputs for each foot."
      ],
      "metadata": {
        "id": "QYrG6r4EVNEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The relevant folders and files associated with this dataset\n",
        "base_folder = os.path.join('physionet.org', 'files', 'gaitpdb', '1.0.0')\n",
        "label_filename = os.path.join(base_folder, 'demographics.xls')"
      ],
      "metadata": {
        "id": "85ItYs_7gYDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The recording files are named according to the following convention: `{study_prefix}{subject_type}{subject_id}_{trial_id}.txt` (e.g., `GaCo01_01.txt`)\n",
        "\n",
        "* `study_prefix`: Specifies the institution where the subject was recruited (either `Ga`, `Ju`, or `Si`)\n",
        "* `subject_type`: Specifies whether the subject was a control (`Co`) or a patient (`Pt`)\n",
        "* `subject_id`: Numerical identifier indicating the subject's number within the institution's cohort\n",
        "* `trial_id`: Numerical identifier indicating the trial number. We will be using all trials except for any numbered `10`, which relates to a special protocol used by a single institution."
      ],
      "metadata": {
        "id": "8X30ZmeSfXPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These files are structured as tab-separated spreadsheets with the following columns:\n",
        "\n",
        "| Column # | Description |\n",
        "|----------|-------------|\n",
        "| 1 | Time in seconds|\n",
        "| 2–9 | VGRF on each of the 8 sensors located under the left foot |\n",
        "|10–17 | VGRF on each of the 8 sensors located under the right foot |\n",
        "| 18 | Total force under the left foot |\n",
        "| 19 | Total force under the right foot |"
      ],
      "metadata": {
        "id": "KTU_l5HRMbL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The names of the columns in the recordings\n",
        "column_names = ['Time']\n",
        "for i in range(1, 9):\n",
        "    column_names.append(f'Left Sensor {i}')\n",
        "for i in range(1, 9):\n",
        "    column_names.append(f'Right Sensor {i}')\n",
        "column_names.append('Left Foot')\n",
        "column_names.append('Right Foot')"
      ],
      "metadata": {
        "id": "tjO9wyZHMg9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the structure of one of the files\n",
        "example_filename = 'GaCo01_01.txt'\n",
        "example_df = pd.read_csv(os.path.join(base_folder, example_filename),\n",
        "                         sep=\"\\t\", header=None, names=column_names)\n",
        "example_df"
      ],
      "metadata": {
        "id": "nlbjx-aIDbFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the data\n",
        "plt.figure(figsize=(9, 3))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(example_df['Time'], example_df['Left Foot'], 'k-', label='Left')\n",
        "plt.xlabel('Time (s)'), plt.ylabel('VGRF (N)'), plt.title('Entire Recording, Single Foot')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(example_df['Time'], example_df['Left Foot'], 'k-', label='Left')\n",
        "plt.plot(example_df['Time'], example_df['Right Foot'], 'r-', label='Right')\n",
        "plt.xlabel('Time (s)'), plt.ylabel('VGRF (N)'), plt.title('Short Snippet, Both Feet')\n",
        "plt.xlim(0, 5)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SdmFJoR5ko5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many ways we could structure this problem. For instance, we could create a binary classifier designed to discriminate people with and without Parkinson's disease. For the sake of this exercise, however, we are going to build a ***regression model*** that will predict a person's UPDRS Part III (UPDRSM) score as the label based on their gait characteristics. To ensure that our dataset is not heavily skewed towards assuming that people do not have any motor impairments, we are only going to look at data from patients (e.g., with `Pt` in the recording filename)."
      ],
      "metadata": {
        "id": "SOV9iw3P1xuI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Create Your Features and Labels"
      ],
      "metadata": {
        "id": "dF7vGVljaKp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The labels for our dataset will be the UPDRSM associated with each recording.\n",
        "\n",
        "Traditional machine learning models are not able to handle raw time-series data. Rather, they are best suited for handling tabular data. When we first saw this time-series dataset, we wrote a series of functions that allowed us to summarize gait characteristics according to arbitrary time-domain metrics, arbitrary frequency-domain metrics, and metrics that we calculated as a proxy for bradykinesia, rigidity, and postural instability. These numbers will serve as our features.\n",
        "\n",
        "This goes to show that knowing about machine learning is often not enough to work with real-world data. Having some domain expertise relevant to the target task can ensure that you are able to extract meaningful features from your data."
      ],
      "metadata": {
        "id": "1O2DKWI7lpOk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All of the code from our initial exploration of this dataset is copied below, so refer to that notebook if you need a reminder of how we came up with these functions."
      ],
      "metadata": {
        "id": "QvYU2W0HXJvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_arbitrary_time_domain_metrics(times, values, fs=100):\n",
        "    \"\"\"\n",
        "    Calculates generic time-domain statistics on the signal\n",
        "    times: the times associated with the VGRF data\n",
        "    values: the VGRF data\n",
        "    fs: the sampling rate\n",
        "    \"\"\"\n",
        "    return {'average': np.mean(values),\n",
        "            'stdev': np.std(values),\n",
        "            '95th percentile': np.percentile(values, 95),\n",
        "            'rms': np.sqrt(np.mean(values**2))}"
      ],
      "metadata": {
        "id": "gtMjoTpsulKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.fft import fftfreq\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "def compute_arbitrary_freq_domain_metrics(times, values, fs=100):\n",
        "    \"\"\"\n",
        "    Calculates generic frequency-domain statistics on the signal\n",
        "    times: the times associated with the VGRF data\n",
        "    values: the VGRF data\n",
        "    fs: the sampling rate\n",
        "    \"\"\"\n",
        "    # Calculate the FFT\n",
        "    values_centered = values - values.mean()\n",
        "    fft_mag = np.abs(fft(values_centered))\n",
        "    fft_freqs = fftfreq(len(values_centered), 1/fs)\n",
        "\n",
        "    # Calculate the indices relevant to our frequency bands of interest\n",
        "    low_indices = np.where((fft_freqs >= 0) & (fft_freqs <= 3))\n",
        "    high_indices = np.where((fft_freqs >= 3) & (fft_freqs <= 8))\n",
        "\n",
        "    # Calculate the power at the low and high frequencies\n",
        "    low_power = np.sum(fft_mag[low_indices]**2)\n",
        "    high_power = np.sum(fft_mag[high_indices]**2)\n",
        "\n",
        "    # Calculate the power within the frequency range\n",
        "    high_to_low_ratio = 10*np.log10(high_power / low_power)\n",
        "    return {'power at low freqs': low_power,\n",
        "            'power at high freqs': high_power,\n",
        "            'high-to-low power ratio': high_to_low_ratio}"
      ],
      "metadata": {
        "id": "sy1KLrzRvBzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_amplitude_metrics(times, values, fs=100):\n",
        "    \"\"\"\n",
        "    Calculate metrics related to the transient amplitude of the signal over time\n",
        "    using a 5-second window with 0% overlap\n",
        "    times: the times associated with the VGRF data\n",
        "    values: the VGRF data\n",
        "    fs: the sampling rate\n",
        "    \"\"\"\n",
        "    # Set the sliding window parameters\n",
        "    window_width = 5\n",
        "    start_time = 0\n",
        "    end_time = window_width\n",
        "    sample_period = 1/fs\n",
        "    middle_idx = int((window_width / sample_period) // 2)\n",
        "\n",
        "    # Stop generating windows it would go past the end of the signal\n",
        "    window_amplitudes = []\n",
        "    while end_time < times.max():\n",
        "        # Grab the current window by filtering indexes according to time\n",
        "        window_idxs = (times >= start_time) & (times <= end_time)\n",
        "        window_values = values[window_idxs]\n",
        "\n",
        "        # Calculate the amplitude\n",
        "        window_rms = np.sqrt(np.mean(window_values**2))\n",
        "        window_amplitudes.append(window_rms)\n",
        "\n",
        "        # Move the window over by a stride\n",
        "        start_time += window_width\n",
        "        end_time += window_width\n",
        "\n",
        "    # Summarize the amplitude over time\n",
        "    return {'average amplitude': np.mean(window_amplitudes),\n",
        "            'stdev amplitude': np.std(window_amplitudes)}"
      ],
      "metadata": {
        "id": "FNZOOcXsdISL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cadence_metrics(times, values, fs=100):\n",
        "    \"\"\"\n",
        "    Calculate metrics related to the transient peak frequency of the signal\n",
        "    over time\n",
        "    times: the times associated with the VGRF data\n",
        "    values: the VGRF data\n",
        "    fs: the sampling rate\n",
        "    \"\"\"\n",
        "    # Calculate the spectrogram\n",
        "    values_centered = values - values.mean()\n",
        "    spec_freqs, spec_times, spectro = signal.spectrogram(values_centered, fs)\n",
        "\n",
        "    # Find the largest bin along the frequency dimension\n",
        "    dominant_bins = np.argmax(spectro, axis=0)\n",
        "\n",
        "    # Map those bin indeces to frequencies\n",
        "    peak_freqs = spec_freqs[dominant_bins]\n",
        "\n",
        "    # Summarize the step rate over time\n",
        "    return {'average cadence': np.mean(peak_freqs),\n",
        "            'stdev cadence': np.std(peak_freqs)}"
      ],
      "metadata": {
        "id": "XXS1hhmcq7MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_differences(left, right):\n",
        "    \"\"\"\n",
        "    Compares corresponding metrics across two feet\n",
        "    left: the dictionary of metrics from the left side\n",
        "    right: the dictionary of metrics from the right side\n",
        "    \"\"\"\n",
        "    diffs_dict = {}\n",
        "    for key in left:\n",
        "        diffs_dict[key] = np.abs(left[key] - right[key])\n",
        "    return diffs_dict"
      ],
      "metadata": {
        "id": "3Hicu3U1rD28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is largerly the same as well. However, there are a few small housekeeping changes for both terminology and interfacing with `scikit-learn`:\n",
        "1. **Terminology (Features):** What we originally called `info_dict` and `info_df` are now called `feature_dict` and `features_df` to reflect the fact that the metrics we extracted from our images will serve as our features.\n",
        "2. **Terminology (Labels):** What we originally called `demo_df` is now called `labels_df` to reflect the fact that the diagnoses will serve as our labels.\n",
        "3. **Adding demographic variables:** We have added some demographic variables (gender, age, weight) as features.\n",
        "4. **Handling missing data (UPDRS):** Some subjects did not complete the UPDRS. Since we are doing supervised learning, there is little point in using their recordings to train our models and we will throw them out as before.\n",
        "5. **Handling missing data (demographics):** The demographics variables were also not recorded for some subjects. Most machine learning techniques require all features to be present in order for them to work, so we will exclude any rows with missing data.\n",
        "6. **Converting strings to numerics:** Because machine learning algorithms operate on numerical data, we have converted the gender column to a binary sex variable to a binary variable (`'male'` = `0`, `'female'` = `1`).\n",
        "7. **Fixing improper data:** Contrary to the implications of the original header, the researchers responsible for collecting data from the `Ju` cohort actually reported height in centimeters rather than meters, so we will need to fix those ourselves."
      ],
      "metadata": {
        "id": "k3pNYdaha_X7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_recording(filename):\n",
        "    \"\"\"\n",
        "    Process a VGRF recording and produce all of the features as a dictionary\n",
        "    (one value per key)\n",
        "    filename: the name of the recording file\n",
        "    \"\"\"\n",
        "    # Get the useful columns\n",
        "    df = pd.read_csv(os.path.join(base_folder, filename),\n",
        "                     sep=\"\\t\", header=None, names=column_names)\n",
        "    time = df['Time'].values\n",
        "    left_values = df['Left Foot'].values\n",
        "    right_values = df['Right Foot'].values\n",
        "\n",
        "    # Extract metrics from the left side\n",
        "    left_time = compute_arbitrary_time_domain_metrics(time, left_values)\n",
        "    left_freq = compute_arbitrary_freq_domain_metrics(time, left_values)\n",
        "    left_amplitude = compute_amplitude_metrics(time, left_values)\n",
        "    left_cadence = compute_cadence_metrics(time, left_values)\n",
        "\n",
        "    # Extract metrics from the right side\n",
        "    right_time = compute_arbitrary_time_domain_metrics(time, right_values)\n",
        "    right_freq = compute_arbitrary_freq_domain_metrics(time, right_values)\n",
        "    right_amplitude = compute_amplitude_metrics(time, right_values)\n",
        "    right_cadence = compute_cadence_metrics(time, right_values)\n",
        "\n",
        "    # Extract difference metrics\n",
        "    diff_time = compute_differences(left_time, right_time)\n",
        "    diff_freq = compute_differences(left_freq, right_freq)\n",
        "    diff_amplitude = compute_differences(left_amplitude, right_amplitude)\n",
        "    diff_cadence = compute_differences(left_cadence, right_cadence)\n",
        "\n",
        "    # Combine everything into a dictionary\n",
        "    feature_dict = {}\n",
        "    for left_dict in [left_time, left_freq, left_amplitude, left_cadence]:\n",
        "        for key in left_dict:\n",
        "            feature_dict['Single foot ' + key] = left_dict[key]\n",
        "    for diff_dict in [diff_time, diff_freq, diff_amplitude, diff_cadence]:\n",
        "        for key in diff_dict:\n",
        "            feature_dict['Difference ' + key] = diff_dict[key]\n",
        "    return feature_dict"
      ],
      "metadata": {
        "id": "-6Egsxlfil5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_filenames = os.listdir(base_folder)\n",
        "\n",
        "# Iterate through the filenames\n",
        "features_df = pd.DataFrame()\n",
        "for data_filename in data_filenames:\n",
        "    # Skip the file if we want to ignore it\n",
        "    patient_name = data_filename[0:6]\n",
        "    patient_type = data_filename[2:4]\n",
        "    trial_id = data_filename[7:9]\n",
        "    if (patient_type == 'Co') or (trial_id == '10') or not ('_' in data_filename):\n",
        "        continue\n",
        "\n",
        "    # Generate the features\n",
        "    feature_dict = process_recording(data_filename)\n",
        "\n",
        "    # Add the patient's name as the identifier\n",
        "    feature_dict['ID'] = patient_name\n",
        "    feature_dict = pd.DataFrame([feature_dict])\n",
        "    features_df = pd.concat([features_df, feature_dict], axis=0)\n",
        "\n",
        "# Set the index to the image name\n",
        "features_df.set_index(['ID'], inplace=True)\n",
        "features_df"
      ],
      "metadata": {
        "id": "vyt2LUL7i1BC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df = pd.read_excel(label_filename, index_col='ID')\n",
        "labels_df"
      ],
      "metadata": {
        "id": "Xkr2TodFhmN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only patient data\n",
        "labels_df = labels_df[labels_df['Group'] == 'PD']\n",
        "\n",
        "# Get rid of unnecessary columns\n",
        "labels_df = labels_df[['Gender', 'Age', 'Height (meters)',\n",
        "                       'Weight (kg)', 'UPDRSM']]\n",
        "\n",
        "# Rename the columns\n",
        "labels_df.rename(columns={'Gender': 'Sex', 'Height (meters)': 'Height',\n",
        "                          'Weight (kg)': 'Weight', 'UPDRSM': 'Label'}, inplace=True)\n",
        "labels_df"
      ],
      "metadata": {
        "id": "2e_PIVlqk6CT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert gender to a binary sex variable\n",
        "labels_df['Sex'] = labels_df['Sex'].replace({'male': 0, 'female': 1})\n",
        "labels_df"
      ],
      "metadata": {
        "id": "QYP272-ll4Tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix the Ju rows so that the height is in meters\n",
        "bad_height_rows = labels_df.index.str.startswith('Ju')\n",
        "labels_df.loc[bad_height_rows, 'Height'] /= 100\n",
        "labels_df"
      ],
      "metadata": {
        "id": "t5ByBmhOlYJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.merge(labels_df, features_df, how='right', left_index=True, right_index=True)\n",
        "df"
      ],
      "metadata": {
        "id": "IGmw_RJsZXqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows with missing data\n",
        "df = df.dropna(how='any')\n",
        "df"
      ],
      "metadata": {
        "id": "pdjzLQhUdVXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Decide How the Data Should Be Split for Training and Testing"
      ],
      "metadata": {
        "id": "ryaahUysaOHD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because we have multiple trials from the same subjects, we cannot just use the `train_test_split()` function in order to split our dataset. Otherwise, we run the risk of having a subject's data across multiple splits. Unless we expect that subjects will provide labeled data as a sort of \"personal calibration\" for model training, this would constitute information leakage."
      ],
      "metadata": {
        "id": "n0hb8m7jfSpW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we need to do is split the data while being cognizant that rows with the same `ID` should be grouped together. One convenient way we can do that is by using the `GroupKFold` class in `scikit-learn`. This object splits data according to k-fold cross-validation while keeping all of the samples associated with the same grouping variable in the same fold."
      ],
      "metadata": {
        "id": "dsJbPr1Xfqn1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the example below, we can see how `GroupKFold` splits our data into 5 folds while using the index of our `DataFrame` as the grouping variable:"
      ],
      "metadata": {
        "id": "V-rWznPKr0le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "# Set the random seed to an arbitrary number of your choosing\n",
        "np.random.seed(42)\n",
        "\n",
        "# Get the features, labels, and grouping variables\n",
        "x = df.drop('Label', axis=1).values\n",
        "y = df['Label'].values\n",
        "groups = df.index.values\n",
        "\n",
        "# Split the data into folds\n",
        "group_kfold = GroupKFold(n_splits=5)\n",
        "for train_idxs, test_idxs in group_kfold.split(x, y, groups):\n",
        "    print(f'Train row idxs: {train_idxs}')\n",
        "    print(f'Test row idxs: {test_idxs}')\n",
        "    print('---------------')"
      ],
      "metadata": {
        "id": "9dBvWdv6f1KV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are more sophisiticated functions and classes we can use to automate the entire cross-validation procedure for us. However, we will get to that in a bit."
      ],
      "metadata": {
        "id": "hqNOgGPOIO1V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: (Optional) Add Feature Selection"
      ],
      "metadata": {
        "id": "Ft8ymn0J0Io4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have explicitly included features that are inspired by domain expertise and our general knowledge about signal processing so that we can eventually try out feature selection. However, we are going to skip this step for now."
      ],
      "metadata": {
        "id": "TI3mp5UWzItT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: (Optional) Balance Your Dataset"
      ],
      "metadata": {
        "id": "AUL_8Ns90M6f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although there aren't distinct classes we can balance, we can still check that we have a reasonable distribution of UPDRSM scores. We will use this opportunity to show one of the ways that `pandas` interfaces with `matplotlib` to simplify how you can visualize data:"
      ],
      "metadata": {
        "id": "EECBO7dX1nMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(3, 3))\n",
        "df['Label'].plot.hist(bins=12, alpha=0.5)\n",
        "plt.xlabel('UPDRSM Score')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kJHepUOk1qG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ideally, this would be a completely normal distribution with taller bars in the middle and shorter bars on either side. Although that isn't what we see here, most of the scores lie between 15–20 and we have scores that are above and below that range. Since there is no glaring imbalance in our dataset, it is probably not worth trying to balance our dataset and adding yet another step in our pipeline."
      ],
      "metadata": {
        "id": "FsIkdMQIFNnB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Select an Appropriate Model"
      ],
      "metadata": {
        "id": "TUuv3wRJaVer"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`scikit-learn` provides numerous regression model architectures with their own advantages and disadvantages. We are going to use a ***k-nearest neighbors regressor***, which makes predictions by taking the average label of samples from the training set with similar features."
      ],
      "metadata": {
        "id": "IiS0RhPymQwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "reg = KNeighborsRegressor()"
      ],
      "metadata": {
        "id": "-ZejuzTe8X3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Something you may be thinking right now is that our features have different ranges, which complicates how a k-nearest neighbors regressor identifies neighboring samples. Points will be closer according to features with smaller ranges, so those features will have a stronger influence on how neighbors are deteremined. We can fix this by normalizing the distributions of our features."
      ],
      "metadata": {
        "id": "XpySSjEfMy_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, we are not going to do this until the next lecture. Part of the reason why we are going to forgo this step for now is that it is not required for all model architectures. For example, decision trees and random forests are scale-invariant; regardless of the range of a feature, a decision boundary can be selected to split the data in the exact same way."
      ],
      "metadata": {
        "id": "NT8WXP-kOZ4L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: (Optional) Select Your Hyperparameters"
      ],
      "metadata": {
        "id": "A-AcODJ3aYx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-nearest neighbor regression has a fairly obvious hyperparameter: the number of neighbors we use to make our predictions. The default value is 5, and we are going to keep it that way for simplicity."
      ],
      "metadata": {
        "id": "u5UTDgY31cQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8: Train and Test Your Model"
      ],
      "metadata": {
        "id": "gmMs1P1tabse"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As with classification models, we can train a regression model by calling `.fit()` and generate predictions using `.predict()`. Since the predictions are going to be continuous values, there is no equivalent to the `.predict_proba()` method."
      ],
      "metadata": {
        "id": "nZLFduix1Dgg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sicne we are doing k-fold cross-validation, our train-and-test procedure is going to be more complicated. The pseudocode for the procedure is as follows:\n",
        "\n",
        "```\n",
        "initialize a data structure for saving our final results\n",
        "for each fold:\n",
        "    split data into train and test\n",
        "    train a model on training data\n",
        "    predict on the test data using that model\n",
        "    add the predictions to our final results data structure\n",
        "```"
      ],
      "metadata": {
        "id": "zzZm_NJ_Gt4Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And here is that procedure in action:"
      ],
      "metadata": {
        "id": "4kDdk9_5Kp5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed to an arbitrary number of your choosing\n",
        "np.random.seed(42)\n",
        "\n",
        "# Initialize a data structure to save our final results,\n",
        "# assuming all of the predictions are 0 to start\n",
        "y_pred = np.zeros(y.shape)\n",
        "\n",
        "# Get the features, labels, and grouping variables\n",
        "x = df.drop('Label', axis=1).values\n",
        "y = df['Label'].values\n",
        "groups = df.index.values\n",
        "\n",
        "# Split the data into folds\n",
        "group_kfold = GroupKFold(n_splits=5)\n",
        "for train_idxs, test_idxs in group_kfold.split(x, y, groups):\n",
        "    # Split the data into train and test\n",
        "    x_train = x[train_idxs]\n",
        "    y_train = y[train_idxs]\n",
        "    x_test = x[test_idxs]\n",
        "    y_test = y[test_idxs]\n",
        "\n",
        "    # Train a model on the training data\n",
        "    reg = KNeighborsRegressor()\n",
        "    reg.fit(x_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_test_pred = reg.predict(x_test)\n",
        "    y_pred[test_idxs] = y_test_pred"
      ],
      "metadata": {
        "id": "zUO20hcDKr2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`scikit-learn` provides a function called `cross_val_predict()` that will automate this procedure for us:"
      ],
      "metadata": {
        "id": "BLh7BsNDJaAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "sklearn.set_config(enable_metadata_routing=True)\n",
        "\n",
        "# Perform cross-validation and get the predictions\n",
        "y_pred = cross_val_predict(reg, x, y, cv=GroupKFold(n_splits=5),\n",
        "                           params={'groups': groups})"
      ],
      "metadata": {
        "id": "7uHJnLC1tFhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, we are going to stick with our manual implementation for two reasons: (1) doing it ourselves will reinforce what this procedure is doing, and (2) it will give us greater flexibility to change our pipeline in a later session.\n",
        "\n",
        "As you get more familiar with `scikit-learn` and machine learning in general, you will discover for yourself which shortcuts you want to rely on."
      ],
      "metadata": {
        "id": "JKepkPnYJ-vc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 9: Use an Appropriate Method for Interpreting Results"
      ],
      "metadata": {
        "id": "hT0cnOFdafEF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have predictions, we will examine a variety of metrics to see how well our model performed. Most of the functions we will discuss in this section require two inputs:\n",
        "1. **y_true:** The known ground-truth labels from our dataset\n",
        "2. **y_pred:** The labels predicted from the model"
      ],
      "metadata": {
        "id": "zj0apvZTbn5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distance Metrics"
      ],
      "metadata": {
        "id": "e87qpxdPIsga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `metrics` module from `scikit-learn` provides multiple functions for evaluating the performance of a regression model. However, some of the most useful ones can be calculated using simply `numpy` operations:"
      ],
      "metadata": {
        "id": "zvZqiWh9bU7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Mean error: {np.mean(y_pred-y)}')\n",
        "print(f'Mean absolute error: {np.mean(np.abs(y_pred-y))}')"
      ],
      "metadata": {
        "id": "U4JQn0MdbmdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation Metrics"
      ],
      "metadata": {
        "id": "pcs02trXU1k5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`scipy` provides functions for calculating both Pearson's and Spearman's correlation. These functions return a special object that contains two values: the correlation coefficient and its p-value."
      ],
      "metadata": {
        "id": "YSxKWcHkU1k6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "pcorr = pearsonr(y, y_pred)\n",
        "scorr = spearmanr(y, y_pred)\n",
        "print(f'Pearson correlation: r = {pcorr[0]:0.2f}, pval = {pcorr[1]:0.2f}')\n",
        "print(f'Spearman correlation: r = {scorr[0]:0.2f}, pval = {scorr[1]:0.2f}')"
      ],
      "metadata": {
        "id": "NyxPcNu3U1k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although interpretations of the relationship strength can vary between disciplines, the table below gives general rules of thumb:\n",
        "\n",
        "| Range | Interpretation | Direction\n",
        "|-------|------|------|\n",
        "| Between 0.5 and 1 | Strong | Positive |\n",
        "| Between 0.3 and 0.5 | Moderate | Positive |\n",
        "| Between 0 and 0.3 | Weak | Positive |\n",
        "| 0 | No correlation | N/A |\n",
        "| Between -0.3 and 0 | Weak | Negative |\n",
        "| Between -0.5 and -0.3 | Moderate | Negative |\n",
        "| Between -1 and -0.5 | Strong | Positive |"
      ],
      "metadata": {
        "id": "FSWseGDEKhXX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We calculate the R2 score, also known as the coefficient of determination. Similar conventions can be applied here."
      ],
      "metadata": {
        "id": "hoTWVMebriW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "print(f'R2 Score: {r2_score(y, y_pred)}')"
      ],
      "metadata": {
        "id": "TprzrDzerprl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To establish these correlation results further, we can plot them on a correlation plot:"
      ],
      "metadata": {
        "id": "QWrIJa0_kxzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig_bounds = [y.min()-1, y.max()+1]\n",
        "plt.figure(figsize=(3, 3))\n",
        "plt.plot(y, y_pred, '*')\n",
        "plt.plot(fig_bounds, fig_bounds, 'k--')\n",
        "plt.grid()\n",
        "plt.xlim(fig_bounds), plt.ylim(fig_bounds)\n",
        "plt.xlabel('Actual Score'), plt.ylabel('Predicted Score')\n",
        "plt.title('Correlation Plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1suawldOk3Op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another graph that can be useful for analyzing regression performance is a ***Bland-Altmann plot***. These graphs are designed to show how the agreement between two measurement methods varies according to their magnitude. Typically, the x-axis of these graphs is the average between the measurement methods (in this case, known labels and their corresponding predictions) and the y-axis is the difference between them.\n",
        "\n",
        "However, this is the case when one measurement method does not take precedence over another. In our case, we know that one of the measurement methods is \"correct\". Therefore, we will create a modified Bland-Altmann plot where the x-axis is the known label and the y-axis is the difference between the prediction and the known label."
      ],
      "metadata": {
        "id": "HSQJ47KgmrH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(3, 3))\n",
        "plt.plot(y, y_pred-y, '*')\n",
        "plt.grid()\n",
        "plt.xlim(fig_bounds)\n",
        "plt.xlabel('Actual Score'), plt.ylabel('Error')\n",
        "plt.title('Modified Bland Altmann')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iomJ0RUdnulP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating Performance"
      ],
      "metadata": {
        "id": "uvtSJXQxeJE9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a function that will generate a detailed regression accuracy report combining the aforementioned metrics and visualizations:"
      ],
      "metadata": {
        "id": "dOvMA31Y8EYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def regression_evaluation(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Generate a series of graphs that will help us determine the performance of\n",
        "    a regression model\n",
        "    y_true: the target labels\n",
        "    y_pred: the predicted labels\n",
        "    \"\"\"\n",
        "    # Calculate the distance metrics and Pearson's correlation\n",
        "    mean_error = np.mean(y_pred-y)\n",
        "    std_error = np.std(y_pred-y)\n",
        "    mean_absolute_error = np.mean(np.abs(y_pred-y))\n",
        "    corr, pval = pearsonr(y, y_pred)\n",
        "\n",
        "    # Set up the graphs\n",
        "    fig_bounds = [y.min()-1, y.max()+1]\n",
        "    corr_title = f'Correlation = {corr:0.2f}'\n",
        "    corr_title += ', p<.05' if pval <.05 else ', n.s.'\n",
        "    ba_title = f'Mean Error = {mean_error:0.2f} ± {std_error:0.2f}'\n",
        "\n",
        "    # Generate a correlation plot with the scores in the title\n",
        "    plt.figure(figsize=(9, 3))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(y, y_pred, '*')\n",
        "    plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--')\n",
        "    plt.grid()\n",
        "    plt.xlim(fig_bounds), plt.ylim(fig_bounds)\n",
        "    plt.xlabel('Actual Score'), plt.ylabel('Predicted Score')\n",
        "    plt.title(corr_title)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(y, y_pred-y, '*')\n",
        "    plt.axhline(y=mean_error, color='k', linestyle='--')\n",
        "    plt.axhline(y=mean_error+std_error, color='r', linestyle='--')\n",
        "    plt.axhline(y=mean_error-std_error, color='r', linestyle='--')\n",
        "    plt.xlim(fig_bounds)\n",
        "    plt.xlabel('Actual Score'), plt.ylabel('Error')\n",
        "    plt.title(ba_title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "b1LxWw82eXkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regression_evaluation(y, y_pred)"
      ],
      "metadata": {
        "id": "A-eEyZjjjl_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So what can we learn from these results:\n",
        "* Our model has a slight tendency to overpredict scores given the positive mean error.\n",
        "* Notice that all of our predictions are generally between 15–25 regardless of the label. This may be because most of the samples within our dataset fall within that range. When a regression model is biased in this way, some data scientists will say that it is ***mean tracking*** in the sense that its predictions tend to hover around the average in the dataset.\n",
        "* The mean tracking is even more evident in the Bland-Altman. Notice how it has a diagonal shape that trends from the top-left to the bottom-right. This means that the model tends to overestimate lower scores and underestimate higher scores, which is exactly what if the model were always predicting the average label."
      ],
      "metadata": {
        "id": "73HEAeGwqoEr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to revisit this machine learning pipeline in a later session to see how we can improve its performance."
      ],
      "metadata": {
        "id": "Wkt4YdgS_PJK"
      }
    }
  ]
}