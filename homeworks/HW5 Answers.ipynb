{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "B6v86VjQmIrK",
        "IhQvi7z1v6rm",
        "xP4sP_ekZxqW",
        "XXy14O09UM3L",
        "buga415hls_2",
        "2gLiPr2p6ymF",
        "h6-LwnNSWE8B",
        "0CfvcgvOiRgw"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, your task is to explore a dataset of polysomnography data (PSG) from patients in a sleep clinic. The data is taken from a [PhysioNet](https://www.physionet.org/) repository called [Haaglanden Medisch Centrum Sleep Staging Database](https://physionet.org/content/hmc-sleep-staging/1.1/) by Diego Alvarez-Estevez and Roselyne Rijsman."
      ],
      "metadata": {
        "id": "eBuos7F5sEIo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6v86VjQmIrK"
      },
      "source": [
        "## Important: Run this code cell each time you start a new session!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install os\n",
        "!pip install mne\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import mne"
      ],
      "metadata": {
        "id": "jrO0X1ZMxMN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subject_list = [f'SN{str(i).zfill(3)}' for i in range(1, 4)]\n",
        "fs = 256\n",
        "old_base_folder = os.path.join('physionet.org', 'files', 'hmc-sleep-staging', '1.1', 'recordings')"
      ],
      "metadata": {
        "id": "-qob8l2O_Gds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for subject in subject_list:\n",
        "    !wget -rNcnp https://physionet.org/files/hmc-sleep-staging/1.1/recordings/{subject}.edf\n",
        "    !wget -rNcnp https://physionet.org/files/hmc-sleep-staging/1.1/recordings/{subject}_sleepscoring.edf"
      ],
      "metadata": {
        "id": "mD9SEZljuFVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a simple directory to hold the data\n",
        "if not os.path.exists('data'):\n",
        "    os.makedirs('data')\n",
        "\n",
        "# Iterate through the filenames\n",
        "for subject in subject_list:\n",
        "    # Load the annotations\n",
        "    annotations = mne.read_annotations(os.path.join(old_base_folder, f'{subject}_sleepscoring.edf'))\n",
        "    annotations_data = {\n",
        "        'onset': annotations.onset,\n",
        "        'duration': annotations.duration,\n",
        "        'description': annotations.description\n",
        "    }\n",
        "\n",
        "    # Load the data\n",
        "    edf = mne.io.read_raw_edf(os.path.join(old_base_folder, f'{subject}.edf'))\n",
        "    df = pd.DataFrame(edf.get_data().T, columns=edf.ch_names)\n",
        "    df['Time'] = np.arange(0, len(df))*(1/fs)\n",
        "\n",
        "    # Add the annotations as a new column\n",
        "    df['Annotation'] = np.nan\n",
        "    annotations_data = zip(annotations.onset,\n",
        "                           annotations.duration,\n",
        "                           annotations.description)\n",
        "    for onset, duration, description in annotations_data:\n",
        "        # Skip if annotation relates to lights\n",
        "        if 'Light' in description:\n",
        "            continue\n",
        "\n",
        "        # Add annotation to df\n",
        "        label = description.split(' ')[-1]\n",
        "        window_condition = (df['Time'] >= onset) & (df['Time'] < onset+duration)\n",
        "        df.loc[window_condition, 'Annotation'] = label\n",
        "\n",
        "    # Clean up the table save\n",
        "    first_cols = ['Time', 'Annotation']\n",
        "    new_col_order = first_cols + [col for col in df.columns if col not in first_cols]\n",
        "    df = df[new_col_order]\n",
        "    df.dropna(inplace=True)\n",
        "    df.to_csv(os.path.join('data', f'{subject}.csv'), index=False)"
      ],
      "metadata": {
        "id": "o8I8wOuMuPOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "XkuBmVcDv_l4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhQvi7z1v6rm"
      },
      "source": [
        "# Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get full credit for this assignment, we should be able to run your entire notbook from start to finish without any errors. You can check this yourself by selecting \"Runtime\" > \"Run all\" in the Google Colab menu."
      ],
      "metadata": {
        "id": "FmZhTZTraQGQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview of the Dataset"
      ],
      "metadata": {
        "id": "xP4sP_ekZxqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are several stages of sleep that occur in a cycle throughout the night. For the sake of this dataset, sleep can be divided into the following stages: awake (W), light sleep (N1), intermediate sleep (N2), deep sleep (N3), and REM sleep (R). Each stage of sleep plays an important role in the overall health and well-being of an individual. Therefore, sleep stage classification is a useful technique for diagnosing sleep disorders."
      ],
      "metadata": {
        "id": "CXg2PYdjevCJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this dataset is to enable researchers to automatically identify sleep stages using polysomnographic (PSG) recordings. Given the large size of these recordings, we will work only work with data from 3 participants from this 151-person study. Patient recordings were randomly selected from a heterogeneous group of patients who were referred for PSG examination due to different sleep disorders."
      ],
      "metadata": {
        "id": "BBrNiJenan-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Participants were instrumented with the minimal recommended set of sensors necessary to visually score sleep stages: four EEG (F4/M1, C4/M1, O2/M1, and C3/M2), two EOG (E1/M2 and E2/M2), one bipolar chin EMG, and one ECG (single modified lead II) data stream. Participants slept in the sleep clinic for one night. Their PSG recordings were reviewed and annotated by expert clinicians according to discrete 30-second windows. An example of this annotation process is shown below (note: this is merely an illustration and does not represent the true time-scale of the data):\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1UnkMe1WmP813ZGyS7ynT_CMqP2Nr2do0\" width=750px/>"
      ],
      "metadata": {
        "id": "QYrG6r4EVNEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All data was recorded at 256 Hz. For your convenience, the data has already been processed so that there is one `.csv` per participant in a folder called `data` with the following naming convention: `SN{subject_id}.csv`. These files have the following columns:"
      ],
      "metadata": {
        "id": "p6bvWQ9Tqzvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Column # | Description |\n",
        "|----------|-------------|\n",
        "| 1 | Time in seconds|\n",
        "| 2 | Annotation given by the sleep experts (W, N1, N2, N3, R) |\n",
        "| 3–6 | EEG data |\n",
        "| 7 | EMG data |\n",
        "| 8–9 | EOG data |\n",
        "| 10 | ECG data |"
      ],
      "metadata": {
        "id": "KTU_l5HRMbL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The relevant folders and files associated with this dataset\n",
        "base_folder = 'data'"
      ],
      "metadata": {
        "id": "tjO9wyZHMg9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, your goal will be to summarize the sensor data within each 30-second window in a way that makes it easy to discriminate between epochs during different sleep stages."
      ],
      "metadata": {
        "id": "sdZhpbU3XDH6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspecting the Dataset"
      ],
      "metadata": {
        "id": "XXy14O09UM3L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this part of the notebook, your task is to complete some helper functions that will help you load and examine the dataset. An example `DataFrame` and some commands for testing these functions have been provided for you."
      ],
      "metadata": {
        "id": "5-c6ElaQ96Lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(os.path.join(base_folder, f'{subject_list[0]}.csv'))"
      ],
      "metadata": {
        "id": "TxBSR831-Ayx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(Part 1)** Complete the function below so that it grabs a single 30-second window of data from a DataFrame `df` starting from `start_time`. The function should also return the annotation associated with that window."
      ],
      "metadata": {
        "id": "9lWAWkZ2UjdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grab_window(df, start_time):\n",
        "    \"\"\"\n",
        "    Grab a 30-second window of data from start_time to start_time+30\n",
        "    df: the DataFrame\n",
        "    start_time: the start of the window in seconds (must be a multiple of 30)\n",
        "    \"\"\"\n",
        "    # Check the inputs\n",
        "    if start_time % 30 != 0:\n",
        "        raise Exception('start_time should be a multiple of 30')\n",
        "\n",
        "    # Get the data window of interest\n",
        "    subset_condition = (df['Time'] >= start_time) & (df['Time'] < start_time+30)\n",
        "    window_df = df[subset_condition]\n",
        "\n",
        "    # Get the annotation associated with the window\n",
        "    # Note: this works since the annnotation is the same for\n",
        "    # all rows in a 30-second chunk,\n",
        "    # you could use .mode()[0] to take the most common value in the window\n",
        "    annotation = window_df['Annotation'].values[0]\n",
        "    return window_df, annotation"
      ],
      "metadata": {
        "id": "nlbjx-aIDbFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_df, annotation = grab_window(df, 0)\n",
        "print(f'Annotation: {annotation}')\n",
        "window_df"
      ],
      "metadata": {
        "id": "YEot_wLE9yf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_df, annotation = grab_window(df, 30*100)\n",
        "print(f'Annotation: {annotation}')\n",
        "window_df"
      ],
      "metadata": {
        "id": "TVisBuos-2-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(Part 2)** Complete the function below so that it takes in a 30-second window of data and displays the data from a single column `sensor`as both as a time-series signal (signal over time) and as a spectrogram (frequency over time heatmap)."
      ],
      "metadata": {
        "id": "HNtaTJPC9iwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.fft import fftfreq\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "def view_recording(window_df, sensor):\n",
        "    \"\"\"\n",
        "    Displays data in the sensor column as a time-domain signal and as a spectrogram\n",
        "    window_df: the 30-second DataFrame\n",
        "    sensor: the name of the sensor column to be displayed\n",
        "    \"\"\"\n",
        "    # Check the inputs\n",
        "    window_length = window_df['Time'].max()-window_df['Time'].min()\n",
        "    if window_length > 30:\n",
        "        raise Exception('Please only provide a 30-second window')\n",
        "    if sensor not in list(df.columns):\n",
        "        raise Exception('Sensor not found')\n",
        "\n",
        "    # Grab the data\n",
        "    time = window_df['Time'].values\n",
        "    values = window_df[sensor].values\n",
        "\n",
        "    # Calculate the spectrogram\n",
        "    values_centered = values - values.mean()\n",
        "    spec_freqs, spec_times, spectro = signal.spectrogram(values_centered, fs)\n",
        "\n",
        "    # Show the two signal representations\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title('Time Domain')\n",
        "    plt.plot(time, values)\n",
        "    plt.xlabel('Time (s)'), plt.ylabel(sensor)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title('Frequency Domain: Spectrogram')\n",
        "    plt.pcolormesh(spec_times, spec_freqs, spectro, shading='gouraud')\n",
        "    plt.xlabel('Time (s)'), plt.ylabel('Frequency (Hz)')\n",
        "    plt.ylim(0, 30)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "dBTjZHFj9iUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_df, _ = grab_window(df, 0)\n",
        "view_recording(window_df, 'EEG F4-M1')\n",
        "view_recording(window_df, 'ECG')"
      ],
      "metadata": {
        "id": "6ZQZQ4ZpCCh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_df, _ = grab_window(df, 30*100)\n",
        "view_recording(window_df, 'EEG F4-M1')\n",
        "view_recording(window_df, 'ECG')"
      ],
      "metadata": {
        "id": "fMaDF7r0Dd-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting Information from a Recording"
      ],
      "metadata": {
        "id": "buga415hls_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this part of the notebook, your task is to create functions that will process the sensor data within a given 30-second window into a compact representation that will make it easier for us to compare windows across different sleep stages. It is up to you to decide the kind of information you want to extract from each window, but here are some pieces of advice:\n",
        "* Examine the data using the `view_recording()` function you created earlier to see if you notice any interesting trends in the data.\n",
        "* If you don't know where to start, consider using basic time-domain and frequency-domain metrics that we discussed in class.\n",
        "* It is okay to use the same metrics for each sensor."
      ],
      "metadata": {
        "id": "t9huu6aTluCV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may use the following window to test your functions:"
      ],
      "metadata": {
        "id": "RZUGcuocMlxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window_df, _ = grab_window(df, 30*100)"
      ],
      "metadata": {
        "id": "jDiycx6uFLg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each function should return a `dict` of the following form:\n",
        "```\n",
        "{'metric name 1': 0.0000,\n",
        "'metric name 2': 0.0000,\n",
        "...}\n",
        "```"
      ],
      "metadata": {
        "id": "Ay7M4a-CHmmS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(Part 1)** Complete the function below to summarize the four columns of EEG data within a 30-second window."
      ],
      "metadata": {
        "id": "zXJsc4xYtZ8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_eeg_metrics(window_df, fs=256):\n",
        "    \"\"\"\n",
        "    Returns a dictionary of metrics that summarize the EEG data in the DataFrame\n",
        "    df: the DataFrame\n",
        "    fs: the sampling rate\n",
        "    \"\"\"\n",
        "    # Grab the time data\n",
        "    eeg_ch = ['EEG F4-M1', 'EEG C4-M1', 'EEG O2-M1', 'EEG C3-M2']\n",
        "    time = window_df['Time'].values\n",
        "\n",
        "    # Initialize the dictionary\n",
        "    info_dict = {}\n",
        "\n",
        "    # Iterate through the EEG channels and perform time- and frequency-domain calculations\n",
        "    for eeg_name in eeg_ch:\n",
        "        eeg = window_df[eeg_name].values\n",
        "        # Time domain\n",
        "        info_dict[f'{eeg_name} mean'] = eeg.mean()\n",
        "        info_dict[f'{eeg_name} stdev'] = eeg.std()\n",
        "\n",
        "        # Frequency domain\n",
        "        eeg_centered = eeg - eeg.mean()\n",
        "        fft_mag = np.abs(fft(eeg_centered))\n",
        "        fft_freqs = fftfreq(len(eeg_centered), 1/fs)\n",
        "        info_dict[f'{eeg_name} peak freq'] = fft_freqs[fft_mag.argmax()]\n",
        "\n",
        "    # Add time-domain features for overall EEG\n",
        "    eeg = np.sqrt(sum([window_df[eeg_name].values**2\n",
        "                       for eeg_name in eeg_ch]))\n",
        "    info_dict[f'EEG mean'] = eeg.mean()\n",
        "\n",
        "    # Return a dictionary of calculations\n",
        "    return info_dict"
      ],
      "metadata": {
        "id": "gtMjoTpsulKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_eeg_metrics(window_df)"
      ],
      "metadata": {
        "id": "GSGqgXVmKr9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(Part 2)** Complete the function below to summarize the single column of EMG data within a 30-second window."
      ],
      "metadata": {
        "id": "Gc5Ebna4Kzwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_emg_metrics(window_df, fs=256):\n",
        "    \"\"\"\n",
        "    Returns a dictionary of metrics that summarize the EMG data in the DataFrame\n",
        "    df: the DataFrame\n",
        "    fs: the sampling rate\n",
        "    \"\"\"\n",
        "    # Grab the data\n",
        "    time = window_df['Time'].values\n",
        "    emg = window_df['EMG chin'].values\n",
        "    info_dict = {}\n",
        "\n",
        "    # Time domain\n",
        "    info_dict[f'EMG mean'] = emg.mean()\n",
        "    info_dict[f'EMG stdev'] = emg.std()\n",
        "\n",
        "    # Frequency domain\n",
        "    emg_centered = emg - emg.mean()\n",
        "    fft_mag = np.abs(fft(emg_centered))\n",
        "    fft_freqs = fftfreq(len(emg_centered), 1/fs)\n",
        "    info_dict[f'EMG peak freq'] = fft_freqs[fft_mag.argmax()]\n",
        "\n",
        "    # Return a dictionary of calculations\n",
        "    return info_dict"
      ],
      "metadata": {
        "id": "7knUZx4OKzws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_emg_metrics(window_df)"
      ],
      "metadata": {
        "id": "5Eiid14yKzws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(Part 3)** Complete the function below to summarize the two columns of EOG data within a 30-second window."
      ],
      "metadata": {
        "id": "z14SIHihK1ii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_eog_metrics(window_df, fs=256):\n",
        "    \"\"\"\n",
        "    Returns a dictionary of metrics that summarize the EOG data in the DataFrame\n",
        "    df: the DataFrame\n",
        "    fs: the sampling rate\n",
        "    \"\"\"\n",
        "    # Grab the time data\n",
        "    eog_ch = ['EOG E1-M2', 'EOG E2-M2']\n",
        "    time = window_df['Time'].values\n",
        "\n",
        "    # Initialize the dictionary\n",
        "    info_dict = {}\n",
        "\n",
        "    # Iterate through the EEG channels and perform time- and frequency-domain calculations\n",
        "    for eog_name in eog_ch:\n",
        "        eog = window_df[eog_name].values\n",
        "        # Time domain\n",
        "        info_dict[f'{eog_name} mean'] = eog.mean()\n",
        "        info_dict[f'{eog_name} stdev'] = eog.std()\n",
        "\n",
        "        # Frequency domain\n",
        "        eog_centered = eog - eog.mean()\n",
        "        fft_mag = np.abs(fft(eog_centered))\n",
        "        fft_freqs = fftfreq(len(eog_centered), 1/fs)\n",
        "        info_dict[f'{eog_name} peak freq'] = fft_freqs[fft_mag.argmax()]\n",
        "\n",
        "    # Add time-domain features for overall EEG\n",
        "    eog = np.sqrt(sum([window_df[eog_name].values**2\n",
        "                       for eog_name in eog_ch]))\n",
        "    info_dict[f'EOG mean'] = eog.mean()\n",
        "\n",
        "    # Return a dictionary of calculations\n",
        "    return info_dict"
      ],
      "metadata": {
        "id": "a0-Z5RDqK1ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_eog_metrics(window_df)"
      ],
      "metadata": {
        "id": "9yr1SCsgK1ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(Part 4)** Complete the function below to summarize the single column of ECG data within a 30-second window."
      ],
      "metadata": {
        "id": "uafj0JmBK11H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_ecg_metrics(window_df, fs=256):\n",
        "    \"\"\"\n",
        "    Returns a dictionary of metrics that summarize the ECG data in the DataFrame\n",
        "    df: the DataFrame\n",
        "    fs: the sampling rate\n",
        "    \"\"\"\n",
        "    # Grab the data\n",
        "    time = window_df['Time'].values\n",
        "    ecg = window_df['ECG'].values\n",
        "    info_dict = {}\n",
        "\n",
        "    # Time domain\n",
        "    info_dict[f'ECG mean'] = ecg.mean()\n",
        "    info_dict[f'ECG stdev'] = ecg.std()\n",
        "\n",
        "    # Frequency domain\n",
        "    ecg_centered = ecg - ecg.mean()\n",
        "    fft_mag = np.abs(fft(ecg_centered))\n",
        "    fft_freqs = fftfreq(len(ecg_centered), 1/fs)\n",
        "    info_dict[f'ECG peak freq'] = fft_freqs[fft_mag.argmax()]\n",
        "\n",
        "    # Return a dictionary of calculations\n",
        "    return info_dict"
      ],
      "metadata": {
        "id": "B2XcmaQ7K11H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_ecg_metrics(window_df)"
      ],
      "metadata": {
        "id": "qFsr-9_1K11H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(Part 5)** If all of the functions above are complete, then you should be able to run the following function below to produce a single `dict` that includes the metrics across all sensors for a given `DataFrame`:"
      ],
      "metadata": {
        "id": "OrgAiKEgNmBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_window(window_df):\n",
        "    \"\"\"\n",
        "    Process a DataFrame and produce all of the metrics as a dictionary\n",
        "    (one value per key)\n",
        "    window_df: the DataFrame\n",
        "    \"\"\"\n",
        "    # Extract metrics\n",
        "    eeg_dict = compute_eeg_metrics(window_df)\n",
        "    emg_dict = compute_emg_metrics(window_df)\n",
        "    eog_dict = compute_eog_metrics(window_df)\n",
        "    ecg_dict = compute_ecg_metrics(window_df)\n",
        "\n",
        "    # Combine everything into a single dictionary\n",
        "    final_dict = {}\n",
        "    final_dict.update(eeg_dict)\n",
        "    final_dict.update(emg_dict)\n",
        "    final_dict.update(eog_dict)\n",
        "    final_dict.update(ecg_dict)\n",
        "\n",
        "    # Check that the keys are unique from the original metrics\n",
        "    if len(final_dict) != len(eeg_dict) + len(emg_dict) + len(eog_dict) + len(ecg_dict):\n",
        "        raise Exception('Make sure the keys of your dictionaries are unique')\n",
        "    return final_dict"
      ],
      "metadata": {
        "id": "-6Egsxlfil5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test our function\n",
        "process_window(window_df)"
      ],
      "metadata": {
        "id": "6YynXU1C-J7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Our Processed Dataset"
      ],
      "metadata": {
        "id": "2gLiPr2p6ymF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this part of the notebook, simply run the code below to create your final dataset. This will take a long time because the recordings are long. When the code is done running, notice how each window corresponds to a single row."
      ],
      "metadata": {
        "id": "wXntyzHBC-tQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the subject IDs\n",
        "df = pd.DataFrame()\n",
        "for subject in subject_list:\n",
        "    # Load the DataFrame\n",
        "    subject_df = pd.read_csv(os.path.join(base_folder, f'{subject}.csv'))\n",
        "\n",
        "    # Iterate through all windows\n",
        "    window_starts = np.arange(0, subject_df['Time'].max(), 30)\n",
        "    for window_start in window_starts:\n",
        "        # Grab the window\n",
        "        window_df, annotation = grab_window(subject_df, window_start)\n",
        "\n",
        "        # Process the window\n",
        "        result_dict = process_window(window_df)\n",
        "\n",
        "        # Add it to the final DataFrame\n",
        "        result_dict['Subject ID'] = subject\n",
        "        result_dict['Start Time'] = window_start\n",
        "        result_dict['Annotation'] = annotation\n",
        "\n",
        "        result_df = pd.DataFrame([result_dict])\n",
        "        df = pd.concat([df, result_df], axis=0)"
      ],
      "metadata": {
        "id": "vyt2LUL7i1BC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_cols = ['Subject ID', 'Start Time', 'Annotation']\n",
        "new_col_order = first_cols + [col for col in df.columns if col not in first_cols]\n",
        "df = df[new_col_order]\n",
        "df"
      ],
      "metadata": {
        "id": "B9UUHzncTGGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring Our PSG Data Characteristics"
      ],
      "metadata": {
        "id": "h6-LwnNSWE8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this part of the notebook, your task is to use the techniques we discussed in class to the various techniques we discussed in class (e.g., descriptive statistics, histograms) to investigate whether the window characteristics you calculated are useful for discriminating different sleep stages.\n",
        "\n",
        "You do not need to look at every single metric using every analysis technique. However, it is important that you are able to show that you come away from this homework feeling comfortable that at least a few of your metrics are discriminative since you will use this dataset in later assignments. If none of your metrics are discriminative, then you should consider extracting different metrics from the windows."
      ],
      "metadata": {
        "id": "QxpSzGO1ypCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For your convenience, the code below retrieves the names of all of your metrics:"
      ],
      "metadata": {
        "id": "i8f6r0ZGk52s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = list(filter(lambda x: x not in first_cols, df.columns))\n",
        "metrics"
      ],
      "metadata": {
        "id": "a6nzJMa0WHS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(Part 1)** Calculate the average and standard deviation of your metrics within each sleep stage. For the sake of readability, you do not need to show these statistics for every single metric."
      ],
      "metadata": {
        "id": "mem2Aa8wlHoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_w = df[df['Annotation'] == 'W']\n",
        "df_n1 = df[df['Annotation'] == 'N1']\n",
        "df_n2 = df[df['Annotation'] == 'N2']\n",
        "df_n3 = df[df['Annotation'] == 'N3']\n",
        "df_r = df[df['Annotation'] == 'R']"
      ],
      "metadata": {
        "id": "-nn6JLgul4Z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in metrics[:5]:\n",
        "    print(col)\n",
        "    print(f'W: {df_w[col].mean()} ± {df_w[col].std()}')\n",
        "    print(f'N1: {df_n1[col].mean()} ± {df_n1[col].std()}')\n",
        "    print(f'N2: {df_n2[col].mean()} ± {df_n2[col].std()}')\n",
        "    print(f'N3: {df_n3[col].mean()} ± {df_n3[col].std()}')\n",
        "    print(f'R: {df_r[col].mean()} ± {df_r[col].std()}')\n",
        "    print('------------------')"
      ],
      "metadata": {
        "id": "gXIDkkz1lUAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(Part 2)** Generate histograms showing how the distribution of your metrics differ across sleep stages. For the sake of readability, you do not need to show these statistics for every single metric."
      ],
      "metadata": {
        "id": "aFedJTcYnipw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_histograms(df, col):\n",
        "    plt.figure(figsize=(8,4))\n",
        "    grouped_df = df.groupby('Annotation')[col]\n",
        "    grouped_df.plot.hist(bins=20, alpha=0.7, legend=True)\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title(f'Histogram of {col}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "6v5o15ieuABC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in metrics[:5]:\n",
        "    compare_histograms(df, col)"
      ],
      "metadata": {
        "id": "vp_YAvHeu86z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(Part 3)** The following code has already been written for your to conduct statistical tests comparing your metrics across sleep stages. Notice that the code uses different statistical tests than the ones we did in class: ANOVA instead of a t-test and a Kruskal-Wallis instead of a Mann-Whitney U test. This is because we have more than two categories that we are interested in comparing.\n",
        "\n",
        "Run this code to determine whether or not any of your metrics are significantly different across sleep stages."
      ],
      "metadata": {
        "id": "oBSGWZoFJGCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "def compare_distributions(df, col):\n",
        "    # Get the relevant data\n",
        "    data = df[col]\n",
        "    df_w_data = df[df['Annotation'] == 'W'][col]\n",
        "    df_n1_data = df[df['Annotation'] == 'N1'][col]\n",
        "    df_n2_data = df[df['Annotation'] == 'N2'][col]\n",
        "    df_n3_data = df[df['Annotation'] == 'N3'][col]\n",
        "    df_r_data = df[df['Annotation'] == 'R'][col]\n",
        "\n",
        "    # Check of the data is normally distributed\n",
        "    statistic, p_value = stats.normaltest(data)\n",
        "    test = None\n",
        "    if p_value > 0.05:\n",
        "        # Data is normally distributed, use ANOVA\n",
        "        test = 'ANOVA'\n",
        "        statistic, p_value = stats.f_oneway(df_w_data, df_n1_data, df_n2_data, df_n3_data, df_r_data)\n",
        "    else:\n",
        "        # Data is not normally distributed, use Kruskal-Wallis Test\n",
        "        test = 'Kruskal-Wallis'\n",
        "        statistic, p_value = stats.kruskal(df_w_data, df_n1_data, df_n2_data, df_n3_data, df_r_data)\n",
        "\n",
        "    print(f'Result of {test} for {col}: {statistic}, p-value is {p_value:0.3f}')"
      ],
      "metadata": {
        "id": "kUlm9qmPJHaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in metrics[:5]:\n",
        "    compare_distributions(df, col)"
      ],
      "metadata": {
        "id": "m3cscikbPXIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bookkeeping"
      ],
      "metadata": {
        "id": "0CfvcgvOiRgw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANT:** Once you are happy with your `DataFrame`, export it as a `.csv` and save it somewhere on your local machine. We will use this `.csv` in future assignments."
      ],
      "metadata": {
        "id": "7GlkmtVpiBLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('psg_data.csv', index=False)"
      ],
      "metadata": {
        "id": "fpTaXbIZiY8e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}